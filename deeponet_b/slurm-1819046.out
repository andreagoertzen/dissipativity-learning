Using backend: pytorch
Other supported backends: tensorflow.compat.v1, tensorflow, jax, paddle.
paddle supports more examples now and is recommended.
getting data...
done
initializing model...
4698625
iteration: 0      train loss: 9.44e-01      test loss: 9.40e-01      test metric: 9.98e-01
6.623706579208374
iteration: 1000      train loss: 6.90e-03      test loss: 6.90e-03      test metric: 8.55e-02
123.1921489238739
iteration: 2000      train loss: 4.55e-03      test loss: 4.32e-03      test metric: 6.76e-02
123.71012234687805
iteration: 3000      train loss: 3.05e-03      test loss: 2.91e-03      test metric: 5.55e-02
123.67224645614624
iteration: 4000      train loss: 2.18e-03      test loss: 1.97e-03      test metric: 4.56e-02
123.74733328819275
iteration: 5000      train loss: 2.18e-03      test loss: 2.21e-03      test metric: 4.83e-02
123.63154292106628
iteration: 6000      train loss: 1.91e-03      test loss: 2.23e-03      test metric: 4.86e-02
123.57168388366699
iteration: 7000      train loss: 2.11e-03      test loss: 2.07e-03      test metric: 4.68e-02
123.5167498588562
iteration: 8000      train loss: 1.20e-03      test loss: 1.14e-03      test metric: 3.47e-02
123.43016791343689
iteration: 9000      train loss: 7.55e-04      test loss: 8.52e-04      test metric: 3.00e-02
123.35290813446045
iteration: 10000      train loss: 1.69e-03      test loss: 1.36e-03      test metric: 3.80e-02
123.45522713661194
iteration: 11000      train loss: 9.55e-04      test loss: 9.35e-04      test metric: 3.15e-02
123.39934134483337
iteration: 12000      train loss: 1.61e-03      test loss: 1.16e-03      test metric: 3.50e-02
123.43364524841309
iteration: 13000      train loss: 6.42e-04      test loss: 6.82e-04      test metric: 2.69e-02
123.35792565345764
iteration: 14000      train loss: 7.17e-04      test loss: 6.70e-04      test metric: 2.66e-02
123.25505447387695
iteration: 15000      train loss: 6.55e-04      test loss: 5.72e-04      test metric: 2.46e-02
123.17317509651184
iteration: 16000      train loss: 6.19e-04      test loss: 5.32e-04      test metric: 2.37e-02
123.13436961174011
iteration: 17000      train loss: 8.09e-04      test loss: 7.60e-04      test metric: 2.84e-02
123.04604005813599
iteration: 18000      train loss: 1.00e-03      test loss: 1.04e-03      test metric: 3.32e-02
123.14120101928711
iteration: 19000      train loss: 4.47e-04      test loss: 4.41e-04      test metric: 2.16e-02
123.06638073921204
iteration: 20000      train loss: 4.06e-04      test loss: 4.28e-04      test metric: 2.13e-02
123.05365443229675
iteration: 21000      train loss: 4.69e-04      test loss: 3.99e-04      test metric: 2.05e-02
123.00325441360474
iteration: 22000      train loss: 5.07e-04      test loss: 5.19e-04      test metric: 2.34e-02
122.98577547073364
iteration: 23000      train loss: 5.69e-04      test loss: 5.87e-04      test metric: 2.49e-02
122.9258291721344
iteration: 24000      train loss: 6.82e-04      test loss: 6.84e-04      test metric: 2.69e-02
122.98843598365784
iteration: 25000      train loss: 2.64e-04      test loss: 3.03e-04      test metric: 1.79e-02
122.85966873168945
iteration: 26000      train loss: 2.67e-04      test loss: 2.81e-04      test metric: 1.72e-02
122.88622689247131
iteration: 27000      train loss: 3.49e-04      test loss: 3.34e-04      test metric: 1.88e-02
122.8688154220581
iteration: 28000      train loss: 3.79e-04      test loss: 4.59e-04      test metric: 2.21e-02
122.86292171478271
iteration: 29000      train loss: 2.71e-04      test loss: 2.84e-04      test metric: 1.74e-02
122.82639837265015
iteration: 30000      train loss: 5.95e-04      test loss: 6.45e-04      test metric: 2.61e-02
122.88451743125916
iteration: 31000      train loss: 3.86e-04      test loss: 5.04e-04      test metric: 2.31e-02
122.77655339241028
iteration: 32000      train loss: 4.27e-04      test loss: 6.33e-04      test metric: 2.59e-02
123.26021790504456
iteration: 33000      train loss: 2.20e-04      test loss: 2.27e-04      test metric: 1.55e-02
122.6761474609375
iteration: 34000      train loss: 2.72e-04      test loss: 3.01e-04      test metric: 1.78e-02
122.6530408859253
iteration: 35000      train loss: 8.70e-04      test loss: 1.14e-03      test metric: 3.48e-02
122.73482203483582
iteration: 36000      train loss: 2.29e-04      test loss: 2.63e-04      test metric: 1.67e-02
122.81686329841614
iteration: 37000      train loss: 5.98e-04      test loss: 5.32e-04      test metric: 2.37e-02
122.79939699172974
iteration: 38000      train loss: 2.66e-04      test loss: 2.66e-04      test metric: 1.68e-02
122.76445317268372
iteration: 39000      train loss: 1.62e-04      test loss: 1.72e-04      test metric: 1.35e-02
122.70155787467957
iteration: 40000      train loss: 2.09e-04      test loss: 2.60e-04      test metric: 1.66e-02
122.62445998191833
iteration: 41000      train loss: 3.08e-04      test loss: 2.77e-04      test metric: 1.71e-02
122.66071796417236
iteration: 42000      train loss: 3.09e-04      test loss: 2.79e-04      test metric: 1.72e-02
122.53211545944214
iteration: 43000      train loss: 2.20e-04      test loss: 2.05e-04      test metric: 1.47e-02
122.51952815055847
iteration: 44000      train loss: 1.63e-04      test loss: 1.94e-04      test metric: 1.43e-02
122.51020216941833
iteration: 45000      train loss: 2.02e-04      test loss: 2.30e-04      test metric: 1.56e-02
122.58608913421631
iteration: 46000      train loss: 1.88e-04      test loss: 2.20e-04      test metric: 1.52e-02
122.53446388244629
iteration: 47000      train loss: 2.47e-04      test loss: 3.00e-04      test metric: 1.78e-02
122.5212025642395
iteration: 48000      train loss: 2.74e-04      test loss: 3.35e-04      test metric: 1.88e-02
122.54577422142029
iteration: 49000      train loss: 1.62e-04      test loss: 1.84e-04      test metric: 1.40e-02
122.52078819274902
iteration: 50000      train loss: 1.51e-04      test loss: 1.64e-04      test metric: 1.32e-02
122.38414597511292
iteration: 51000      train loss: 1.47e-04      test loss: 1.53e-04      test metric: 1.27e-02
122.34433555603027
iteration: 52000      train loss: 1.87e-04      test loss: 1.89e-04      test metric: 1.41e-02
122.45414996147156
iteration: 53000      train loss: 4.00e-04      test loss: 2.76e-04      test metric: 1.71e-02
122.4202196598053
iteration: 54000      train loss: 1.64e-04      test loss: 1.74e-04      test metric: 1.36e-02
122.28933525085449
iteration: 55000      train loss: 2.24e-04      test loss: 2.02e-04      test metric: 1.46e-02
122.34380173683167
iteration: 56000      train loss: 2.28e-04      test loss: 2.32e-04      test metric: 1.57e-02
122.18442821502686
iteration: 57000      train loss: 1.40e-04      test loss: 1.54e-04      test metric: 1.28e-02
122.2845549583435
iteration: 58000      train loss: 1.28e-04      test loss: 1.46e-04      test metric: 1.24e-02
122.21140027046204
iteration: 59000      train loss: 1.37e-04      test loss: 1.49e-04      test metric: 1.26e-02
122.11757397651672
iteration: 60000      train loss: 1.44e-04      test loss: 1.58e-04      test metric: 1.29e-02
122.1710696220398
iteration: 61000      train loss: 1.31e-04      test loss: 1.39e-04      test metric: 1.21e-02
122.01637864112854
iteration: 62000      train loss: 1.34e-04      test loss: 1.45e-04      test metric: 1.24e-02
121.99156284332275
iteration: 63000      train loss: 3.13e-04      test loss: 3.29e-04      test metric: 1.87e-02
122.2136824131012
iteration: 64000      train loss: 3.44e-04      test loss: 3.42e-04      test metric: 1.90e-02
122.98701906204224
iteration: 65000      train loss: 1.73e-04      test loss: 1.76e-04      test metric: 1.36e-02
122.06933116912842
iteration: 66000      train loss: 1.53e-04      test loss: 1.69e-04      test metric: 1.34e-02
122.02798557281494
iteration: 67000      train loss: 1.22e-04      test loss: 1.36e-04      test metric: 1.20e-02
122.07257866859436
iteration: 68000      train loss: 1.49e-04      test loss: 1.44e-04      test metric: 1.23e-02
122.09071731567383
iteration: 69000      train loss: 1.46e-04      test loss: 1.60e-04      test metric: 1.30e-02
122.09679698944092
iteration: 70000      train loss: 1.57e-04      test loss: 1.84e-04      test metric: 1.39e-02
122.09951186180115
iteration: 71000      train loss: 8.70e-05      test loss: 1.09e-04      test metric: 1.07e-02
122.18943500518799
iteration: 72000      train loss: 3.33e-04      test loss: 2.94e-04      test metric: 1.76e-02
122.17147707939148
iteration: 73000      train loss: 1.12e-04      test loss: 1.54e-04      test metric: 1.28e-02
122.31816244125366
iteration: 74000      train loss: 8.47e-05      test loss: 1.04e-04      test metric: 1.05e-02
122.26999711990356
iteration: 75000      train loss: 1.18e-04      test loss: 1.37e-04      test metric: 1.20e-02
122.24352169036865
iteration: 76000      train loss: 8.96e-05      test loss: 1.09e-04      test metric: 1.07e-02
121.8905897140503
iteration: 77000      train loss: 1.36e-04      test loss: 1.36e-04      test metric: 1.20e-02
121.86220693588257
iteration: 78000      train loss: 2.15e-04      test loss: 2.21e-04      test metric: 1.53e-02
121.82368588447571
iteration: 79000      train loss: 2.98e-04      test loss: 4.57e-04      test metric: 2.20e-02
121.80708742141724
iteration: 80000      train loss: 8.42e-05      test loss: 1.03e-04      test metric: 1.04e-02
121.77922773361206
iteration: 81000      train loss: 9.30e-05      test loss: 1.08e-04      test metric: 1.07e-02
121.69183564186096
iteration: 82000      train loss: 1.64e-04      test loss: 1.66e-04      test metric: 1.32e-02
121.61146283149719
iteration: 83000      train loss: 9.30e-05      test loss: 1.08e-04      test metric: 1.07e-02
121.5330822467804
iteration: 84000      train loss: 1.06e-04      test loss: 1.24e-04      test metric: 1.15e-02
121.73478078842163
iteration: 85000      train loss: 1.13e-04      test loss: 1.22e-04      test metric: 1.14e-02
121.6926531791687
iteration: 86000      train loss: 4.08e-04      test loss: 3.64e-04      test metric: 1.96e-02
121.71887612342834
iteration: 87000      train loss: 1.55e-04      test loss: 1.80e-04      test metric: 1.38e-02
121.5027322769165
iteration: 88000      train loss: 1.28e-04      test loss: 1.64e-04      test metric: 1.32e-02
121.60416793823242
iteration: 89000      train loss: 2.66e-04      test loss: 2.95e-04      test metric: 1.77e-02
121.66534876823425
iteration: 90000      train loss: 7.62e-05      test loss: 9.43e-05      test metric: 9.99e-03
121.69643926620483
iteration: 91000      train loss: 6.96e-05      test loss: 8.62e-05      test metric: 9.56e-03
121.6583514213562
iteration: 92000      train loss: 1.57e-04      test loss: 1.77e-04      test metric: 1.37e-02
121.52754974365234
iteration: 93000      train loss: 7.27e-05      test loss: 9.49e-05      test metric: 1.00e-02
121.5684404373169
iteration: 94000      train loss: 8.39e-05      test loss: 1.02e-04      test metric: 1.04e-02
121.68427395820618
iteration: 95000      train loss: 2.58e-04      test loss: 2.82e-04      test metric: 1.73e-02
121.70282244682312
iteration: 96000      train loss: 9.75e-05      test loss: 1.17e-04      test metric: 1.11e-02
121.94435906410217
iteration: 97000      train loss: 7.30e-05      test loss: 9.29e-05      test metric: 9.92e-03
121.54291844367981
iteration: 98000      train loss: 1.14e-04      test loss: 1.39e-04      test metric: 1.21e-02
121.58572959899902
iteration: 99000      train loss: 1.17e-04      test loss: 1.37e-04      test metric: 1.20e-02
121.74071645736694
iteration: 100000      train loss: 8.02e-05      test loss: 1.03e-04      test metric: 1.04e-02
121.68721747398376
91000
torch.Size([19950, 4096])
torch.Size([19950, 4096])
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
torch.Size([20000, 4096])
torch.Size([10000, 4096])
torch.Size([20000, 64, 64])
torch.Size([10000, 64, 64])
torch.Size([20000, 4096])
torch.Size([19950, 4096])
torch.Size([19950, 4096])
torch.Size([19950, 64, 64])
torch.Size([19950, 64, 64])
torch.Size([19950, 4096])
