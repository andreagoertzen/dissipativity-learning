2025-08-15 03:23:04,045:INFO:Created DataLoaders with 2994 training samples and 998 validation samples.
2025-08-15 03:23:05,324:INFO:model params: 479490
2025-08-15 03:23:06,953:INFO:Epoch: 0/10000 | Train Loss: 5.094e+00 | Dynamic Loss: 5.094e+00 | Regularization Loss: 6.195e-25 | Val Loss: 3.413e+00 | Time: 1.63s
2025-08-15 03:23:06,953:INFO:New best model found at epoch 0 with validation loss 3.413e+00. Saving...
2025-08-15 03:23:11,436:INFO:Epoch: 50/10000 | Train Loss: 9.023e-01 | Dynamic Loss: 9.023e-01 | Regularization Loss: 2.074e-21 | Val Loss: 9.511e-01 | Time: 4.39s
2025-08-15 03:23:11,436:INFO:New best model found at epoch 50 with validation loss 9.511e-01. Saving...
2025-08-15 03:23:15,769:INFO:Epoch: 100/10000 | Train Loss: 7.129e-01 | Dynamic Loss: 7.129e-01 | Regularization Loss: 1.892e-15 | Val Loss: 7.449e-01 | Time: 4.32s
2025-08-15 03:23:15,769:INFO:New best model found at epoch 100 with validation loss 7.449e-01. Saving...
2025-08-15 03:23:20,175:INFO:Epoch: 150/10000 | Train Loss: 6.434e-01 | Dynamic Loss: 6.434e-01 | Regularization Loss: 2.342e-08 | Val Loss: 6.642e-01 | Time: 4.40s
2025-08-15 03:23:20,175:INFO:New best model found at epoch 150 with validation loss 6.642e-01. Saving...
2025-08-15 03:23:24,553:INFO:Epoch: 200/10000 | Train Loss: 6.069e-01 | Dynamic Loss: 6.069e-01 | Regularization Loss: 6.373e-07 | Val Loss: 6.280e-01 | Time: 4.37s
2025-08-15 03:23:24,553:INFO:New best model found at epoch 200 with validation loss 6.280e-01. Saving...
2025-08-15 03:23:28,941:INFO:Epoch: 250/10000 | Train Loss: 5.925e-01 | Dynamic Loss: 5.925e-01 | Regularization Loss: 6.242e-07 | Val Loss: 6.005e-01 | Time: 4.37s
2025-08-15 03:23:28,941:INFO:New best model found at epoch 250 with validation loss 6.005e-01. Saving...
2025-08-15 03:23:38,812:INFO:Epoch: 300/10000 | Train Loss: 5.772e-01 | Dynamic Loss: 5.772e-01 | Regularization Loss: 6.029e-07 | Val Loss: 5.841e-01 | Time: 9.86s
2025-08-15 03:23:38,812:INFO:New best model found at epoch 300 with validation loss 5.841e-01. Saving...
2025-08-15 03:23:43,250:INFO:Epoch: 350/10000 | Train Loss: 5.739e-01 | Dynamic Loss: 5.739e-01 | Regularization Loss: 5.821e-07 | Val Loss: 5.742e-01 | Time: 4.43s
2025-08-15 03:23:43,250:INFO:New best model found at epoch 350 with validation loss 5.742e-01. Saving...
2025-08-15 03:23:47,658:INFO:Epoch: 400/10000 | Train Loss: 5.650e-01 | Dynamic Loss: 5.650e-01 | Regularization Loss: 5.630e-07 | Val Loss: 5.652e-01 | Time: 4.40s
2025-08-15 03:23:47,658:INFO:New best model found at epoch 400 with validation loss 5.652e-01. Saving...
2025-08-15 03:23:52,088:INFO:Epoch: 450/10000 | Train Loss: 5.606e-01 | Dynamic Loss: 5.606e-01 | Regularization Loss: 5.463e-07 | Val Loss: 5.572e-01 | Time: 4.42s
2025-08-15 03:23:52,088:INFO:New best model found at epoch 450 with validation loss 5.572e-01. Saving...
2025-08-15 03:24:02,160:INFO:Epoch: 500/10000 | Train Loss: 5.571e-01 | Dynamic Loss: 5.571e-01 | Regularization Loss: 5.288e-07 | Val Loss: 5.512e-01 | Time: 10.06s
2025-08-15 03:24:02,160:INFO:New best model found at epoch 500 with validation loss 5.512e-01. Saving...
2025-08-15 03:24:06,701:INFO:Epoch: 550/10000 | Train Loss: 5.510e-01 | Dynamic Loss: 5.510e-01 | Regularization Loss: 5.135e-07 | Val Loss: 5.460e-01 | Time: 4.53s
2025-08-15 03:24:06,701:INFO:New best model found at epoch 550 with validation loss 5.460e-01. Saving...
2025-08-15 03:24:11,141:INFO:Epoch: 600/10000 | Train Loss: 5.495e-01 | Dynamic Loss: 5.495e-01 | Regularization Loss: 4.986e-07 | Val Loss: 5.418e-01 | Time: 4.43s
2025-08-15 03:24:11,141:INFO:New best model found at epoch 600 with validation loss 5.418e-01. Saving...
2025-08-15 03:24:15,630:INFO:Epoch: 650/10000 | Train Loss: 5.447e-01 | Dynamic Loss: 5.447e-01 | Regularization Loss: 4.824e-07 | Val Loss: 5.369e-01 | Time: 4.48s
2025-08-15 03:24:15,630:INFO:New best model found at epoch 650 with validation loss 5.369e-01. Saving...
2025-08-15 03:24:20,185:INFO:Epoch: 700/10000 | Train Loss: 5.413e-01 | Dynamic Loss: 5.413e-01 | Regularization Loss: 4.676e-07 | Val Loss: 5.312e-01 | Time: 4.55s
2025-08-15 03:24:20,185:INFO:New best model found at epoch 700 with validation loss 5.312e-01. Saving...
2025-08-15 03:24:24,744:INFO:Epoch: 750/10000 | Train Loss: 5.349e-01 | Dynamic Loss: 5.349e-01 | Regularization Loss: 4.540e-07 | Val Loss: 5.274e-01 | Time: 4.55s
2025-08-15 03:24:24,744:INFO:New best model found at epoch 750 with validation loss 5.274e-01. Saving...
2025-08-15 03:24:29,261:INFO:Epoch: 800/10000 | Train Loss: 5.354e-01 | Dynamic Loss: 5.354e-01 | Regularization Loss: 4.443e-07 | Val Loss: 5.223e-01 | Time: 4.51s
2025-08-15 03:24:29,261:INFO:New best model found at epoch 800 with validation loss 5.223e-01. Saving...
2025-08-15 03:24:33,735:INFO:Epoch: 850/10000 | Train Loss: 5.291e-01 | Dynamic Loss: 5.291e-01 | Regularization Loss: 4.315e-07 | Val Loss: 5.195e-01 | Time: 4.46s
2025-08-15 03:24:33,735:INFO:New best model found at epoch 850 with validation loss 5.195e-01. Saving...
2025-08-15 03:24:39,545:INFO:Epoch: 900/10000 | Train Loss: 5.278e-01 | Dynamic Loss: 5.278e-01 | Regularization Loss: 4.226e-07 | Val Loss: 5.170e-01 | Time: 5.80s
2025-08-15 03:24:39,545:INFO:New best model found at epoch 900 with validation loss 5.170e-01. Saving...
2025-08-15 03:24:43,985:INFO:Epoch: 950/10000 | Train Loss: 5.230e-01 | Dynamic Loss: 5.230e-01 | Regularization Loss: 4.099e-07 | Val Loss: 5.156e-01 | Time: 4.43s
2025-08-15 03:24:43,985:INFO:New best model found at epoch 950 with validation loss 5.156e-01. Saving...
2025-08-15 03:24:48,438:INFO:Epoch: 1000/10000 | Train Loss: 5.216e-01 | Dynamic Loss: 5.216e-01 | Regularization Loss: 3.999e-07 | Val Loss: 5.104e-01 | Time: 4.45s
2025-08-15 03:24:48,439:INFO:New best model found at epoch 1000 with validation loss 5.104e-01. Saving...
2025-08-15 03:24:52,878:INFO:Epoch: 1050/10000 | Train Loss: 5.184e-01 | Dynamic Loss: 5.184e-01 | Regularization Loss: 3.883e-07 | Val Loss: 5.069e-01 | Time: 4.43s
2025-08-15 03:24:52,878:INFO:New best model found at epoch 1050 with validation loss 5.069e-01. Saving...
2025-08-15 03:24:58,242:INFO:Epoch: 1100/10000 | Train Loss: 5.147e-01 | Dynamic Loss: 5.147e-01 | Regularization Loss: 3.804e-07 | Val Loss: 5.048e-01 | Time: 5.36s
2025-08-15 03:24:58,242:INFO:New best model found at epoch 1100 with validation loss 5.048e-01. Saving...
2025-08-15 03:25:02,720:INFO:Epoch: 1150/10000 | Train Loss: 5.116e-01 | Dynamic Loss: 5.116e-01 | Regularization Loss: 3.717e-07 | Val Loss: 5.017e-01 | Time: 4.47s
2025-08-15 03:25:02,720:INFO:New best model found at epoch 1150 with validation loss 5.017e-01. Saving...
2025-08-15 03:25:07,206:INFO:Epoch: 1200/10000 | Train Loss: 5.118e-01 | Dynamic Loss: 5.118e-01 | Regularization Loss: 3.653e-07 | Val Loss: 5.010e-01 | Time: 4.48s
2025-08-15 03:25:07,207:INFO:New best model found at epoch 1200 with validation loss 5.010e-01. Saving...
2025-08-15 03:25:11,620:INFO:Epoch: 1250/10000 | Train Loss: 5.096e-01 | Dynamic Loss: 5.096e-01 | Regularization Loss: 3.583e-07 | Val Loss: 4.964e-01 | Time: 4.40s
2025-08-15 03:25:11,620:INFO:New best model found at epoch 1250 with validation loss 4.964e-01. Saving...
2025-08-15 03:25:16,082:INFO:Epoch: 1300/10000 | Train Loss: 5.073e-01 | Dynamic Loss: 5.073e-01 | Regularization Loss: 3.501e-07 | Val Loss: 4.945e-01 | Time: 4.45s
2025-08-15 03:25:16,082:INFO:New best model found at epoch 1300 with validation loss 4.945e-01. Saving...
2025-08-15 03:25:25,665:INFO:Epoch: 1350/10000 | Train Loss: 5.043e-01 | Dynamic Loss: 5.043e-01 | Regularization Loss: 3.430e-07 | Val Loss: 4.929e-01 | Time: 9.57s
2025-08-15 03:25:25,666:INFO:New best model found at epoch 1350 with validation loss 4.929e-01. Saving...
2025-08-15 03:25:30,207:INFO:Epoch: 1400/10000 | Train Loss: 5.011e-01 | Dynamic Loss: 5.011e-01 | Regularization Loss: 3.356e-07 | Val Loss: 4.897e-01 | Time: 4.53s
2025-08-15 03:25:30,207:INFO:New best model found at epoch 1400 with validation loss 4.897e-01. Saving...
2025-08-15 03:25:34,723:INFO:Epoch: 1450/10000 | Train Loss: 5.011e-01 | Dynamic Loss: 5.011e-01 | Regularization Loss: 3.299e-07 | Val Loss: 4.896e-01 | Time: 4.51s
2025-08-15 03:25:34,723:INFO:New best model found at epoch 1450 with validation loss 4.896e-01. Saving...
2025-08-15 03:25:39,176:INFO:Epoch: 1500/10000 | Train Loss: 4.995e-01 | Dynamic Loss: 4.995e-01 | Regularization Loss: 3.229e-07 | Val Loss: 4.860e-01 | Time: 4.44s
2025-08-15 03:25:39,177:INFO:New best model found at epoch 1500 with validation loss 4.860e-01. Saving...
2025-08-15 03:25:44,779:INFO:Epoch: 1550/10000 | Train Loss: 4.955e-01 | Dynamic Loss: 4.955e-01 | Regularization Loss: 3.192e-07 | Val Loss: 4.843e-01 | Time: 5.59s
2025-08-15 03:25:44,779:INFO:New best model found at epoch 1550 with validation loss 4.843e-01. Saving...
2025-08-15 03:25:49,308:INFO:Epoch: 1600/10000 | Train Loss: 4.951e-01 | Dynamic Loss: 4.951e-01 | Regularization Loss: 3.132e-07 | Val Loss: 4.834e-01 | Time: 4.52s
2025-08-15 03:25:49,308:INFO:New best model found at epoch 1600 with validation loss 4.834e-01. Saving...
2025-08-15 03:25:53,819:INFO:Epoch: 1650/10000 | Train Loss: 4.931e-01 | Dynamic Loss: 4.931e-01 | Regularization Loss: 3.086e-07 | Val Loss: 4.807e-01 | Time: 4.50s
2025-08-15 03:25:53,819:INFO:New best model found at epoch 1650 with validation loss 4.807e-01. Saving...
2025-08-15 03:25:58,318:INFO:Epoch: 1700/10000 | Train Loss: 4.938e-01 | Dynamic Loss: 4.938e-01 | Regularization Loss: 3.029e-07 | Val Loss: 4.820e-01 | Time: 4.49s
2025-08-15 03:26:02,846:INFO:Epoch: 1750/10000 | Train Loss: 4.893e-01 | Dynamic Loss: 4.893e-01 | Regularization Loss: 2.976e-07 | Val Loss: 4.776e-01 | Time: 4.53s
2025-08-15 03:26:02,846:INFO:New best model found at epoch 1750 with validation loss 4.776e-01. Saving...
2025-08-15 03:26:12,694:INFO:Epoch: 1800/10000 | Train Loss: 4.890e-01 | Dynamic Loss: 4.890e-01 | Regularization Loss: 2.946e-07 | Val Loss: 4.779e-01 | Time: 9.84s
2025-08-15 03:26:17,227:INFO:Epoch: 1850/10000 | Train Loss: 4.865e-01 | Dynamic Loss: 4.865e-01 | Regularization Loss: 2.884e-07 | Val Loss: 4.757e-01 | Time: 4.53s
2025-08-15 03:26:17,227:INFO:New best model found at epoch 1850 with validation loss 4.757e-01. Saving...
2025-08-15 03:26:21,731:INFO:Epoch: 1900/10000 | Train Loss: 4.838e-01 | Dynamic Loss: 4.838e-01 | Regularization Loss: 2.837e-07 | Val Loss: 4.746e-01 | Time: 4.49s
2025-08-15 03:26:21,731:INFO:New best model found at epoch 1900 with validation loss 4.746e-01. Saving...
2025-08-15 03:26:26,245:INFO:Epoch: 1950/10000 | Train Loss: 4.836e-01 | Dynamic Loss: 4.836e-01 | Regularization Loss: 2.777e-07 | Val Loss: 4.728e-01 | Time: 4.50s
2025-08-15 03:26:26,245:INFO:New best model found at epoch 1950 with validation loss 4.728e-01. Saving...
2025-08-15 03:26:35,803:INFO:Epoch: 2000/10000 | Train Loss: 4.810e-01 | Dynamic Loss: 4.810e-01 | Regularization Loss: 2.740e-07 | Val Loss: 4.712e-01 | Time: 9.55s
2025-08-15 03:26:35,803:INFO:New best model found at epoch 2000 with validation loss 4.712e-01. Saving...
2025-08-15 03:26:40,305:INFO:Epoch: 2050/10000 | Train Loss: 4.819e-01 | Dynamic Loss: 4.819e-01 | Regularization Loss: 2.689e-07 | Val Loss: 4.721e-01 | Time: 4.49s
2025-08-15 03:26:44,866:INFO:Epoch: 2100/10000 | Train Loss: 4.759e-01 | Dynamic Loss: 4.759e-01 | Regularization Loss: 2.638e-07 | Val Loss: 4.676e-01 | Time: 4.56s
2025-08-15 03:26:44,866:INFO:New best model found at epoch 2100 with validation loss 4.676e-01. Saving...
2025-08-15 03:26:49,371:INFO:Epoch: 2150/10000 | Train Loss: 4.743e-01 | Dynamic Loss: 4.743e-01 | Regularization Loss: 2.574e-07 | Val Loss: 4.652e-01 | Time: 4.50s
2025-08-15 03:26:49,371:INFO:New best model found at epoch 2150 with validation loss 4.652e-01. Saving...
2025-08-15 03:26:54,507:INFO:Epoch: 2200/10000 | Train Loss: 4.717e-01 | Dynamic Loss: 4.717e-01 | Regularization Loss: 2.526e-07 | Val Loss: 4.659e-01 | Time: 5.12s
2025-08-15 03:26:58,991:INFO:Epoch: 2250/10000 | Train Loss: 4.693e-01 | Dynamic Loss: 4.693e-01 | Regularization Loss: 2.468e-07 | Val Loss: 4.618e-01 | Time: 4.48s
2025-08-15 03:26:58,992:INFO:New best model found at epoch 2250 with validation loss 4.618e-01. Saving...
2025-08-15 03:27:03,536:INFO:Epoch: 2300/10000 | Train Loss: 4.659e-01 | Dynamic Loss: 4.659e-01 | Regularization Loss: 2.422e-07 | Val Loss: 4.610e-01 | Time: 4.54s
2025-08-15 03:27:03,536:INFO:New best model found at epoch 2300 with validation loss 4.610e-01. Saving...
2025-08-15 03:27:08,024:INFO:Epoch: 2350/10000 | Train Loss: 4.648e-01 | Dynamic Loss: 4.648e-01 | Regularization Loss: 2.388e-07 | Val Loss: 4.583e-01 | Time: 4.48s
2025-08-15 03:27:08,024:INFO:New best model found at epoch 2350 with validation loss 4.583e-01. Saving...
2025-08-15 03:27:12,524:INFO:Epoch: 2400/10000 | Train Loss: 4.651e-01 | Dynamic Loss: 4.651e-01 | Regularization Loss: 2.356e-07 | Val Loss: 4.590e-01 | Time: 4.49s
2025-08-15 03:27:19,968:INFO:Epoch: 2450/10000 | Train Loss: 4.629e-01 | Dynamic Loss: 4.629e-01 | Regularization Loss: 2.338e-07 | Val Loss: 4.568e-01 | Time: 7.44s
2025-08-15 03:27:19,968:INFO:New best model found at epoch 2450 with validation loss 4.568e-01. Saving...
2025-08-15 03:27:24,478:INFO:Epoch: 2500/10000 | Train Loss: 4.624e-01 | Dynamic Loss: 4.624e-01 | Regularization Loss: 2.306e-07 | Val Loss: 4.566e-01 | Time: 4.50s
2025-08-15 03:27:24,478:INFO:New best model found at epoch 2500 with validation loss 4.566e-01. Saving...
2025-08-15 03:27:28,958:INFO:Epoch: 2550/10000 | Train Loss: 4.599e-01 | Dynamic Loss: 4.599e-01 | Regularization Loss: 2.283e-07 | Val Loss: 4.546e-01 | Time: 4.47s
2025-08-15 03:27:28,958:INFO:New best model found at epoch 2550 with validation loss 4.546e-01. Saving...
2025-08-15 03:27:33,472:INFO:Epoch: 2600/10000 | Train Loss: 4.598e-01 | Dynamic Loss: 4.598e-01 | Regularization Loss: 2.250e-07 | Val Loss: 4.539e-01 | Time: 4.50s
2025-08-15 03:27:33,472:INFO:New best model found at epoch 2600 with validation loss 4.539e-01. Saving...
2025-08-15 03:27:38,010:INFO:Epoch: 2650/10000 | Train Loss: 4.585e-01 | Dynamic Loss: 4.585e-01 | Regularization Loss: 2.235e-07 | Val Loss: 4.546e-01 | Time: 4.53s
2025-08-15 03:27:48,934:INFO:Epoch: 2700/10000 | Train Loss: 4.573e-01 | Dynamic Loss: 4.573e-01 | Regularization Loss: 2.214e-07 | Val Loss: 4.526e-01 | Time: 10.92s
2025-08-15 03:27:48,934:INFO:New best model found at epoch 2700 with validation loss 4.526e-01. Saving...
2025-08-15 03:27:53,482:INFO:Epoch: 2750/10000 | Train Loss: 4.564e-01 | Dynamic Loss: 4.564e-01 | Regularization Loss: 2.189e-07 | Val Loss: 4.524e-01 | Time: 4.54s
2025-08-15 03:27:53,482:INFO:New best model found at epoch 2750 with validation loss 4.524e-01. Saving...
2025-08-15 03:27:57,969:INFO:Epoch: 2800/10000 | Train Loss: 4.553e-01 | Dynamic Loss: 4.553e-01 | Regularization Loss: 2.176e-07 | Val Loss: 4.519e-01 | Time: 4.48s
2025-08-15 03:27:57,970:INFO:New best model found at epoch 2800 with validation loss 4.519e-01. Saving...
2025-08-15 03:28:02,471:INFO:Epoch: 2850/10000 | Train Loss: 4.542e-01 | Dynamic Loss: 4.542e-01 | Regularization Loss: 2.137e-07 | Val Loss: 4.526e-01 | Time: 4.49s
2025-08-15 03:28:13,301:INFO:Epoch: 2900/10000 | Train Loss: 4.537e-01 | Dynamic Loss: 4.537e-01 | Regularization Loss: 2.125e-07 | Val Loss: 4.497e-01 | Time: 10.83s
2025-08-15 03:28:13,301:INFO:New best model found at epoch 2900 with validation loss 4.497e-01. Saving...
2025-08-15 03:28:17,928:INFO:Epoch: 2950/10000 | Train Loss: 4.538e-01 | Dynamic Loss: 4.538e-01 | Regularization Loss: 2.098e-07 | Val Loss: 4.490e-01 | Time: 4.62s
2025-08-15 03:28:17,928:INFO:New best model found at epoch 2950 with validation loss 4.490e-01. Saving...
2025-08-15 03:28:22,522:INFO:Epoch: 3000/10000 | Train Loss: 4.530e-01 | Dynamic Loss: 4.530e-01 | Regularization Loss: 2.068e-07 | Val Loss: 4.489e-01 | Time: 4.58s
2025-08-15 03:28:22,522:INFO:New best model found at epoch 3000 with validation loss 4.489e-01. Saving...
2025-08-15 03:28:27,016:INFO:Epoch: 3050/10000 | Train Loss: 4.498e-01 | Dynamic Loss: 4.498e-01 | Regularization Loss: 2.048e-07 | Val Loss: 4.464e-01 | Time: 4.49s
2025-08-15 03:28:27,016:INFO:New best model found at epoch 3050 with validation loss 4.464e-01. Saving...
2025-08-15 03:28:32,596:INFO:Epoch: 3100/10000 | Train Loss: 4.506e-01 | Dynamic Loss: 4.506e-01 | Regularization Loss: 2.026e-07 | Val Loss: 4.456e-01 | Time: 5.57s
2025-08-15 03:28:32,596:INFO:New best model found at epoch 3100 with validation loss 4.456e-01. Saving...
2025-08-15 03:28:37,142:INFO:Epoch: 3150/10000 | Train Loss: 4.493e-01 | Dynamic Loss: 4.493e-01 | Regularization Loss: 2.013e-07 | Val Loss: 4.447e-01 | Time: 4.54s
2025-08-15 03:28:37,143:INFO:New best model found at epoch 3150 with validation loss 4.447e-01. Saving...
2025-08-15 03:28:41,726:INFO:Epoch: 3200/10000 | Train Loss: 4.485e-01 | Dynamic Loss: 4.485e-01 | Regularization Loss: 1.989e-07 | Val Loss: 4.438e-01 | Time: 4.58s
2025-08-15 03:28:41,726:INFO:New best model found at epoch 3200 with validation loss 4.438e-01. Saving...
2025-08-15 03:28:46,280:INFO:Epoch: 3250/10000 | Train Loss: 4.460e-01 | Dynamic Loss: 4.460e-01 | Regularization Loss: 1.975e-07 | Val Loss: 4.434e-01 | Time: 4.54s
2025-08-15 03:28:46,280:INFO:New best model found at epoch 3250 with validation loss 4.434e-01. Saving...
2025-08-15 03:28:50,772:INFO:Epoch: 3300/10000 | Train Loss: 4.452e-01 | Dynamic Loss: 4.452e-01 | Regularization Loss: 1.955e-07 | Val Loss: 4.437e-01 | Time: 4.48s
2025-08-15 03:28:59,148:INFO:Epoch: 3350/10000 | Train Loss: 4.452e-01 | Dynamic Loss: 4.452e-01 | Regularization Loss: 1.932e-07 | Val Loss: 4.438e-01 | Time: 8.38s
2025-08-15 03:29:03,704:INFO:Epoch: 3400/10000 | Train Loss: 4.445e-01 | Dynamic Loss: 4.445e-01 | Regularization Loss: 1.921e-07 | Val Loss: 4.417e-01 | Time: 4.56s
2025-08-15 03:29:03,704:INFO:New best model found at epoch 3400 with validation loss 4.417e-01. Saving...
2025-08-15 03:29:08,266:INFO:Epoch: 3450/10000 | Train Loss: 4.441e-01 | Dynamic Loss: 4.441e-01 | Regularization Loss: 1.900e-07 | Val Loss: 4.403e-01 | Time: 4.55s
2025-08-15 03:29:08,266:INFO:New best model found at epoch 3450 with validation loss 4.403e-01. Saving...
2025-08-15 03:29:12,863:INFO:Epoch: 3500/10000 | Train Loss: 4.441e-01 | Dynamic Loss: 4.441e-01 | Regularization Loss: 1.896e-07 | Val Loss: 4.408e-01 | Time: 4.59s
2025-08-15 03:29:17,370:INFO:Epoch: 3550/10000 | Train Loss: 4.430e-01 | Dynamic Loss: 4.430e-01 | Regularization Loss: 1.883e-07 | Val Loss: 4.396e-01 | Time: 4.51s
2025-08-15 03:29:17,370:INFO:New best model found at epoch 3550 with validation loss 4.396e-01. Saving...
2025-08-15 03:29:28,034:INFO:Epoch: 3600/10000 | Train Loss: 4.428e-01 | Dynamic Loss: 4.428e-01 | Regularization Loss: 1.872e-07 | Val Loss: 4.403e-01 | Time: 10.65s
2025-08-15 03:29:32,603:INFO:Epoch: 3650/10000 | Train Loss: 4.421e-01 | Dynamic Loss: 4.421e-01 | Regularization Loss: 1.855e-07 | Val Loss: 4.392e-01 | Time: 4.57s
2025-08-15 03:29:32,603:INFO:New best model found at epoch 3650 with validation loss 4.392e-01. Saving...
2025-08-15 03:29:37,193:INFO:Epoch: 3700/10000 | Train Loss: 4.406e-01 | Dynamic Loss: 4.406e-01 | Regularization Loss: 1.845e-07 | Val Loss: 4.392e-01 | Time: 4.58s
2025-08-15 03:29:41,730:INFO:Epoch: 3750/10000 | Train Loss: 4.405e-01 | Dynamic Loss: 4.405e-01 | Regularization Loss: 1.827e-07 | Val Loss: 4.390e-01 | Time: 4.54s
2025-08-15 03:29:41,730:INFO:New best model found at epoch 3750 with validation loss 4.390e-01. Saving...
2025-08-15 03:29:49,685:INFO:Epoch: 3800/10000 | Train Loss: 4.401e-01 | Dynamic Loss: 4.401e-01 | Regularization Loss: 1.813e-07 | Val Loss: 4.391e-01 | Time: 7.95s
2025-08-15 03:29:54,223:INFO:Epoch: 3850/10000 | Train Loss: 4.392e-01 | Dynamic Loss: 4.392e-01 | Regularization Loss: 1.801e-07 | Val Loss: 4.386e-01 | Time: 4.54s
2025-08-15 03:29:54,223:INFO:New best model found at epoch 3850 with validation loss 4.386e-01. Saving...
2025-08-15 03:29:58,783:INFO:Epoch: 3900/10000 | Train Loss: 4.385e-01 | Dynamic Loss: 4.385e-01 | Regularization Loss: 1.785e-07 | Val Loss: 4.377e-01 | Time: 4.55s
2025-08-15 03:29:58,783:INFO:New best model found at epoch 3900 with validation loss 4.377e-01. Saving...
2025-08-15 03:30:03,344:INFO:Epoch: 3950/10000 | Train Loss: 4.383e-01 | Dynamic Loss: 4.383e-01 | Regularization Loss: 1.778e-07 | Val Loss: 4.370e-01 | Time: 4.55s
2025-08-15 03:30:03,344:INFO:New best model found at epoch 3950 with validation loss 4.370e-01. Saving...
2025-08-15 03:30:10,851:INFO:Epoch: 4000/10000 | Train Loss: 4.381e-01 | Dynamic Loss: 4.381e-01 | Regularization Loss: 1.762e-07 | Val Loss: 4.370e-01 | Time: 7.50s
2025-08-15 03:30:15,462:INFO:Epoch: 4050/10000 | Train Loss: 4.366e-01 | Dynamic Loss: 4.366e-01 | Regularization Loss: 1.753e-07 | Val Loss: 4.361e-01 | Time: 4.61s
2025-08-15 03:30:15,462:INFO:New best model found at epoch 4050 with validation loss 4.361e-01. Saving...
2025-08-15 03:30:20,030:INFO:Epoch: 4100/10000 | Train Loss: 4.347e-01 | Dynamic Loss: 4.347e-01 | Regularization Loss: 1.731e-07 | Val Loss: 4.359e-01 | Time: 4.56s
2025-08-15 03:30:20,030:INFO:New best model found at epoch 4100 with validation loss 4.359e-01. Saving...
2025-08-15 03:30:24,526:INFO:Epoch: 4150/10000 | Train Loss: 4.346e-01 | Dynamic Loss: 4.346e-01 | Regularization Loss: 1.722e-07 | Val Loss: 4.353e-01 | Time: 4.49s
2025-08-15 03:30:24,526:INFO:New best model found at epoch 4150 with validation loss 4.353e-01. Saving...
2025-08-15 03:30:29,040:INFO:Epoch: 4200/10000 | Train Loss: 4.351e-01 | Dynamic Loss: 4.351e-01 | Regularization Loss: 1.692e-07 | Val Loss: 4.346e-01 | Time: 4.50s
2025-08-15 03:30:29,040:INFO:New best model found at epoch 4200 with validation loss 4.346e-01. Saving...
2025-08-15 03:30:39,818:INFO:Epoch: 4250/10000 | Train Loss: 4.308e-01 | Dynamic Loss: 4.308e-01 | Regularization Loss: 1.669e-07 | Val Loss: 4.330e-01 | Time: 10.77s
2025-08-15 03:30:39,818:INFO:New best model found at epoch 4250 with validation loss 4.330e-01. Saving...
2025-08-15 03:30:44,452:INFO:Epoch: 4300/10000 | Train Loss: 4.301e-01 | Dynamic Loss: 4.301e-01 | Regularization Loss: 1.642e-07 | Val Loss: 4.322e-01 | Time: 4.62s
2025-08-15 03:30:44,452:INFO:New best model found at epoch 4300 with validation loss 4.322e-01. Saving...
2025-08-15 03:30:49,061:INFO:Epoch: 4350/10000 | Train Loss: 4.297e-01 | Dynamic Loss: 4.297e-01 | Regularization Loss: 1.638e-07 | Val Loss: 4.324e-01 | Time: 4.60s
2025-08-15 03:30:53,617:INFO:Epoch: 4400/10000 | Train Loss: 4.290e-01 | Dynamic Loss: 4.290e-01 | Regularization Loss: 1.628e-07 | Val Loss: 4.312e-01 | Time: 4.56s
2025-08-15 03:30:53,618:INFO:New best model found at epoch 4400 with validation loss 4.312e-01. Saving...
2025-08-15 03:30:58,164:INFO:Epoch: 4450/10000 | Train Loss: 4.271e-01 | Dynamic Loss: 4.271e-01 | Regularization Loss: 1.610e-07 | Val Loss: 4.294e-01 | Time: 4.54s
2025-08-15 03:30:58,164:INFO:New best model found at epoch 4450 with validation loss 4.294e-01. Saving...
2025-08-15 03:31:09,427:INFO:Epoch: 4500/10000 | Train Loss: 4.273e-01 | Dynamic Loss: 4.273e-01 | Regularization Loss: 1.595e-07 | Val Loss: 4.304e-01 | Time: 11.25s
2025-08-15 03:31:14,077:INFO:Epoch: 4550/10000 | Train Loss: 4.267e-01 | Dynamic Loss: 4.267e-01 | Regularization Loss: 1.581e-07 | Val Loss: 4.290e-01 | Time: 4.65s
2025-08-15 03:31:14,078:INFO:New best model found at epoch 4550 with validation loss 4.290e-01. Saving...
2025-08-15 03:31:18,686:INFO:Epoch: 4600/10000 | Train Loss: 4.214e-01 | Dynamic Loss: 4.214e-01 | Regularization Loss: 1.559e-07 | Val Loss: 4.256e-01 | Time: 4.60s
2025-08-15 03:31:18,686:INFO:New best model found at epoch 4600 with validation loss 4.256e-01. Saving...
2025-08-15 03:31:23,210:INFO:Epoch: 4650/10000 | Train Loss: 4.212e-01 | Dynamic Loss: 4.212e-01 | Regularization Loss: 1.546e-07 | Val Loss: 4.248e-01 | Time: 4.52s
2025-08-15 03:31:23,211:INFO:New best model found at epoch 4650 with validation loss 4.248e-01. Saving...
2025-08-15 03:31:27,792:INFO:Epoch: 4700/10000 | Train Loss: 4.199e-01 | Dynamic Loss: 4.199e-01 | Regularization Loss: 1.542e-07 | Val Loss: 4.243e-01 | Time: 4.57s
2025-08-15 03:31:27,792:INFO:New best model found at epoch 4700 with validation loss 4.243e-01. Saving...
2025-08-15 03:31:39,155:INFO:Epoch: 4750/10000 | Train Loss: 4.206e-01 | Dynamic Loss: 4.206e-01 | Regularization Loss: 1.527e-07 | Val Loss: 4.242e-01 | Time: 11.35s
2025-08-15 03:31:39,155:INFO:New best model found at epoch 4750 with validation loss 4.242e-01. Saving...
2025-08-15 03:31:43,737:INFO:Epoch: 4800/10000 | Train Loss: 4.197e-01 | Dynamic Loss: 4.197e-01 | Regularization Loss: 1.514e-07 | Val Loss: 4.236e-01 | Time: 4.57s
2025-08-15 03:31:43,737:INFO:New best model found at epoch 4800 with validation loss 4.236e-01. Saving...
2025-08-15 03:31:48,332:INFO:Epoch: 4850/10000 | Train Loss: 4.177e-01 | Dynamic Loss: 4.177e-01 | Regularization Loss: 1.496e-07 | Val Loss: 4.238e-01 | Time: 4.59s
2025-08-15 03:31:52,937:INFO:Epoch: 4900/10000 | Train Loss: 4.161e-01 | Dynamic Loss: 4.161e-01 | Regularization Loss: 1.487e-07 | Val Loss: 4.227e-01 | Time: 4.61s
2025-08-15 03:31:52,938:INFO:New best model found at epoch 4900 with validation loss 4.227e-01. Saving...
2025-08-15 03:31:57,627:INFO:Epoch: 4950/10000 | Train Loss: 4.161e-01 | Dynamic Loss: 4.161e-01 | Regularization Loss: 1.465e-07 | Val Loss: 4.225e-01 | Time: 4.68s
2025-08-15 03:31:57,627:INFO:New best model found at epoch 4950 with validation loss 4.225e-01. Saving...
2025-08-15 03:32:02,269:INFO:Epoch: 5000/10000 | Train Loss: 4.153e-01 | Dynamic Loss: 4.153e-01 | Regularization Loss: 1.465e-07 | Val Loss: 4.223e-01 | Time: 4.63s
2025-08-15 03:32:02,269:INFO:New best model found at epoch 5000 with validation loss 4.223e-01. Saving...
2025-08-15 03:32:06,889:INFO:Epoch: 5050/10000 | Train Loss: 4.138e-01 | Dynamic Loss: 4.138e-01 | Regularization Loss: 1.453e-07 | Val Loss: 4.217e-01 | Time: 4.61s
2025-08-15 03:32:06,889:INFO:New best model found at epoch 5050 with validation loss 4.217e-01. Saving...
2025-08-15 03:32:11,467:INFO:Epoch: 5100/10000 | Train Loss: 4.123e-01 | Dynamic Loss: 4.123e-01 | Regularization Loss: 1.438e-07 | Val Loss: 4.210e-01 | Time: 4.57s
2025-08-15 03:32:11,467:INFO:New best model found at epoch 5100 with validation loss 4.210e-01. Saving...
2025-08-15 03:32:16,035:INFO:Epoch: 5150/10000 | Train Loss: 4.128e-01 | Dynamic Loss: 4.128e-01 | Regularization Loss: 1.410e-07 | Val Loss: 4.206e-01 | Time: 4.56s
2025-08-15 03:32:16,035:INFO:New best model found at epoch 5150 with validation loss 4.206e-01. Saving...
2025-08-15 03:32:23,927:INFO:Epoch: 5200/10000 | Train Loss: 4.097e-01 | Dynamic Loss: 4.097e-01 | Regularization Loss: 1.398e-07 | Val Loss: 4.195e-01 | Time: 7.88s
2025-08-15 03:32:23,927:INFO:New best model found at epoch 5200 with validation loss 4.195e-01. Saving...
2025-08-15 03:32:28,523:INFO:Epoch: 5250/10000 | Train Loss: 4.108e-01 | Dynamic Loss: 4.108e-01 | Regularization Loss: 1.384e-07 | Val Loss: 4.184e-01 | Time: 4.59s
2025-08-15 03:32:28,523:INFO:New best model found at epoch 5250 with validation loss 4.184e-01. Saving...
2025-08-15 03:32:33,141:INFO:Epoch: 5300/10000 | Train Loss: 4.100e-01 | Dynamic Loss: 4.100e-01 | Regularization Loss: 1.381e-07 | Val Loss: 4.176e-01 | Time: 4.61s
2025-08-15 03:32:33,141:INFO:New best model found at epoch 5300 with validation loss 4.176e-01. Saving...
2025-08-15 03:32:37,762:INFO:Epoch: 5350/10000 | Train Loss: 4.085e-01 | Dynamic Loss: 4.085e-01 | Regularization Loss: 1.361e-07 | Val Loss: 4.172e-01 | Time: 4.61s
2025-08-15 03:32:37,762:INFO:New best model found at epoch 5350 with validation loss 4.172e-01. Saving...
2025-08-15 03:32:42,383:INFO:Epoch: 5400/10000 | Train Loss: 4.078e-01 | Dynamic Loss: 4.078e-01 | Regularization Loss: 1.363e-07 | Val Loss: 4.166e-01 | Time: 4.61s
2025-08-15 03:32:42,383:INFO:New best model found at epoch 5400 with validation loss 4.166e-01. Saving...
2025-08-15 03:32:50,553:INFO:Epoch: 5450/10000 | Train Loss: 4.067e-01 | Dynamic Loss: 4.067e-01 | Regularization Loss: 1.352e-07 | Val Loss: 4.152e-01 | Time: 8.16s
2025-08-15 03:32:50,553:INFO:New best model found at epoch 5450 with validation loss 4.152e-01. Saving...
2025-08-15 03:32:55,176:INFO:Epoch: 5500/10000 | Train Loss: 4.075e-01 | Dynamic Loss: 4.075e-01 | Regularization Loss: 1.350e-07 | Val Loss: 4.161e-01 | Time: 4.61s
2025-08-15 03:32:59,719:INFO:Epoch: 5550/10000 | Train Loss: 4.062e-01 | Dynamic Loss: 4.062e-01 | Regularization Loss: 1.329e-07 | Val Loss: 4.146e-01 | Time: 4.54s
2025-08-15 03:32:59,719:INFO:New best model found at epoch 5550 with validation loss 4.146e-01. Saving...
2025-08-15 03:33:04,290:INFO:Epoch: 5600/10000 | Train Loss: 4.069e-01 | Dynamic Loss: 4.069e-01 | Regularization Loss: 1.323e-07 | Val Loss: 4.141e-01 | Time: 4.56s
2025-08-15 03:33:04,290:INFO:New best model found at epoch 5600 with validation loss 4.141e-01. Saving...
2025-08-15 03:33:08,871:INFO:Epoch: 5650/10000 | Train Loss: 4.047e-01 | Dynamic Loss: 4.047e-01 | Regularization Loss: 1.339e-07 | Val Loss: 4.140e-01 | Time: 4.57s
2025-08-15 03:33:08,871:INFO:New best model found at epoch 5650 with validation loss 4.140e-01. Saving...
2025-08-15 03:33:18,385:INFO:Epoch: 5700/10000 | Train Loss: 4.048e-01 | Dynamic Loss: 4.048e-01 | Regularization Loss: 1.319e-07 | Val Loss: 4.128e-01 | Time: 9.50s
2025-08-15 03:33:18,385:INFO:New best model found at epoch 5700 with validation loss 4.128e-01. Saving...
2025-08-15 03:33:23,023:INFO:Epoch: 5750/10000 | Train Loss: 4.034e-01 | Dynamic Loss: 4.034e-01 | Regularization Loss: 1.292e-07 | Val Loss: 4.123e-01 | Time: 4.63s
2025-08-15 03:33:23,023:INFO:New best model found at epoch 5750 with validation loss 4.123e-01. Saving...
2025-08-15 03:33:27,655:INFO:Epoch: 5800/10000 | Train Loss: 4.025e-01 | Dynamic Loss: 4.025e-01 | Regularization Loss: 1.299e-07 | Val Loss: 4.118e-01 | Time: 4.62s
2025-08-15 03:33:27,655:INFO:New best model found at epoch 5800 with validation loss 4.118e-01. Saving...
2025-08-15 03:33:32,213:INFO:Epoch: 5850/10000 | Train Loss: 4.017e-01 | Dynamic Loss: 4.017e-01 | Regularization Loss: 1.295e-07 | Val Loss: 4.110e-01 | Time: 4.55s
2025-08-15 03:33:32,213:INFO:New best model found at epoch 5850 with validation loss 4.110e-01. Saving...
2025-08-15 03:33:37,479:INFO:Epoch: 5900/10000 | Train Loss: 4.004e-01 | Dynamic Loss: 4.004e-01 | Regularization Loss: 1.264e-07 | Val Loss: 4.102e-01 | Time: 5.26s
2025-08-15 03:33:37,480:INFO:New best model found at epoch 5900 with validation loss 4.102e-01. Saving...
2025-08-15 03:33:42,166:INFO:Epoch: 5950/10000 | Train Loss: 4.003e-01 | Dynamic Loss: 4.003e-01 | Regularization Loss: 1.253e-07 | Val Loss: 4.100e-01 | Time: 4.68s
2025-08-15 03:33:42,166:INFO:New best model found at epoch 5950 with validation loss 4.100e-01. Saving...
2025-08-15 03:33:46,845:INFO:Epoch: 6000/10000 | Train Loss: 3.976e-01 | Dynamic Loss: 3.976e-01 | Regularization Loss: 1.226e-07 | Val Loss: 4.084e-01 | Time: 4.67s
2025-08-15 03:33:46,845:INFO:New best model found at epoch 6000 with validation loss 4.084e-01. Saving...
2025-08-15 03:33:51,452:INFO:Epoch: 6050/10000 | Train Loss: 3.966e-01 | Dynamic Loss: 3.966e-01 | Regularization Loss: 1.221e-07 | Val Loss: 4.073e-01 | Time: 4.60s
2025-08-15 03:33:51,452:INFO:New best model found at epoch 6050 with validation loss 4.073e-01. Saving...
2025-08-15 03:33:56,075:INFO:Epoch: 6100/10000 | Train Loss: 3.939e-01 | Dynamic Loss: 3.939e-01 | Regularization Loss: 1.209e-07 | Val Loss: 4.060e-01 | Time: 4.61s
2025-08-15 03:33:56,076:INFO:New best model found at epoch 6100 with validation loss 4.060e-01. Saving...
2025-08-15 03:34:04,585:INFO:Epoch: 6150/10000 | Train Loss: 3.939e-01 | Dynamic Loss: 3.939e-01 | Regularization Loss: 1.191e-07 | Val Loss: 4.054e-01 | Time: 8.50s
2025-08-15 03:34:04,585:INFO:New best model found at epoch 6150 with validation loss 4.054e-01. Saving...
2025-08-15 03:34:09,233:INFO:Epoch: 6200/10000 | Train Loss: 3.934e-01 | Dynamic Loss: 3.934e-01 | Regularization Loss: 1.172e-07 | Val Loss: 4.045e-01 | Time: 4.64s
2025-08-15 03:34:09,233:INFO:New best model found at epoch 6200 with validation loss 4.045e-01. Saving...
2025-08-15 03:34:13,917:INFO:Epoch: 6250/10000 | Train Loss: 3.915e-01 | Dynamic Loss: 3.915e-01 | Regularization Loss: 1.156e-07 | Val Loss: 4.023e-01 | Time: 4.67s
2025-08-15 03:34:13,917:INFO:New best model found at epoch 6250 with validation loss 4.023e-01. Saving...
2025-08-15 03:34:18,536:INFO:Epoch: 6300/10000 | Train Loss: 3.909e-01 | Dynamic Loss: 3.909e-01 | Regularization Loss: 1.156e-07 | Val Loss: 4.016e-01 | Time: 4.61s
2025-08-15 03:34:18,536:INFO:New best model found at epoch 6300 with validation loss 4.016e-01. Saving...
2025-08-15 03:34:23,132:INFO:Epoch: 6350/10000 | Train Loss: 3.902e-01 | Dynamic Loss: 3.902e-01 | Regularization Loss: 1.157e-07 | Val Loss: 4.012e-01 | Time: 4.59s
2025-08-15 03:34:23,132:INFO:New best model found at epoch 6350 with validation loss 4.012e-01. Saving...
2025-08-15 03:34:30,508:INFO:Epoch: 6400/10000 | Train Loss: 3.908e-01 | Dynamic Loss: 3.908e-01 | Regularization Loss: 1.143e-07 | Val Loss: 4.002e-01 | Time: 7.37s
2025-08-15 03:34:30,508:INFO:New best model found at epoch 6400 with validation loss 4.002e-01. Saving...
2025-08-15 03:34:35,111:INFO:Epoch: 6450/10000 | Train Loss: 3.900e-01 | Dynamic Loss: 3.900e-01 | Regularization Loss: 1.138e-07 | Val Loss: 3.999e-01 | Time: 4.59s
2025-08-15 03:34:35,111:INFO:New best model found at epoch 6450 with validation loss 3.999e-01. Saving...
2025-08-15 03:34:39,770:INFO:Epoch: 6500/10000 | Train Loss: 3.894e-01 | Dynamic Loss: 3.894e-01 | Regularization Loss: 1.121e-07 | Val Loss: 3.995e-01 | Time: 4.65s
2025-08-15 03:34:39,770:INFO:New best model found at epoch 6500 with validation loss 3.995e-01. Saving...
2025-08-15 03:34:44,382:INFO:Epoch: 6550/10000 | Train Loss: 3.866e-01 | Dynamic Loss: 3.866e-01 | Regularization Loss: 1.126e-07 | Val Loss: 3.983e-01 | Time: 4.60s
2025-08-15 03:34:44,382:INFO:New best model found at epoch 6550 with validation loss 3.983e-01. Saving...
2025-08-15 03:34:49,048:INFO:Epoch: 6600/10000 | Train Loss: 3.891e-01 | Dynamic Loss: 3.891e-01 | Regularization Loss: 1.096e-07 | Val Loss: 3.980e-01 | Time: 4.66s
2025-08-15 03:34:49,048:INFO:New best model found at epoch 6600 with validation loss 3.980e-01. Saving...
2025-08-15 03:34:55,667:INFO:Epoch: 6650/10000 | Train Loss: 3.876e-01 | Dynamic Loss: 3.876e-01 | Regularization Loss: 1.108e-07 | Val Loss: 3.979e-01 | Time: 6.61s
2025-08-15 03:34:55,667:INFO:New best model found at epoch 6650 with validation loss 3.979e-01. Saving...
2025-08-15 03:35:00,255:INFO:Epoch: 6700/10000 | Train Loss: 3.874e-01 | Dynamic Loss: 3.874e-01 | Regularization Loss: 1.099e-07 | Val Loss: 3.973e-01 | Time: 4.58s
2025-08-15 03:35:00,255:INFO:New best model found at epoch 6700 with validation loss 3.973e-01. Saving...
2025-08-15 03:35:04,876:INFO:Epoch: 6750/10000 | Train Loss: 3.866e-01 | Dynamic Loss: 3.866e-01 | Regularization Loss: 1.090e-07 | Val Loss: 3.965e-01 | Time: 4.61s
2025-08-15 03:35:04,876:INFO:New best model found at epoch 6750 with validation loss 3.965e-01. Saving...
2025-08-15 03:35:09,513:INFO:Epoch: 6800/10000 | Train Loss: 3.863e-01 | Dynamic Loss: 3.863e-01 | Regularization Loss: 1.099e-07 | Val Loss: 3.961e-01 | Time: 4.63s
2025-08-15 03:35:09,513:INFO:New best model found at epoch 6800 with validation loss 3.961e-01. Saving...
2025-08-15 03:35:14,161:INFO:Epoch: 6850/10000 | Train Loss: 3.848e-01 | Dynamic Loss: 3.848e-01 | Regularization Loss: 1.072e-07 | Val Loss: 3.957e-01 | Time: 4.64s
2025-08-15 03:35:14,161:INFO:New best model found at epoch 6850 with validation loss 3.957e-01. Saving...
2025-08-15 03:35:25,062:INFO:Epoch: 6900/10000 | Train Loss: 3.855e-01 | Dynamic Loss: 3.855e-01 | Regularization Loss: 1.094e-07 | Val Loss: 3.959e-01 | Time: 10.89s
2025-08-15 03:35:29,685:INFO:Epoch: 6950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.62s
2025-08-15 03:35:34,271:INFO:Epoch: 7000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.59s
2025-08-15 03:35:38,916:INFO:Epoch: 7050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.64s
2025-08-15 03:35:43,504:INFO:Epoch: 7100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.59s
2025-08-15 03:35:54,152:INFO:Epoch: 7150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 10.65s
2025-08-15 03:35:58,864:INFO:Epoch: 7200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.71s
2025-08-15 03:36:03,528:INFO:Epoch: 7250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.66s
2025-08-15 03:36:08,056:INFO:Epoch: 7300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.53s
2025-08-15 03:36:13,329:INFO:Epoch: 7350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.27s
2025-08-15 03:36:18,021:INFO:Epoch: 7400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.69s
2025-08-15 03:36:22,691:INFO:Epoch: 7450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.67s
2025-08-15 03:36:27,344:INFO:Epoch: 7500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.65s
2025-08-15 03:36:31,910:INFO:Epoch: 7550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.57s
2025-08-15 03:36:36,590:INFO:Epoch: 7600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.68s
2025-08-15 03:36:41,282:INFO:Epoch: 7650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.69s
2025-08-15 03:36:45,949:INFO:Epoch: 7700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.67s
2025-08-15 03:36:50,647:INFO:Epoch: 7750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.70s
2025-08-15 03:36:55,261:INFO:Epoch: 7800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.61s
2025-08-15 03:37:06,557:INFO:Epoch: 7850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 11.30s
2025-08-15 03:37:11,260:INFO:Epoch: 7900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.70s
2025-08-15 03:37:15,951:INFO:Epoch: 7950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.69s
2025-08-15 03:37:20,627:INFO:Epoch: 8000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.68s
2025-08-15 03:37:25,138:INFO:Epoch: 8050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.51s
2025-08-15 03:37:36,457:INFO:Epoch: 8100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 11.32s
2025-08-15 03:37:41,189:INFO:Epoch: 8150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.73s
2025-08-15 03:37:45,903:INFO:Epoch: 8200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.71s
2025-08-15 03:37:50,588:INFO:Epoch: 8250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.68s
2025-08-15 03:37:55,093:INFO:Epoch: 8300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.50s
2025-08-15 03:38:06,601:INFO:Epoch: 8350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 11.51s
2025-08-15 03:38:11,316:INFO:Epoch: 8400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.71s
2025-08-15 03:38:16,018:INFO:Epoch: 8450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.70s
2025-08-15 03:38:20,716:INFO:Epoch: 8500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.70s
2025-08-15 03:38:25,410:INFO:Epoch: 8550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.69s
2025-08-15 03:38:30,064:INFO:Epoch: 8600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.65s
2025-08-15 03:38:34,734:INFO:Epoch: 8650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.67s
2025-08-15 03:38:39,427:INFO:Epoch: 8700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.69s
2025-08-15 03:38:44,100:INFO:Epoch: 8750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.67s
2025-08-15 03:38:48,831:INFO:Epoch: 8800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.73s
2025-08-15 03:38:53,502:INFO:Epoch: 8850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.67s
2025-08-15 03:38:58,258:INFO:Epoch: 8900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.76s
2025-08-15 03:39:02,946:INFO:Epoch: 8950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.69s
2025-08-15 03:39:07,577:INFO:Epoch: 9000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.63s
2025-08-15 03:39:12,296:INFO:Epoch: 9050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.72s
2025-08-15 03:39:16,968:INFO:Epoch: 9100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.67s
2025-08-15 03:39:21,651:INFO:Epoch: 9150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.68s
2025-08-15 03:39:26,320:INFO:Epoch: 9200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.67s
2025-08-15 03:39:31,007:INFO:Epoch: 9250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.69s
2025-08-15 03:39:41,464:INFO:Epoch: 9300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 10.46s
2025-08-15 03:39:46,147:INFO:Epoch: 9350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.68s
2025-08-15 03:39:50,797:INFO:Epoch: 9400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.65s
2025-08-15 03:39:55,517:INFO:Epoch: 9450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.72s
2025-08-15 03:40:00,184:INFO:Epoch: 9500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.67s
2025-08-15 03:40:11,532:INFO:Epoch: 9550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 11.35s
2025-08-15 03:40:16,232:INFO:Epoch: 9600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.70s
2025-08-15 03:40:20,925:INFO:Epoch: 9650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.69s
2025-08-15 03:40:25,682:INFO:Epoch: 9700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.76s
2025-08-15 03:40:30,589:INFO:Epoch: 9750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.91s
2025-08-15 03:40:35,280:INFO:Epoch: 9800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.69s
2025-08-15 03:40:39,995:INFO:Epoch: 9850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.71s
2025-08-15 03:40:44,697:INFO:Epoch: 9900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.70s
2025-08-15 03:40:49,455:INFO:Epoch: 9950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.76s
2025-08-15 03:40:56,448:INFO:Epoch: 10000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 6.99s
