2025-08-15 03:04:06,114:INFO:Created DataLoaders with 2994 training samples and 998 validation samples.
2025-08-15 03:04:06,751:INFO:model params: 479490
2025-08-15 03:04:07,450:INFO:Epoch: 0/10000 | Train Loss: 5.094e+00 | Dynamic Loss: 5.094e+00 | Regularization Loss: 6.195e-21 | Val Loss: 3.413e+00 | Time: 0.70s
2025-08-15 03:04:07,450:INFO:New best model found at epoch 0 with validation loss 3.413e+00. Saving...
2025-08-15 03:04:11,937:INFO:Epoch: 50/10000 | Train Loss: 9.023e-01 | Dynamic Loss: 9.023e-01 | Regularization Loss: 2.074e-17 | Val Loss: 9.511e-01 | Time: 4.42s
2025-08-15 03:04:11,937:INFO:New best model found at epoch 50 with validation loss 9.511e-01. Saving...
2025-08-15 03:04:16,241:INFO:Epoch: 100/10000 | Train Loss: 7.129e-01 | Dynamic Loss: 7.129e-01 | Regularization Loss: 1.892e-11 | Val Loss: 7.449e-01 | Time: 4.29s
2025-08-15 03:04:16,241:INFO:New best model found at epoch 100 with validation loss 7.449e-01. Saving...
2025-08-15 03:04:20,729:INFO:Epoch: 150/10000 | Train Loss: 6.426e-01 | Dynamic Loss: 6.426e-01 | Regularization Loss: 5.461e-07 | Val Loss: 6.645e-01 | Time: 4.48s
2025-08-15 03:04:20,729:INFO:New best model found at epoch 150 with validation loss 6.645e-01. Saving...
2025-08-15 03:04:25,197:INFO:Epoch: 200/10000 | Train Loss: 6.091e-01 | Dynamic Loss: 6.091e-01 | Regularization Loss: 6.102e-07 | Val Loss: 6.244e-01 | Time: 4.46s
2025-08-15 03:04:25,197:INFO:New best model found at epoch 200 with validation loss 6.244e-01. Saving...
2025-08-15 03:04:29,648:INFO:Epoch: 250/10000 | Train Loss: 5.894e-01 | Dynamic Loss: 5.894e-01 | Regularization Loss: 5.944e-07 | Val Loss: 6.002e-01 | Time: 4.44s
2025-08-15 03:04:29,648:INFO:New best model found at epoch 250 with validation loss 6.002e-01. Saving...
2025-08-15 03:04:34,069:INFO:Epoch: 300/10000 | Train Loss: 5.808e-01 | Dynamic Loss: 5.808e-01 | Regularization Loss: 5.771e-07 | Val Loss: 5.843e-01 | Time: 4.41s
2025-08-15 03:04:34,069:INFO:New best model found at epoch 300 with validation loss 5.843e-01. Saving...
2025-08-15 03:04:38,501:INFO:Epoch: 350/10000 | Train Loss: 5.716e-01 | Dynamic Loss: 5.716e-01 | Regularization Loss: 5.564e-07 | Val Loss: 5.730e-01 | Time: 4.42s
2025-08-15 03:04:38,502:INFO:New best model found at epoch 350 with validation loss 5.730e-01. Saving...
2025-08-15 03:04:42,933:INFO:Epoch: 400/10000 | Train Loss: 5.636e-01 | Dynamic Loss: 5.636e-01 | Regularization Loss: 5.389e-07 | Val Loss: 5.645e-01 | Time: 4.42s
2025-08-15 03:04:42,933:INFO:New best model found at epoch 400 with validation loss 5.645e-01. Saving...
2025-08-15 03:04:52,224:INFO:Epoch: 450/10000 | Train Loss: 5.592e-01 | Dynamic Loss: 5.592e-01 | Regularization Loss: 5.230e-07 | Val Loss: 5.584e-01 | Time: 9.28s
2025-08-15 03:04:52,224:INFO:New best model found at epoch 450 with validation loss 5.584e-01. Saving...
2025-08-15 03:04:56,696:INFO:Epoch: 500/10000 | Train Loss: 5.572e-01 | Dynamic Loss: 5.572e-01 | Regularization Loss: 5.072e-07 | Val Loss: 5.514e-01 | Time: 4.46s
2025-08-15 03:04:56,696:INFO:New best model found at epoch 500 with validation loss 5.514e-01. Saving...
2025-08-15 03:05:01,182:INFO:Epoch: 550/10000 | Train Loss: 5.514e-01 | Dynamic Loss: 5.514e-01 | Regularization Loss: 4.934e-07 | Val Loss: 5.460e-01 | Time: 4.48s
2025-08-15 03:05:01,183:INFO:New best model found at epoch 550 with validation loss 5.460e-01. Saving...
2025-08-15 03:05:05,645:INFO:Epoch: 600/10000 | Train Loss: 5.509e-01 | Dynamic Loss: 5.509e-01 | Regularization Loss: 4.785e-07 | Val Loss: 5.446e-01 | Time: 4.45s
2025-08-15 03:05:05,645:INFO:New best model found at epoch 600 with validation loss 5.446e-01. Saving...
2025-08-15 03:05:12,718:INFO:Epoch: 650/10000 | Train Loss: 5.428e-01 | Dynamic Loss: 5.428e-01 | Regularization Loss: 4.643e-07 | Val Loss: 5.361e-01 | Time: 7.06s
2025-08-15 03:05:12,718:INFO:New best model found at epoch 650 with validation loss 5.361e-01. Saving...
2025-08-15 03:05:17,283:INFO:Epoch: 700/10000 | Train Loss: 5.434e-01 | Dynamic Loss: 5.434e-01 | Regularization Loss: 4.501e-07 | Val Loss: 5.320e-01 | Time: 4.56s
2025-08-15 03:05:17,284:INFO:New best model found at epoch 700 with validation loss 5.320e-01. Saving...
2025-08-15 03:05:21,858:INFO:Epoch: 750/10000 | Train Loss: 5.351e-01 | Dynamic Loss: 5.351e-01 | Regularization Loss: 4.374e-07 | Val Loss: 5.263e-01 | Time: 4.57s
2025-08-15 03:05:21,858:INFO:New best model found at epoch 750 with validation loss 5.263e-01. Saving...
2025-08-15 03:05:26,432:INFO:Epoch: 800/10000 | Train Loss: 5.344e-01 | Dynamic Loss: 5.344e-01 | Regularization Loss: 4.277e-07 | Val Loss: 5.244e-01 | Time: 4.56s
2025-08-15 03:05:26,432:INFO:New best model found at epoch 800 with validation loss 5.244e-01. Saving...
2025-08-15 03:05:30,885:INFO:Epoch: 850/10000 | Train Loss: 5.310e-01 | Dynamic Loss: 5.310e-01 | Regularization Loss: 4.152e-07 | Val Loss: 5.202e-01 | Time: 4.44s
2025-08-15 03:05:30,885:INFO:New best model found at epoch 850 with validation loss 5.202e-01. Saving...
2025-08-15 03:05:40,567:INFO:Epoch: 900/10000 | Train Loss: 5.267e-01 | Dynamic Loss: 5.267e-01 | Regularization Loss: 4.067e-07 | Val Loss: 5.160e-01 | Time: 9.67s
2025-08-15 03:05:40,567:INFO:New best model found at epoch 900 with validation loss 5.160e-01. Saving...
2025-08-15 03:05:45,092:INFO:Epoch: 950/10000 | Train Loss: 5.222e-01 | Dynamic Loss: 5.222e-01 | Regularization Loss: 3.940e-07 | Val Loss: 5.126e-01 | Time: 4.52s
2025-08-15 03:05:45,092:INFO:New best model found at epoch 950 with validation loss 5.126e-01. Saving...
2025-08-15 03:05:49,596:INFO:Epoch: 1000/10000 | Train Loss: 5.231e-01 | Dynamic Loss: 5.231e-01 | Regularization Loss: 3.865e-07 | Val Loss: 5.120e-01 | Time: 4.50s
2025-08-15 03:05:49,597:INFO:New best model found at epoch 1000 with validation loss 5.120e-01. Saving...
2025-08-15 03:05:54,093:INFO:Epoch: 1050/10000 | Train Loss: 5.204e-01 | Dynamic Loss: 5.204e-01 | Regularization Loss: 3.747e-07 | Val Loss: 5.078e-01 | Time: 4.49s
2025-08-15 03:05:54,093:INFO:New best model found at epoch 1050 with validation loss 5.078e-01. Saving...
2025-08-15 03:05:58,586:INFO:Epoch: 1100/10000 | Train Loss: 5.151e-01 | Dynamic Loss: 5.151e-01 | Regularization Loss: 3.659e-07 | Val Loss: 5.044e-01 | Time: 4.48s
2025-08-15 03:05:58,586:INFO:New best model found at epoch 1100 with validation loss 5.044e-01. Saving...
2025-08-15 03:06:08,877:INFO:Epoch: 1150/10000 | Train Loss: 5.139e-01 | Dynamic Loss: 5.139e-01 | Regularization Loss: 3.582e-07 | Val Loss: 5.025e-01 | Time: 10.28s
2025-08-15 03:06:08,877:INFO:New best model found at epoch 1150 with validation loss 5.025e-01. Saving...
2025-08-15 03:06:13,403:INFO:Epoch: 1200/10000 | Train Loss: 5.105e-01 | Dynamic Loss: 5.105e-01 | Regularization Loss: 3.501e-07 | Val Loss: 4.990e-01 | Time: 4.52s
2025-08-15 03:06:13,404:INFO:New best model found at epoch 1200 with validation loss 4.990e-01. Saving...
2025-08-15 03:06:17,875:INFO:Epoch: 1250/10000 | Train Loss: 5.097e-01 | Dynamic Loss: 5.097e-01 | Regularization Loss: 3.451e-07 | Val Loss: 4.970e-01 | Time: 4.46s
2025-08-15 03:06:17,875:INFO:New best model found at epoch 1250 with validation loss 4.970e-01. Saving...
2025-08-15 03:06:22,430:INFO:Epoch: 1300/10000 | Train Loss: 5.085e-01 | Dynamic Loss: 5.085e-01 | Regularization Loss: 3.371e-07 | Val Loss: 4.949e-01 | Time: 4.55s
2025-08-15 03:06:22,430:INFO:New best model found at epoch 1300 with validation loss 4.949e-01. Saving...
2025-08-15 03:06:26,896:INFO:Epoch: 1350/10000 | Train Loss: 5.067e-01 | Dynamic Loss: 5.067e-01 | Regularization Loss: 3.317e-07 | Val Loss: 4.937e-01 | Time: 4.46s
2025-08-15 03:06:26,896:INFO:New best model found at epoch 1350 with validation loss 4.937e-01. Saving...
2025-08-15 03:06:31,427:INFO:Epoch: 1400/10000 | Train Loss: 5.036e-01 | Dynamic Loss: 5.036e-01 | Regularization Loss: 3.235e-07 | Val Loss: 4.914e-01 | Time: 4.52s
2025-08-15 03:06:31,427:INFO:New best model found at epoch 1400 with validation loss 4.914e-01. Saving...
2025-08-15 03:06:35,946:INFO:Epoch: 1450/10000 | Train Loss: 5.016e-01 | Dynamic Loss: 5.016e-01 | Regularization Loss: 3.181e-07 | Val Loss: 4.881e-01 | Time: 4.51s
2025-08-15 03:06:35,946:INFO:New best model found at epoch 1450 with validation loss 4.881e-01. Saving...
2025-08-15 03:06:40,402:INFO:Epoch: 1500/10000 | Train Loss: 4.994e-01 | Dynamic Loss: 4.994e-01 | Regularization Loss: 3.116e-07 | Val Loss: 4.866e-01 | Time: 4.45s
2025-08-15 03:06:40,402:INFO:New best model found at epoch 1500 with validation loss 4.866e-01. Saving...
2025-08-15 03:06:48,941:INFO:Epoch: 1550/10000 | Train Loss: 4.949e-01 | Dynamic Loss: 4.949e-01 | Regularization Loss: 3.072e-07 | Val Loss: 4.844e-01 | Time: 8.53s
2025-08-15 03:06:48,942:INFO:New best model found at epoch 1550 with validation loss 4.844e-01. Saving...
2025-08-15 03:06:53,532:INFO:Epoch: 1600/10000 | Train Loss: 4.954e-01 | Dynamic Loss: 4.954e-01 | Regularization Loss: 3.018e-07 | Val Loss: 4.831e-01 | Time: 4.58s
2025-08-15 03:06:53,532:INFO:New best model found at epoch 1600 with validation loss 4.831e-01. Saving...
2025-08-15 03:06:58,053:INFO:Epoch: 1650/10000 | Train Loss: 4.936e-01 | Dynamic Loss: 4.936e-01 | Regularization Loss: 2.976e-07 | Val Loss: 4.818e-01 | Time: 4.51s
2025-08-15 03:06:58,054:INFO:New best model found at epoch 1650 with validation loss 4.818e-01. Saving...
2025-08-15 03:07:03,688:INFO:Epoch: 1700/10000 | Train Loss: 4.919e-01 | Dynamic Loss: 4.919e-01 | Regularization Loss: 2.919e-07 | Val Loss: 4.794e-01 | Time: 5.62s
2025-08-15 03:07:03,688:INFO:New best model found at epoch 1700 with validation loss 4.794e-01. Saving...
2025-08-15 03:07:08,208:INFO:Epoch: 1750/10000 | Train Loss: 4.903e-01 | Dynamic Loss: 4.903e-01 | Regularization Loss: 2.873e-07 | Val Loss: 4.799e-01 | Time: 4.51s
2025-08-15 03:07:12,712:INFO:Epoch: 1800/10000 | Train Loss: 4.884e-01 | Dynamic Loss: 4.884e-01 | Regularization Loss: 2.830e-07 | Val Loss: 4.772e-01 | Time: 4.50s
2025-08-15 03:07:12,712:INFO:New best model found at epoch 1800 with validation loss 4.772e-01. Saving...
2025-08-15 03:07:17,211:INFO:Epoch: 1850/10000 | Train Loss: 4.870e-01 | Dynamic Loss: 4.870e-01 | Regularization Loss: 2.777e-07 | Val Loss: 4.746e-01 | Time: 4.49s
2025-08-15 03:07:17,211:INFO:New best model found at epoch 1850 with validation loss 4.746e-01. Saving...
2025-08-15 03:07:25,858:INFO:Epoch: 1900/10000 | Train Loss: 4.848e-01 | Dynamic Loss: 4.848e-01 | Regularization Loss: 2.736e-07 | Val Loss: 4.744e-01 | Time: 8.64s
2025-08-15 03:07:25,858:INFO:New best model found at epoch 1900 with validation loss 4.744e-01. Saving...
2025-08-15 03:07:30,517:INFO:Epoch: 1950/10000 | Train Loss: 4.826e-01 | Dynamic Loss: 4.826e-01 | Regularization Loss: 2.681e-07 | Val Loss: 4.725e-01 | Time: 4.65s
2025-08-15 03:07:30,517:INFO:New best model found at epoch 1950 with validation loss 4.725e-01. Saving...
2025-08-15 03:07:35,162:INFO:Epoch: 2000/10000 | Train Loss: 4.798e-01 | Dynamic Loss: 4.798e-01 | Regularization Loss: 2.641e-07 | Val Loss: 4.705e-01 | Time: 4.64s
2025-08-15 03:07:35,162:INFO:New best model found at epoch 2000 with validation loss 4.705e-01. Saving...
2025-08-15 03:07:39,707:INFO:Epoch: 2050/10000 | Train Loss: 4.800e-01 | Dynamic Loss: 4.800e-01 | Regularization Loss: 2.600e-07 | Val Loss: 4.694e-01 | Time: 4.54s
2025-08-15 03:07:39,707:INFO:New best model found at epoch 2050 with validation loss 4.694e-01. Saving...
2025-08-15 03:07:47,468:INFO:Epoch: 2100/10000 | Train Loss: 4.753e-01 | Dynamic Loss: 4.753e-01 | Regularization Loss: 2.545e-07 | Val Loss: 4.675e-01 | Time: 7.75s
2025-08-15 03:07:47,468:INFO:New best model found at epoch 2100 with validation loss 4.675e-01. Saving...
2025-08-15 03:07:52,042:INFO:Epoch: 2150/10000 | Train Loss: 4.755e-01 | Dynamic Loss: 4.755e-01 | Regularization Loss: 2.490e-07 | Val Loss: 4.662e-01 | Time: 4.56s
2025-08-15 03:07:52,042:INFO:New best model found at epoch 2150 with validation loss 4.662e-01. Saving...
2025-08-15 03:07:56,597:INFO:Epoch: 2200/10000 | Train Loss: 4.729e-01 | Dynamic Loss: 4.729e-01 | Regularization Loss: 2.437e-07 | Val Loss: 4.642e-01 | Time: 4.55s
2025-08-15 03:07:56,597:INFO:New best model found at epoch 2200 with validation loss 4.642e-01. Saving...
2025-08-15 03:08:01,177:INFO:Epoch: 2250/10000 | Train Loss: 4.693e-01 | Dynamic Loss: 4.693e-01 | Regularization Loss: 2.384e-07 | Val Loss: 4.624e-01 | Time: 4.57s
2025-08-15 03:08:01,177:INFO:New best model found at epoch 2250 with validation loss 4.624e-01. Saving...
2025-08-15 03:08:05,719:INFO:Epoch: 2300/10000 | Train Loss: 4.666e-01 | Dynamic Loss: 4.666e-01 | Regularization Loss: 2.347e-07 | Val Loss: 4.605e-01 | Time: 4.53s
2025-08-15 03:08:05,719:INFO:New best model found at epoch 2300 with validation loss 4.605e-01. Saving...
2025-08-15 03:08:13,287:INFO:Epoch: 2350/10000 | Train Loss: 4.641e-01 | Dynamic Loss: 4.641e-01 | Regularization Loss: 2.297e-07 | Val Loss: 4.603e-01 | Time: 7.56s
2025-08-15 03:08:13,287:INFO:New best model found at epoch 2350 with validation loss 4.603e-01. Saving...
2025-08-15 03:08:17,940:INFO:Epoch: 2400/10000 | Train Loss: 4.657e-01 | Dynamic Loss: 4.657e-01 | Regularization Loss: 2.270e-07 | Val Loss: 4.575e-01 | Time: 4.64s
2025-08-15 03:08:17,940:INFO:New best model found at epoch 2400 with validation loss 4.575e-01. Saving...
2025-08-15 03:08:22,510:INFO:Epoch: 2450/10000 | Train Loss: 4.655e-01 | Dynamic Loss: 4.655e-01 | Regularization Loss: 2.269e-07 | Val Loss: 4.605e-01 | Time: 4.56s
2025-08-15 03:08:27,036:INFO:Epoch: 2500/10000 | Train Loss: 4.618e-01 | Dynamic Loss: 4.618e-01 | Regularization Loss: 2.226e-07 | Val Loss: 4.562e-01 | Time: 4.53s
2025-08-15 03:08:27,036:INFO:New best model found at epoch 2500 with validation loss 4.562e-01. Saving...
2025-08-15 03:08:31,973:INFO:Epoch: 2550/10000 | Train Loss: 4.601e-01 | Dynamic Loss: 4.601e-01 | Regularization Loss: 2.201e-07 | Val Loss: 4.576e-01 | Time: 4.93s
2025-08-15 03:08:36,514:INFO:Epoch: 2600/10000 | Train Loss: 4.593e-01 | Dynamic Loss: 4.593e-01 | Regularization Loss: 2.170e-07 | Val Loss: 4.556e-01 | Time: 4.54s
2025-08-15 03:08:36,515:INFO:New best model found at epoch 2600 with validation loss 4.556e-01. Saving...
2025-08-15 03:08:41,058:INFO:Epoch: 2650/10000 | Train Loss: 4.598e-01 | Dynamic Loss: 4.598e-01 | Regularization Loss: 2.156e-07 | Val Loss: 4.551e-01 | Time: 4.53s
2025-08-15 03:08:41,058:INFO:New best model found at epoch 2650 with validation loss 4.551e-01. Saving...
2025-08-15 03:08:46,069:INFO:Epoch: 2700/10000 | Train Loss: 4.588e-01 | Dynamic Loss: 4.588e-01 | Regularization Loss: 2.135e-07 | Val Loss: 4.531e-01 | Time: 5.00s
2025-08-15 03:08:46,069:INFO:New best model found at epoch 2700 with validation loss 4.531e-01. Saving...
2025-08-15 03:08:55,367:INFO:Epoch: 2750/10000 | Train Loss: 4.561e-01 | Dynamic Loss: 4.561e-01 | Regularization Loss: 2.112e-07 | Val Loss: 4.527e-01 | Time: 9.29s
2025-08-15 03:08:55,367:INFO:New best model found at epoch 2750 with validation loss 4.527e-01. Saving...
2025-08-15 03:08:59,968:INFO:Epoch: 2800/10000 | Train Loss: 4.552e-01 | Dynamic Loss: 4.552e-01 | Regularization Loss: 2.098e-07 | Val Loss: 4.519e-01 | Time: 4.59s
2025-08-15 03:08:59,968:INFO:New best model found at epoch 2800 with validation loss 4.519e-01. Saving...
2025-08-15 03:09:04,513:INFO:Epoch: 2850/10000 | Train Loss: 4.557e-01 | Dynamic Loss: 4.557e-01 | Regularization Loss: 2.071e-07 | Val Loss: 4.537e-01 | Time: 4.54s
2025-08-15 03:09:09,126:INFO:Epoch: 2900/10000 | Train Loss: 4.539e-01 | Dynamic Loss: 4.539e-01 | Regularization Loss: 2.052e-07 | Val Loss: 4.502e-01 | Time: 4.61s
2025-08-15 03:09:09,126:INFO:New best model found at epoch 2900 with validation loss 4.502e-01. Saving...
2025-08-15 03:09:13,695:INFO:Epoch: 2950/10000 | Train Loss: 4.543e-01 | Dynamic Loss: 4.543e-01 | Regularization Loss: 2.031e-07 | Val Loss: 4.492e-01 | Time: 4.56s
2025-08-15 03:09:13,695:INFO:New best model found at epoch 2950 with validation loss 4.492e-01. Saving...
2025-08-15 03:09:18,202:INFO:Epoch: 3000/10000 | Train Loss: 4.526e-01 | Dynamic Loss: 4.526e-01 | Regularization Loss: 1.998e-07 | Val Loss: 4.480e-01 | Time: 4.50s
2025-08-15 03:09:18,202:INFO:New best model found at epoch 3000 with validation loss 4.480e-01. Saving...
2025-08-15 03:09:22,821:INFO:Epoch: 3050/10000 | Train Loss: 4.514e-01 | Dynamic Loss: 4.514e-01 | Regularization Loss: 1.987e-07 | Val Loss: 4.486e-01 | Time: 4.61s
2025-08-15 03:09:31,548:INFO:Epoch: 3100/10000 | Train Loss: 4.502e-01 | Dynamic Loss: 4.502e-01 | Regularization Loss: 1.959e-07 | Val Loss: 4.469e-01 | Time: 8.73s
2025-08-15 03:09:31,548:INFO:New best model found at epoch 3100 with validation loss 4.469e-01. Saving...
2025-08-15 03:09:36,174:INFO:Epoch: 3150/10000 | Train Loss: 4.495e-01 | Dynamic Loss: 4.495e-01 | Regularization Loss: 1.945e-07 | Val Loss: 4.462e-01 | Time: 4.62s
2025-08-15 03:09:36,174:INFO:New best model found at epoch 3150 with validation loss 4.462e-01. Saving...
2025-08-15 03:09:40,855:INFO:Epoch: 3200/10000 | Train Loss: 4.483e-01 | Dynamic Loss: 4.483e-01 | Regularization Loss: 1.925e-07 | Val Loss: 4.456e-01 | Time: 4.67s
2025-08-15 03:09:40,855:INFO:New best model found at epoch 3200 with validation loss 4.456e-01. Saving...
2025-08-15 03:09:45,417:INFO:Epoch: 3250/10000 | Train Loss: 4.477e-01 | Dynamic Loss: 4.477e-01 | Regularization Loss: 1.907e-07 | Val Loss: 4.456e-01 | Time: 4.55s
2025-08-15 03:09:45,417:INFO:New best model found at epoch 3250 with validation loss 4.456e-01. Saving...
2025-08-15 03:09:50,024:INFO:Epoch: 3300/10000 | Train Loss: 4.459e-01 | Dynamic Loss: 4.459e-01 | Regularization Loss: 1.888e-07 | Val Loss: 4.432e-01 | Time: 4.60s
2025-08-15 03:09:50,025:INFO:New best model found at epoch 3300 with validation loss 4.432e-01. Saving...
2025-08-15 03:10:00,692:INFO:Epoch: 3350/10000 | Train Loss: 4.443e-01 | Dynamic Loss: 4.443e-01 | Regularization Loss: 1.865e-07 | Val Loss: 4.425e-01 | Time: 10.66s
2025-08-15 03:10:00,693:INFO:New best model found at epoch 3350 with validation loss 4.425e-01. Saving...
2025-08-15 03:10:05,313:INFO:Epoch: 3400/10000 | Train Loss: 4.446e-01 | Dynamic Loss: 4.446e-01 | Regularization Loss: 1.852e-07 | Val Loss: 4.422e-01 | Time: 4.61s
2025-08-15 03:10:05,313:INFO:New best model found at epoch 3400 with validation loss 4.422e-01. Saving...
2025-08-15 03:10:09,888:INFO:Epoch: 3450/10000 | Train Loss: 4.437e-01 | Dynamic Loss: 4.437e-01 | Regularization Loss: 1.831e-07 | Val Loss: 4.415e-01 | Time: 4.57s
2025-08-15 03:10:09,888:INFO:New best model found at epoch 3450 with validation loss 4.415e-01. Saving...
2025-08-15 03:10:14,550:INFO:Epoch: 3500/10000 | Train Loss: 4.443e-01 | Dynamic Loss: 4.443e-01 | Regularization Loss: 1.825e-07 | Val Loss: 4.430e-01 | Time: 4.65s
2025-08-15 03:10:21,224:INFO:Epoch: 3550/10000 | Train Loss: 4.426e-01 | Dynamic Loss: 4.426e-01 | Regularization Loss: 1.815e-07 | Val Loss: 4.409e-01 | Time: 6.67s
2025-08-15 03:10:21,224:INFO:New best model found at epoch 3550 with validation loss 4.409e-01. Saving...
2025-08-15 03:10:25,918:INFO:Epoch: 3600/10000 | Train Loss: 4.426e-01 | Dynamic Loss: 4.426e-01 | Regularization Loss: 1.807e-07 | Val Loss: 4.408e-01 | Time: 4.68s
2025-08-15 03:10:25,918:INFO:New best model found at epoch 3600 with validation loss 4.408e-01. Saving...
2025-08-15 03:10:30,539:INFO:Epoch: 3650/10000 | Train Loss: 4.421e-01 | Dynamic Loss: 4.421e-01 | Regularization Loss: 1.793e-07 | Val Loss: 4.401e-01 | Time: 4.61s
2025-08-15 03:10:30,539:INFO:New best model found at epoch 3650 with validation loss 4.401e-01. Saving...
2025-08-15 03:10:35,168:INFO:Epoch: 3700/10000 | Train Loss: 4.413e-01 | Dynamic Loss: 4.413e-01 | Regularization Loss: 1.784e-07 | Val Loss: 4.403e-01 | Time: 4.62s
2025-08-15 03:10:39,743:INFO:Epoch: 3750/10000 | Train Loss: 4.399e-01 | Dynamic Loss: 4.399e-01 | Regularization Loss: 1.760e-07 | Val Loss: 4.394e-01 | Time: 4.57s
2025-08-15 03:10:39,743:INFO:New best model found at epoch 3750 with validation loss 4.394e-01. Saving...
2025-08-15 03:10:48,495:INFO:Epoch: 3800/10000 | Train Loss: 4.391e-01 | Dynamic Loss: 4.391e-01 | Regularization Loss: 1.749e-07 | Val Loss: 4.400e-01 | Time: 8.74s
2025-08-15 03:10:53,083:INFO:Epoch: 3850/10000 | Train Loss: 4.398e-01 | Dynamic Loss: 4.398e-01 | Regularization Loss: 1.734e-07 | Val Loss: 4.389e-01 | Time: 4.59s
2025-08-15 03:10:53,083:INFO:New best model found at epoch 3850 with validation loss 4.389e-01. Saving...
2025-08-15 03:10:57,653:INFO:Epoch: 3900/10000 | Train Loss: 4.382e-01 | Dynamic Loss: 4.382e-01 | Regularization Loss: 1.724e-07 | Val Loss: 4.390e-01 | Time: 4.56s
2025-08-15 03:11:02,217:INFO:Epoch: 3950/10000 | Train Loss: 4.382e-01 | Dynamic Loss: 4.382e-01 | Regularization Loss: 1.711e-07 | Val Loss: 4.384e-01 | Time: 4.56s
2025-08-15 03:11:02,217:INFO:New best model found at epoch 3950 with validation loss 4.384e-01. Saving...
2025-08-15 03:11:06,805:INFO:Epoch: 4000/10000 | Train Loss: 4.375e-01 | Dynamic Loss: 4.375e-01 | Regularization Loss: 1.694e-07 | Val Loss: 4.385e-01 | Time: 4.58s
2025-08-15 03:11:15,208:INFO:Epoch: 4050/10000 | Train Loss: 4.373e-01 | Dynamic Loss: 4.373e-01 | Regularization Loss: 1.693e-07 | Val Loss: 4.386e-01 | Time: 8.40s
2025-08-15 03:11:19,891:INFO:Epoch: 4100/10000 | Train Loss: 4.362e-01 | Dynamic Loss: 4.362e-01 | Regularization Loss: 1.673e-07 | Val Loss: 4.399e-01 | Time: 4.68s
2025-08-15 03:11:24,562:INFO:Epoch: 4150/10000 | Train Loss: 4.332e-01 | Dynamic Loss: 4.332e-01 | Regularization Loss: 1.648e-07 | Val Loss: 4.362e-01 | Time: 4.67s
2025-08-15 03:11:24,562:INFO:New best model found at epoch 4150 with validation loss 4.362e-01. Saving...
2025-08-15 03:11:29,240:INFO:Epoch: 4200/10000 | Train Loss: 4.338e-01 | Dynamic Loss: 4.338e-01 | Regularization Loss: 1.625e-07 | Val Loss: 4.366e-01 | Time: 4.67s
2025-08-15 03:11:33,878:INFO:Epoch: 4250/10000 | Train Loss: 4.301e-01 | Dynamic Loss: 4.301e-01 | Regularization Loss: 1.605e-07 | Val Loss: 4.352e-01 | Time: 4.64s
2025-08-15 03:11:33,878:INFO:New best model found at epoch 4250 with validation loss 4.352e-01. Saving...
2025-08-15 03:11:39,610:INFO:Epoch: 4300/10000 | Train Loss: 4.293e-01 | Dynamic Loss: 4.293e-01 | Regularization Loss: 1.581e-07 | Val Loss: 4.354e-01 | Time: 5.72s
2025-08-15 03:11:44,174:INFO:Epoch: 4350/10000 | Train Loss: 4.291e-01 | Dynamic Loss: 4.291e-01 | Regularization Loss: 1.568e-07 | Val Loss: 4.355e-01 | Time: 4.56s
2025-08-15 03:11:48,821:INFO:Epoch: 4400/10000 | Train Loss: 4.269e-01 | Dynamic Loss: 4.269e-01 | Regularization Loss: 1.561e-07 | Val Loss: 4.303e-01 | Time: 4.65s
2025-08-15 03:11:48,821:INFO:New best model found at epoch 4400 with validation loss 4.303e-01. Saving...
2025-08-15 03:11:53,439:INFO:Epoch: 4450/10000 | Train Loss: 4.259e-01 | Dynamic Loss: 4.259e-01 | Regularization Loss: 1.547e-07 | Val Loss: 4.307e-01 | Time: 4.61s
2025-08-15 03:11:57,993:INFO:Epoch: 4500/10000 | Train Loss: 4.253e-01 | Dynamic Loss: 4.253e-01 | Regularization Loss: 1.534e-07 | Val Loss: 4.292e-01 | Time: 4.55s
2025-08-15 03:11:57,993:INFO:New best model found at epoch 4500 with validation loss 4.292e-01. Saving...
2025-08-15 03:12:05,357:INFO:Epoch: 4550/10000 | Train Loss: 4.254e-01 | Dynamic Loss: 4.254e-01 | Regularization Loss: 1.514e-07 | Val Loss: 4.291e-01 | Time: 7.35s
2025-08-15 03:12:05,358:INFO:New best model found at epoch 4550 with validation loss 4.291e-01. Saving...
2025-08-15 03:12:09,993:INFO:Epoch: 4600/10000 | Train Loss: 4.231e-01 | Dynamic Loss: 4.231e-01 | Regularization Loss: 1.504e-07 | Val Loss: 4.282e-01 | Time: 4.63s
2025-08-15 03:12:09,993:INFO:New best model found at epoch 4600 with validation loss 4.282e-01. Saving...
2025-08-15 03:12:14,621:INFO:Epoch: 4650/10000 | Train Loss: 4.210e-01 | Dynamic Loss: 4.210e-01 | Regularization Loss: 1.493e-07 | Val Loss: 4.251e-01 | Time: 4.62s
2025-08-15 03:12:14,621:INFO:New best model found at epoch 4650 with validation loss 4.251e-01. Saving...
2025-08-15 03:12:19,239:INFO:Epoch: 4700/10000 | Train Loss: 4.193e-01 | Dynamic Loss: 4.193e-01 | Regularization Loss: 1.484e-07 | Val Loss: 4.244e-01 | Time: 4.61s
2025-08-15 03:12:19,239:INFO:New best model found at epoch 4700 with validation loss 4.244e-01. Saving...
2025-08-15 03:12:30,455:INFO:Epoch: 4750/10000 | Train Loss: 4.196e-01 | Dynamic Loss: 4.196e-01 | Regularization Loss: 1.468e-07 | Val Loss: 4.237e-01 | Time: 11.21s
2025-08-15 03:12:30,455:INFO:New best model found at epoch 4750 with validation loss 4.237e-01. Saving...
2025-08-15 03:12:35,184:INFO:Epoch: 4800/10000 | Train Loss: 4.199e-01 | Dynamic Loss: 4.199e-01 | Regularization Loss: 1.463e-07 | Val Loss: 4.237e-01 | Time: 4.72s
2025-08-15 03:12:35,184:INFO:New best model found at epoch 4800 with validation loss 4.237e-01. Saving...
2025-08-15 03:12:39,784:INFO:Epoch: 4850/10000 | Train Loss: 4.169e-01 | Dynamic Loss: 4.169e-01 | Regularization Loss: 1.446e-07 | Val Loss: 4.232e-01 | Time: 4.59s
2025-08-15 03:12:39,784:INFO:New best model found at epoch 4850 with validation loss 4.232e-01. Saving...
2025-08-15 03:12:44,428:INFO:Epoch: 4900/10000 | Train Loss: 4.158e-01 | Dynamic Loss: 4.158e-01 | Regularization Loss: 1.432e-07 | Val Loss: 4.226e-01 | Time: 4.64s
2025-08-15 03:12:44,428:INFO:New best model found at epoch 4900 with validation loss 4.226e-01. Saving...
2025-08-15 03:12:48,977:INFO:Epoch: 4950/10000 | Train Loss: 4.157e-01 | Dynamic Loss: 4.157e-01 | Regularization Loss: 1.415e-07 | Val Loss: 4.217e-01 | Time: 4.54s
2025-08-15 03:12:48,977:INFO:New best model found at epoch 4950 with validation loss 4.217e-01. Saving...
2025-08-15 03:12:59,355:INFO:Epoch: 5000/10000 | Train Loss: 4.162e-01 | Dynamic Loss: 4.162e-01 | Regularization Loss: 1.405e-07 | Val Loss: 4.210e-01 | Time: 10.37s
2025-08-15 03:12:59,355:INFO:New best model found at epoch 5000 with validation loss 4.210e-01. Saving...
2025-08-15 03:13:04,157:INFO:Epoch: 5050/10000 | Train Loss: 4.136e-01 | Dynamic Loss: 4.136e-01 | Regularization Loss: 1.413e-07 | Val Loss: 4.205e-01 | Time: 4.79s
2025-08-15 03:13:04,157:INFO:New best model found at epoch 5050 with validation loss 4.205e-01. Saving...
2025-08-15 03:13:08,840:INFO:Epoch: 5100/10000 | Train Loss: 4.121e-01 | Dynamic Loss: 4.121e-01 | Regularization Loss: 1.385e-07 | Val Loss: 4.199e-01 | Time: 4.67s
2025-08-15 03:13:08,840:INFO:New best model found at epoch 5100 with validation loss 4.199e-01. Saving...
2025-08-15 03:13:13,511:INFO:Epoch: 5150/10000 | Train Loss: 4.123e-01 | Dynamic Loss: 4.123e-01 | Regularization Loss: 1.365e-07 | Val Loss: 4.191e-01 | Time: 4.66s
2025-08-15 03:13:13,511:INFO:New best model found at epoch 5150 with validation loss 4.191e-01. Saving...
2025-08-15 03:13:18,082:INFO:Epoch: 5200/10000 | Train Loss: 4.092e-01 | Dynamic Loss: 4.092e-01 | Regularization Loss: 1.351e-07 | Val Loss: 4.187e-01 | Time: 4.56s
2025-08-15 03:13:18,082:INFO:New best model found at epoch 5200 with validation loss 4.187e-01. Saving...
2025-08-15 03:13:28,866:INFO:Epoch: 5250/10000 | Train Loss: 4.099e-01 | Dynamic Loss: 4.099e-01 | Regularization Loss: 1.330e-07 | Val Loss: 4.176e-01 | Time: 10.78s
2025-08-15 03:13:28,866:INFO:New best model found at epoch 5250 with validation loss 4.176e-01. Saving...
2025-08-15 03:13:33,539:INFO:Epoch: 5300/10000 | Train Loss: 4.092e-01 | Dynamic Loss: 4.092e-01 | Regularization Loss: 1.328e-07 | Val Loss: 4.176e-01 | Time: 4.66s
2025-08-15 03:13:38,169:INFO:Epoch: 5350/10000 | Train Loss: 4.076e-01 | Dynamic Loss: 4.076e-01 | Regularization Loss: 1.300e-07 | Val Loss: 4.169e-01 | Time: 4.63s
2025-08-15 03:13:38,169:INFO:New best model found at epoch 5350 with validation loss 4.169e-01. Saving...
2025-08-15 03:13:42,779:INFO:Epoch: 5400/10000 | Train Loss: 4.047e-01 | Dynamic Loss: 4.047e-01 | Regularization Loss: 1.301e-07 | Val Loss: 4.151e-01 | Time: 4.60s
2025-08-15 03:13:42,780:INFO:New best model found at epoch 5400 with validation loss 4.151e-01. Saving...
2025-08-15 03:13:52,917:INFO:Epoch: 5450/10000 | Train Loss: 4.041e-01 | Dynamic Loss: 4.041e-01 | Regularization Loss: 1.296e-07 | Val Loss: 4.141e-01 | Time: 10.13s
2025-08-15 03:13:52,917:INFO:New best model found at epoch 5450 with validation loss 4.141e-01. Saving...
2025-08-15 03:13:57,612:INFO:Epoch: 5500/10000 | Train Loss: 4.027e-01 | Dynamic Loss: 4.027e-01 | Regularization Loss: 1.277e-07 | Val Loss: 4.131e-01 | Time: 4.69s
2025-08-15 03:13:57,612:INFO:New best model found at epoch 5500 with validation loss 4.131e-01. Saving...
2025-08-15 03:14:02,336:INFO:Epoch: 5550/10000 | Train Loss: 4.011e-01 | Dynamic Loss: 4.011e-01 | Regularization Loss: 1.246e-07 | Val Loss: 4.121e-01 | Time: 4.72s
2025-08-15 03:14:02,336:INFO:New best model found at epoch 5550 with validation loss 4.121e-01. Saving...
2025-08-15 03:14:07,020:INFO:Epoch: 5600/10000 | Train Loss: 4.016e-01 | Dynamic Loss: 4.016e-01 | Regularization Loss: 1.235e-07 | Val Loss: 4.106e-01 | Time: 4.67s
2025-08-15 03:14:07,020:INFO:New best model found at epoch 5600 with validation loss 4.106e-01. Saving...
2025-08-15 03:14:11,683:INFO:Epoch: 5650/10000 | Train Loss: 4.007e-01 | Dynamic Loss: 4.007e-01 | Regularization Loss: 1.242e-07 | Val Loss: 4.098e-01 | Time: 4.65s
2025-08-15 03:14:11,684:INFO:New best model found at epoch 5650 with validation loss 4.098e-01. Saving...
2025-08-15 03:14:22,554:INFO:Epoch: 5700/10000 | Train Loss: 3.972e-01 | Dynamic Loss: 3.972e-01 | Regularization Loss: 1.217e-07 | Val Loss: 4.075e-01 | Time: 10.86s
2025-08-15 03:14:22,554:INFO:New best model found at epoch 5700 with validation loss 4.075e-01. Saving...
2025-08-15 03:14:27,254:INFO:Epoch: 5750/10000 | Train Loss: 3.958e-01 | Dynamic Loss: 3.958e-01 | Regularization Loss: 1.183e-07 | Val Loss: 4.071e-01 | Time: 4.69s
2025-08-15 03:14:27,254:INFO:New best model found at epoch 5750 with validation loss 4.071e-01. Saving...
2025-08-15 03:14:31,974:INFO:Epoch: 5800/10000 | Train Loss: 3.954e-01 | Dynamic Loss: 3.954e-01 | Regularization Loss: 1.188e-07 | Val Loss: 4.060e-01 | Time: 4.71s
2025-08-15 03:14:31,974:INFO:New best model found at epoch 5800 with validation loss 4.060e-01. Saving...
2025-08-15 03:14:36,608:INFO:Epoch: 5850/10000 | Train Loss: 3.939e-01 | Dynamic Loss: 3.939e-01 | Regularization Loss: 1.183e-07 | Val Loss: 4.052e-01 | Time: 4.63s
2025-08-15 03:14:36,609:INFO:New best model found at epoch 5850 with validation loss 4.052e-01. Saving...
2025-08-15 03:14:41,271:INFO:Epoch: 5900/10000 | Train Loss: 3.920e-01 | Dynamic Loss: 3.920e-01 | Regularization Loss: 1.155e-07 | Val Loss: 4.043e-01 | Time: 4.65s
2025-08-15 03:14:41,271:INFO:New best model found at epoch 5900 with validation loss 4.043e-01. Saving...
2025-08-15 03:14:52,064:INFO:Epoch: 5950/10000 | Train Loss: 3.919e-01 | Dynamic Loss: 3.919e-01 | Regularization Loss: 1.143e-07 | Val Loss: 4.032e-01 | Time: 10.78s
2025-08-15 03:14:52,064:INFO:New best model found at epoch 5950 with validation loss 4.032e-01. Saving...
2025-08-15 03:14:56,717:INFO:Epoch: 6000/10000 | Train Loss: 3.903e-01 | Dynamic Loss: 3.903e-01 | Regularization Loss: 1.126e-07 | Val Loss: 4.018e-01 | Time: 4.64s
2025-08-15 03:14:56,717:INFO:New best model found at epoch 6000 with validation loss 4.018e-01. Saving...
2025-08-15 03:15:01,508:INFO:Epoch: 6050/10000 | Train Loss: 3.893e-01 | Dynamic Loss: 3.893e-01 | Regularization Loss: 1.128e-07 | Val Loss: 4.008e-01 | Time: 4.78s
2025-08-15 03:15:01,508:INFO:New best model found at epoch 6050 with validation loss 4.008e-01. Saving...
2025-08-15 03:15:06,158:INFO:Epoch: 6100/10000 | Train Loss: 3.874e-01 | Dynamic Loss: 3.874e-01 | Regularization Loss: 1.122e-07 | Val Loss: 4.010e-01 | Time: 4.64s
2025-08-15 03:15:16,193:INFO:Epoch: 6150/10000 | Train Loss: 3.875e-01 | Dynamic Loss: 3.875e-01 | Regularization Loss: 1.105e-07 | Val Loss: 3.997e-01 | Time: 10.03s
2025-08-15 03:15:16,193:INFO:New best model found at epoch 6150 with validation loss 3.997e-01. Saving...
2025-08-15 03:15:20,881:INFO:Epoch: 6200/10000 | Train Loss: 3.882e-01 | Dynamic Loss: 3.882e-01 | Regularization Loss: 1.087e-07 | Val Loss: 3.996e-01 | Time: 4.68s
2025-08-15 03:15:20,882:INFO:New best model found at epoch 6200 with validation loss 3.996e-01. Saving...
2025-08-15 03:15:25,579:INFO:Epoch: 6250/10000 | Train Loss: 3.871e-01 | Dynamic Loss: 3.871e-01 | Regularization Loss: 1.087e-07 | Val Loss: 3.993e-01 | Time: 4.69s
2025-08-15 03:15:25,580:INFO:New best model found at epoch 6250 with validation loss 3.993e-01. Saving...
2025-08-15 03:15:30,248:INFO:Epoch: 6300/10000 | Train Loss: 3.850e-01 | Dynamic Loss: 3.850e-01 | Regularization Loss: 1.076e-07 | Val Loss: 3.985e-01 | Time: 4.66s
2025-08-15 03:15:30,248:INFO:New best model found at epoch 6300 with validation loss 3.985e-01. Saving...
2025-08-15 03:15:38,296:INFO:Epoch: 6350/10000 | Train Loss: 3.849e-01 | Dynamic Loss: 3.849e-01 | Regularization Loss: 1.113e-07 | Val Loss: 3.987e-01 | Time: 8.04s
2025-08-15 03:15:43,024:INFO:Epoch: 6400/10000 | Train Loss: 3.847e-01 | Dynamic Loss: 3.847e-01 | Regularization Loss: 1.096e-07 | Val Loss: 3.970e-01 | Time: 4.73s
2025-08-15 03:15:43,025:INFO:New best model found at epoch 6400 with validation loss 3.970e-01. Saving...
2025-08-15 03:15:47,803:INFO:Epoch: 6450/10000 | Train Loss: 3.844e-01 | Dynamic Loss: 3.844e-01 | Regularization Loss: 1.054e-07 | Val Loss: 3.976e-01 | Time: 4.77s
2025-08-15 03:15:52,481:INFO:Epoch: 6500/10000 | Train Loss: 3.833e-01 | Dynamic Loss: 3.833e-01 | Regularization Loss: 0.000e+00 | Val Loss: 3.961e-01 | Time: 4.68s
2025-08-15 03:15:52,481:INFO:New best model found at epoch 6500 with validation loss 3.961e-01. Saving...
2025-08-15 03:15:57,132:INFO:Epoch: 6550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.64s
2025-08-15 03:16:04,602:INFO:Epoch: 6600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 7.47s
2025-08-15 03:16:09,305:INFO:Epoch: 6650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.70s
2025-08-15 03:16:13,988:INFO:Epoch: 6700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.68s
2025-08-15 03:16:18,829:INFO:Epoch: 6750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.84s
2025-08-15 03:16:23,458:INFO:Epoch: 6800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.63s
2025-08-15 03:16:28,986:INFO:Epoch: 6850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.53s
2025-08-15 03:16:33,704:INFO:Epoch: 6900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.72s
2025-08-15 03:16:38,314:INFO:Epoch: 6950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.61s
2025-08-15 03:16:42,910:INFO:Epoch: 7000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.60s
2025-08-15 03:16:47,601:INFO:Epoch: 7050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.69s
2025-08-15 03:16:52,229:INFO:Epoch: 7100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.63s
2025-08-15 03:16:57,095:INFO:Epoch: 7150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.87s
2025-08-15 03:17:01,904:INFO:Epoch: 7200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.81s
2025-08-15 03:17:10,581:INFO:Epoch: 7250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 8.68s
2025-08-15 03:17:15,294:INFO:Epoch: 7300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.71s
2025-08-15 03:17:20,022:INFO:Epoch: 7350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.73s
2025-08-15 03:17:24,681:INFO:Epoch: 7400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.66s
2025-08-15 03:17:29,272:INFO:Epoch: 7450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.59s
2025-08-15 03:17:39,479:INFO:Epoch: 7500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 10.21s
2025-08-15 03:17:44,139:INFO:Epoch: 7550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.66s
2025-08-15 03:17:48,968:INFO:Epoch: 7600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.83s
2025-08-15 03:17:53,622:INFO:Epoch: 7650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.65s
2025-08-15 03:17:58,168:INFO:Epoch: 7700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.55s
2025-08-15 03:18:09,073:INFO:Epoch: 7750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 10.90s
2025-08-15 03:18:13,729:INFO:Epoch: 7800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.66s
2025-08-15 03:18:18,394:INFO:Epoch: 7850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.66s
2025-08-15 03:18:23,012:INFO:Epoch: 7900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.62s
2025-08-15 03:18:31,358:INFO:Epoch: 7950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 8.35s
2025-08-15 03:18:36,141:INFO:Epoch: 8000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.78s
2025-08-15 03:18:40,834:INFO:Epoch: 8050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.69s
2025-08-15 03:18:45,515:INFO:Epoch: 8100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.68s
2025-08-15 03:18:50,204:INFO:Epoch: 8150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.69s
2025-08-15 03:18:55,409:INFO:Epoch: 8200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.20s
2025-08-15 03:19:00,075:INFO:Epoch: 8250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.67s
2025-08-15 03:19:04,764:INFO:Epoch: 8300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.69s
2025-08-15 03:19:09,511:INFO:Epoch: 8350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.75s
2025-08-15 03:19:14,183:INFO:Epoch: 8400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.67s
2025-08-15 03:19:22,787:INFO:Epoch: 8450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 8.60s
2025-08-15 03:19:27,453:INFO:Epoch: 8500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.67s
2025-08-15 03:19:32,125:INFO:Epoch: 8550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.67s
2025-08-15 03:19:36,805:INFO:Epoch: 8600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.68s
2025-08-15 03:19:44,233:INFO:Epoch: 8650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 7.43s
2025-08-15 03:19:48,904:INFO:Epoch: 8700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.67s
2025-08-15 03:19:53,603:INFO:Epoch: 8750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.70s
2025-08-15 03:19:58,232:INFO:Epoch: 8800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.63s
2025-08-15 03:20:02,948:INFO:Epoch: 8850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.72s
2025-08-15 03:20:07,807:INFO:Epoch: 8900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.86s
2025-08-15 03:20:12,525:INFO:Epoch: 8950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.72s
2025-08-15 03:20:17,259:INFO:Epoch: 9000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.73s
2025-08-15 03:20:21,973:INFO:Epoch: 9050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.71s
2025-08-15 03:20:26,726:INFO:Epoch: 9100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.75s
2025-08-15 03:20:35,998:INFO:Epoch: 9150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 9.27s
2025-08-15 03:20:40,771:INFO:Epoch: 9200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.77s
2025-08-15 03:20:45,481:INFO:Epoch: 9250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.71s
2025-08-15 03:20:50,243:INFO:Epoch: 9300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.76s
2025-08-15 03:20:54,965:INFO:Epoch: 9350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.72s
2025-08-15 03:21:06,806:INFO:Epoch: 9400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 11.84s
2025-08-15 03:21:11,580:INFO:Epoch: 9450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.77s
2025-08-15 03:21:16,281:INFO:Epoch: 9500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.70s
2025-08-15 03:21:20,935:INFO:Epoch: 9550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.65s
2025-08-15 03:21:25,499:INFO:Epoch: 9600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.56s
2025-08-15 03:21:33,721:INFO:Epoch: 9650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 8.22s
2025-08-15 03:21:38,385:INFO:Epoch: 9700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.66s
2025-08-15 03:21:43,050:INFO:Epoch: 9750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.66s
2025-08-15 03:21:47,681:INFO:Epoch: 9800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.63s
2025-08-15 03:21:52,329:INFO:Epoch: 9850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.65s
2025-08-15 03:22:02,856:INFO:Epoch: 9900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 10.53s
2025-08-15 03:22:07,598:INFO:Epoch: 9950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.74s
2025-08-15 03:22:12,318:INFO:Epoch: 10000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.72s
