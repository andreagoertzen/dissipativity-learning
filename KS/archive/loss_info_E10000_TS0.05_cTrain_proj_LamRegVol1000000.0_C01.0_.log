2025-08-15 02:45:39,364:INFO:Created DataLoaders with 2994 training samples and 998 validation samples.
2025-08-15 02:45:40,750:INFO:model params: 479490
2025-08-15 02:45:42,434:INFO:Epoch: 0/10000 | Train Loss: 5.094e+00 | Dynamic Loss: 5.094e+00 | Regularization Loss: 6.195e-17 | Val Loss: 3.413e+00 | Time: 1.68s
2025-08-15 02:45:42,435:INFO:New best model found at epoch 0 with validation loss 3.413e+00. Saving...
2025-08-15 02:45:46,785:INFO:Epoch: 50/10000 | Train Loss: 9.023e-01 | Dynamic Loss: 9.023e-01 | Regularization Loss: 2.074e-13 | Val Loss: 9.511e-01 | Time: 4.27s
2025-08-15 02:45:46,785:INFO:New best model found at epoch 50 with validation loss 9.511e-01. Saving...
2025-08-15 02:45:50,966:INFO:Epoch: 100/10000 | Train Loss: 7.129e-01 | Dynamic Loss: 7.129e-01 | Regularization Loss: 1.668e-07 | Val Loss: 7.449e-01 | Time: 4.17s
2025-08-15 02:45:50,966:INFO:New best model found at epoch 100 with validation loss 7.449e-01. Saving...
2025-08-15 02:45:55,298:INFO:Epoch: 150/10000 | Train Loss: 6.438e-01 | Dynamic Loss: 6.438e-01 | Regularization Loss: 5.827e-07 | Val Loss: 6.643e-01 | Time: 4.32s
2025-08-15 02:45:55,298:INFO:New best model found at epoch 150 with validation loss 6.643e-01. Saving...
2025-08-15 02:45:59,611:INFO:Epoch: 200/10000 | Train Loss: 6.072e-01 | Dynamic Loss: 6.072e-01 | Regularization Loss: 5.790e-07 | Val Loss: 6.285e-01 | Time: 4.30s
2025-08-15 02:45:59,611:INFO:New best model found at epoch 200 with validation loss 6.285e-01. Saving...
2025-08-15 02:46:03,909:INFO:Epoch: 250/10000 | Train Loss: 5.952e-01 | Dynamic Loss: 5.952e-01 | Regularization Loss: 5.679e-07 | Val Loss: 6.027e-01 | Time: 4.29s
2025-08-15 02:46:03,909:INFO:New best model found at epoch 250 with validation loss 6.027e-01. Saving...
2025-08-15 02:46:13,044:INFO:Epoch: 300/10000 | Train Loss: 5.788e-01 | Dynamic Loss: 5.788e-01 | Regularization Loss: 5.482e-07 | Val Loss: 5.843e-01 | Time: 9.13s
2025-08-15 02:46:13,044:INFO:New best model found at epoch 300 with validation loss 5.843e-01. Saving...
2025-08-15 02:46:17,378:INFO:Epoch: 350/10000 | Train Loss: 5.729e-01 | Dynamic Loss: 5.729e-01 | Regularization Loss: 5.336e-07 | Val Loss: 5.729e-01 | Time: 4.33s
2025-08-15 02:46:17,379:INFO:New best model found at epoch 350 with validation loss 5.729e-01. Saving...
2025-08-15 02:46:21,735:INFO:Epoch: 400/10000 | Train Loss: 5.651e-01 | Dynamic Loss: 5.651e-01 | Regularization Loss: 5.164e-07 | Val Loss: 5.660e-01 | Time: 4.35s
2025-08-15 02:46:21,735:INFO:New best model found at epoch 400 with validation loss 5.660e-01. Saving...
2025-08-15 02:46:26,047:INFO:Epoch: 450/10000 | Train Loss: 5.590e-01 | Dynamic Loss: 5.590e-01 | Regularization Loss: 5.005e-07 | Val Loss: 5.570e-01 | Time: 4.30s
2025-08-15 02:46:26,047:INFO:New best model found at epoch 450 with validation loss 5.570e-01. Saving...
2025-08-15 02:46:31,189:INFO:Epoch: 500/10000 | Train Loss: 5.564e-01 | Dynamic Loss: 5.564e-01 | Regularization Loss: 4.854e-07 | Val Loss: 5.542e-01 | Time: 5.13s
2025-08-15 02:46:31,189:INFO:New best model found at epoch 500 with validation loss 5.542e-01. Saving...
2025-08-15 02:46:35,530:INFO:Epoch: 550/10000 | Train Loss: 5.509e-01 | Dynamic Loss: 5.509e-01 | Regularization Loss: 4.725e-07 | Val Loss: 5.469e-01 | Time: 4.33s
2025-08-15 02:46:35,530:INFO:New best model found at epoch 550 with validation loss 5.469e-01. Saving...
2025-08-15 02:46:39,923:INFO:Epoch: 600/10000 | Train Loss: 5.502e-01 | Dynamic Loss: 5.502e-01 | Regularization Loss: 4.585e-07 | Val Loss: 5.405e-01 | Time: 4.38s
2025-08-15 02:46:39,923:INFO:New best model found at epoch 600 with validation loss 5.405e-01. Saving...
2025-08-15 02:46:44,319:INFO:Epoch: 650/10000 | Train Loss: 5.426e-01 | Dynamic Loss: 5.426e-01 | Regularization Loss: 4.467e-07 | Val Loss: 5.370e-01 | Time: 4.39s
2025-08-15 02:46:44,319:INFO:New best model found at epoch 650 with validation loss 5.370e-01. Saving...
2025-08-15 02:46:48,742:INFO:Epoch: 700/10000 | Train Loss: 5.417e-01 | Dynamic Loss: 5.417e-01 | Regularization Loss: 4.323e-07 | Val Loss: 5.321e-01 | Time: 4.41s
2025-08-15 02:46:48,742:INFO:New best model found at epoch 700 with validation loss 5.321e-01. Saving...
2025-08-15 02:46:53,120:INFO:Epoch: 750/10000 | Train Loss: 5.361e-01 | Dynamic Loss: 5.361e-01 | Regularization Loss: 4.209e-07 | Val Loss: 5.272e-01 | Time: 4.37s
2025-08-15 02:46:53,120:INFO:New best model found at epoch 750 with validation loss 5.272e-01. Saving...
2025-08-15 02:46:57,517:INFO:Epoch: 800/10000 | Train Loss: 5.350e-01 | Dynamic Loss: 5.350e-01 | Regularization Loss: 4.109e-07 | Val Loss: 5.238e-01 | Time: 4.39s
2025-08-15 02:46:57,517:INFO:New best model found at epoch 800 with validation loss 5.238e-01. Saving...
2025-08-15 02:47:01,909:INFO:Epoch: 850/10000 | Train Loss: 5.314e-01 | Dynamic Loss: 5.314e-01 | Regularization Loss: 4.006e-07 | Val Loss: 5.194e-01 | Time: 4.38s
2025-08-15 02:47:01,909:INFO:New best model found at epoch 850 with validation loss 5.194e-01. Saving...
2025-08-15 02:47:06,277:INFO:Epoch: 900/10000 | Train Loss: 5.256e-01 | Dynamic Loss: 5.256e-01 | Regularization Loss: 3.901e-07 | Val Loss: 5.154e-01 | Time: 4.36s
2025-08-15 02:47:06,277:INFO:New best model found at epoch 900 with validation loss 5.154e-01. Saving...
2025-08-15 02:47:16,248:INFO:Epoch: 950/10000 | Train Loss: 5.223e-01 | Dynamic Loss: 5.223e-01 | Regularization Loss: 3.796e-07 | Val Loss: 5.126e-01 | Time: 9.96s
2025-08-15 02:47:16,248:INFO:New best model found at epoch 950 with validation loss 5.126e-01. Saving...
2025-08-15 02:47:20,691:INFO:Epoch: 1000/10000 | Train Loss: 5.210e-01 | Dynamic Loss: 5.210e-01 | Regularization Loss: 3.695e-07 | Val Loss: 5.113e-01 | Time: 4.43s
2025-08-15 02:47:20,691:INFO:New best model found at epoch 1000 with validation loss 5.113e-01. Saving...
2025-08-15 02:47:25,034:INFO:Epoch: 1050/10000 | Train Loss: 5.181e-01 | Dynamic Loss: 5.181e-01 | Regularization Loss: 3.620e-07 | Val Loss: 5.080e-01 | Time: 4.33s
2025-08-15 02:47:25,034:INFO:New best model found at epoch 1050 with validation loss 5.080e-01. Saving...
2025-08-15 02:47:29,444:INFO:Epoch: 1100/10000 | Train Loss: 5.155e-01 | Dynamic Loss: 5.155e-01 | Regularization Loss: 3.518e-07 | Val Loss: 5.045e-01 | Time: 4.40s
2025-08-15 02:47:29,444:INFO:New best model found at epoch 1100 with validation loss 5.045e-01. Saving...
2025-08-15 02:47:33,866:INFO:Epoch: 1150/10000 | Train Loss: 5.116e-01 | Dynamic Loss: 5.116e-01 | Regularization Loss: 3.432e-07 | Val Loss: 5.016e-01 | Time: 4.41s
2025-08-15 02:47:33,867:INFO:New best model found at epoch 1150 with validation loss 5.016e-01. Saving...
2025-08-15 02:47:38,254:INFO:Epoch: 1200/10000 | Train Loss: 5.110e-01 | Dynamic Loss: 5.110e-01 | Regularization Loss: 3.374e-07 | Val Loss: 4.989e-01 | Time: 4.38s
2025-08-15 02:47:38,254:INFO:New best model found at epoch 1200 with validation loss 4.989e-01. Saving...
2025-08-15 02:47:42,697:INFO:Epoch: 1250/10000 | Train Loss: 5.086e-01 | Dynamic Loss: 5.086e-01 | Regularization Loss: 3.316e-07 | Val Loss: 4.970e-01 | Time: 4.43s
2025-08-15 02:47:42,697:INFO:New best model found at epoch 1250 with validation loss 4.970e-01. Saving...
2025-08-15 02:47:47,102:INFO:Epoch: 1300/10000 | Train Loss: 5.071e-01 | Dynamic Loss: 5.071e-01 | Regularization Loss: 3.234e-07 | Val Loss: 4.952e-01 | Time: 4.40s
2025-08-15 02:47:47,102:INFO:New best model found at epoch 1300 with validation loss 4.952e-01. Saving...
2025-08-15 02:47:51,610:INFO:Epoch: 1350/10000 | Train Loss: 5.043e-01 | Dynamic Loss: 5.043e-01 | Regularization Loss: 3.182e-07 | Val Loss: 4.932e-01 | Time: 4.50s
2025-08-15 02:47:51,610:INFO:New best model found at epoch 1350 with validation loss 4.932e-01. Saving...
2025-08-15 02:47:56,034:INFO:Epoch: 1400/10000 | Train Loss: 5.017e-01 | Dynamic Loss: 5.017e-01 | Regularization Loss: 3.117e-07 | Val Loss: 4.902e-01 | Time: 4.41s
2025-08-15 02:47:56,035:INFO:New best model found at epoch 1400 with validation loss 4.902e-01. Saving...
2025-08-15 02:48:00,443:INFO:Epoch: 1450/10000 | Train Loss: 5.000e-01 | Dynamic Loss: 5.000e-01 | Regularization Loss: 3.051e-07 | Val Loss: 4.886e-01 | Time: 4.40s
2025-08-15 02:48:00,443:INFO:New best model found at epoch 1450 with validation loss 4.886e-01. Saving...
2025-08-15 02:48:04,824:INFO:Epoch: 1500/10000 | Train Loss: 4.992e-01 | Dynamic Loss: 4.992e-01 | Regularization Loss: 2.992e-07 | Val Loss: 4.872e-01 | Time: 4.37s
2025-08-15 02:48:04,824:INFO:New best model found at epoch 1500 with validation loss 4.872e-01. Saving...
2025-08-15 02:48:09,239:INFO:Epoch: 1550/10000 | Train Loss: 4.957e-01 | Dynamic Loss: 4.957e-01 | Regularization Loss: 2.959e-07 | Val Loss: 4.868e-01 | Time: 4.41s
2025-08-15 02:48:09,239:INFO:New best model found at epoch 1550 with validation loss 4.868e-01. Saving...
2025-08-15 02:48:19,352:INFO:Epoch: 1600/10000 | Train Loss: 4.945e-01 | Dynamic Loss: 4.945e-01 | Regularization Loss: 2.906e-07 | Val Loss: 4.840e-01 | Time: 10.10s
2025-08-15 02:48:19,352:INFO:New best model found at epoch 1600 with validation loss 4.840e-01. Saving...
2025-08-15 02:48:23,763:INFO:Epoch: 1650/10000 | Train Loss: 4.950e-01 | Dynamic Loss: 4.950e-01 | Regularization Loss: 2.867e-07 | Val Loss: 4.846e-01 | Time: 4.40s
2025-08-15 02:48:28,218:INFO:Epoch: 1700/10000 | Train Loss: 4.911e-01 | Dynamic Loss: 4.911e-01 | Regularization Loss: 2.795e-07 | Val Loss: 4.801e-01 | Time: 4.45s
2025-08-15 02:48:28,218:INFO:New best model found at epoch 1700 with validation loss 4.801e-01. Saving...
2025-08-15 02:48:32,664:INFO:Epoch: 1750/10000 | Train Loss: 4.910e-01 | Dynamic Loss: 4.910e-01 | Regularization Loss: 2.761e-07 | Val Loss: 4.795e-01 | Time: 4.44s
2025-08-15 02:48:32,664:INFO:New best model found at epoch 1750 with validation loss 4.795e-01. Saving...
2025-08-15 02:48:40,233:INFO:Epoch: 1800/10000 | Train Loss: 4.874e-01 | Dynamic Loss: 4.874e-01 | Regularization Loss: 2.722e-07 | Val Loss: 4.791e-01 | Time: 7.56s
2025-08-15 02:48:40,233:INFO:New best model found at epoch 1800 with validation loss 4.791e-01. Saving...
2025-08-15 02:48:44,710:INFO:Epoch: 1850/10000 | Train Loss: 4.858e-01 | Dynamic Loss: 4.858e-01 | Regularization Loss: 2.670e-07 | Val Loss: 4.780e-01 | Time: 4.47s
2025-08-15 02:48:44,710:INFO:New best model found at epoch 1850 with validation loss 4.780e-01. Saving...
2025-08-15 02:48:49,105:INFO:Epoch: 1900/10000 | Train Loss: 4.839e-01 | Dynamic Loss: 4.839e-01 | Regularization Loss: 2.630e-07 | Val Loss: 4.748e-01 | Time: 4.39s
2025-08-15 02:48:49,105:INFO:New best model found at epoch 1900 with validation loss 4.748e-01. Saving...
2025-08-15 02:48:53,546:INFO:Epoch: 1950/10000 | Train Loss: 4.845e-01 | Dynamic Loss: 4.845e-01 | Regularization Loss: 2.576e-07 | Val Loss: 4.743e-01 | Time: 4.43s
2025-08-15 02:48:53,546:INFO:New best model found at epoch 1950 with validation loss 4.743e-01. Saving...
2025-08-15 02:48:57,982:INFO:Epoch: 2000/10000 | Train Loss: 4.821e-01 | Dynamic Loss: 4.821e-01 | Regularization Loss: 2.556e-07 | Val Loss: 4.756e-01 | Time: 4.43s
2025-08-15 02:49:08,273:INFO:Epoch: 2050/10000 | Train Loss: 4.799e-01 | Dynamic Loss: 4.799e-01 | Regularization Loss: 2.488e-07 | Val Loss: 4.688e-01 | Time: 10.29s
2025-08-15 02:49:08,273:INFO:New best model found at epoch 2050 with validation loss 4.688e-01. Saving...
2025-08-15 02:49:12,733:INFO:Epoch: 2100/10000 | Train Loss: 4.786e-01 | Dynamic Loss: 4.786e-01 | Regularization Loss: 2.457e-07 | Val Loss: 4.705e-01 | Time: 4.45s
2025-08-15 02:49:17,200:INFO:Epoch: 2150/10000 | Train Loss: 4.747e-01 | Dynamic Loss: 4.747e-01 | Regularization Loss: 2.391e-07 | Val Loss: 4.664e-01 | Time: 4.47s
2025-08-15 02:49:17,200:INFO:New best model found at epoch 2150 with validation loss 4.664e-01. Saving...
2025-08-15 02:49:21,646:INFO:Epoch: 2200/10000 | Train Loss: 4.732e-01 | Dynamic Loss: 4.732e-01 | Regularization Loss: 2.357e-07 | Val Loss: 4.630e-01 | Time: 4.44s
2025-08-15 02:49:21,646:INFO:New best model found at epoch 2200 with validation loss 4.630e-01. Saving...
2025-08-15 02:49:26,142:INFO:Epoch: 2250/10000 | Train Loss: 4.706e-01 | Dynamic Loss: 4.706e-01 | Regularization Loss: 2.307e-07 | Val Loss: 4.631e-01 | Time: 4.49s
2025-08-15 02:49:30,573:INFO:Epoch: 2300/10000 | Train Loss: 4.693e-01 | Dynamic Loss: 4.693e-01 | Regularization Loss: 2.272e-07 | Val Loss: 4.630e-01 | Time: 4.43s
2025-08-15 02:49:35,038:INFO:Epoch: 2350/10000 | Train Loss: 4.659e-01 | Dynamic Loss: 4.659e-01 | Regularization Loss: 2.215e-07 | Val Loss: 4.596e-01 | Time: 4.47s
2025-08-15 02:49:35,038:INFO:New best model found at epoch 2350 with validation loss 4.596e-01. Saving...
2025-08-15 02:49:39,519:INFO:Epoch: 2400/10000 | Train Loss: 4.656e-01 | Dynamic Loss: 4.656e-01 | Regularization Loss: 2.192e-07 | Val Loss: 4.589e-01 | Time: 4.47s
2025-08-15 02:49:39,519:INFO:New best model found at epoch 2400 with validation loss 4.589e-01. Saving...
2025-08-15 02:49:43,909:INFO:Epoch: 2450/10000 | Train Loss: 4.631e-01 | Dynamic Loss: 4.631e-01 | Regularization Loss: 2.179e-07 | Val Loss: 4.575e-01 | Time: 4.38s
2025-08-15 02:49:43,909:INFO:New best model found at epoch 2450 with validation loss 4.575e-01. Saving...
2025-08-15 02:49:54,191:INFO:Epoch: 2500/10000 | Train Loss: 4.613e-01 | Dynamic Loss: 4.613e-01 | Regularization Loss: 2.139e-07 | Val Loss: 4.560e-01 | Time: 10.27s
2025-08-15 02:49:54,191:INFO:New best model found at epoch 2500 with validation loss 4.560e-01. Saving...
2025-08-15 02:49:58,704:INFO:Epoch: 2550/10000 | Train Loss: 4.618e-01 | Dynamic Loss: 4.618e-01 | Regularization Loss: 2.124e-07 | Val Loss: 4.555e-01 | Time: 4.50s
2025-08-15 02:49:58,704:INFO:New best model found at epoch 2550 with validation loss 4.555e-01. Saving...
2025-08-15 02:50:03,135:INFO:Epoch: 2600/10000 | Train Loss: 4.607e-01 | Dynamic Loss: 4.607e-01 | Regularization Loss: 2.095e-07 | Val Loss: 4.548e-01 | Time: 4.42s
2025-08-15 02:50:03,135:INFO:New best model found at epoch 2600 with validation loss 4.548e-01. Saving...
2025-08-15 02:50:07,602:INFO:Epoch: 2650/10000 | Train Loss: 4.596e-01 | Dynamic Loss: 4.596e-01 | Regularization Loss: 2.074e-07 | Val Loss: 4.547e-01 | Time: 4.46s
2025-08-15 02:50:07,602:INFO:New best model found at epoch 2650 with validation loss 4.547e-01. Saving...
2025-08-15 02:50:13,120:INFO:Epoch: 2700/10000 | Train Loss: 4.581e-01 | Dynamic Loss: 4.581e-01 | Regularization Loss: 2.051e-07 | Val Loss: 4.531e-01 | Time: 5.51s
2025-08-15 02:50:13,120:INFO:New best model found at epoch 2700 with validation loss 4.531e-01. Saving...
2025-08-15 02:50:17,564:INFO:Epoch: 2750/10000 | Train Loss: 4.565e-01 | Dynamic Loss: 4.565e-01 | Regularization Loss: 2.039e-07 | Val Loss: 4.539e-01 | Time: 4.43s
2025-08-15 02:50:22,024:INFO:Epoch: 2800/10000 | Train Loss: 4.565e-01 | Dynamic Loss: 4.565e-01 | Regularization Loss: 2.021e-07 | Val Loss: 4.524e-01 | Time: 4.46s
2025-08-15 02:50:22,024:INFO:New best model found at epoch 2800 with validation loss 4.524e-01. Saving...
2025-08-15 02:50:26,503:INFO:Epoch: 2850/10000 | Train Loss: 4.546e-01 | Dynamic Loss: 4.546e-01 | Regularization Loss: 1.990e-07 | Val Loss: 4.514e-01 | Time: 4.47s
2025-08-15 02:50:26,503:INFO:New best model found at epoch 2850 with validation loss 4.514e-01. Saving...
2025-08-15 02:50:31,036:INFO:Epoch: 2900/10000 | Train Loss: 4.538e-01 | Dynamic Loss: 4.538e-01 | Regularization Loss: 1.977e-07 | Val Loss: 4.500e-01 | Time: 4.52s
2025-08-15 02:50:31,036:INFO:New best model found at epoch 2900 with validation loss 4.500e-01. Saving...
2025-08-15 02:50:35,505:INFO:Epoch: 2950/10000 | Train Loss: 4.545e-01 | Dynamic Loss: 4.545e-01 | Regularization Loss: 1.955e-07 | Val Loss: 4.485e-01 | Time: 4.46s
2025-08-15 02:50:35,505:INFO:New best model found at epoch 2950 with validation loss 4.485e-01. Saving...
2025-08-15 02:50:39,974:INFO:Epoch: 3000/10000 | Train Loss: 4.536e-01 | Dynamic Loss: 4.536e-01 | Regularization Loss: 1.927e-07 | Val Loss: 4.478e-01 | Time: 4.46s
2025-08-15 02:50:39,975:INFO:New best model found at epoch 3000 with validation loss 4.478e-01. Saving...
2025-08-15 02:50:44,412:INFO:Epoch: 3050/10000 | Train Loss: 4.513e-01 | Dynamic Loss: 4.513e-01 | Regularization Loss: 1.911e-07 | Val Loss: 4.475e-01 | Time: 4.43s
2025-08-15 02:50:44,413:INFO:New best model found at epoch 3050 with validation loss 4.475e-01. Saving...
2025-08-15 02:50:48,839:INFO:Epoch: 3100/10000 | Train Loss: 4.491e-01 | Dynamic Loss: 4.491e-01 | Regularization Loss: 1.882e-07 | Val Loss: 4.461e-01 | Time: 4.42s
2025-08-15 02:50:48,839:INFO:New best model found at epoch 3100 with validation loss 4.461e-01. Saving...
2025-08-15 02:50:57,703:INFO:Epoch: 3150/10000 | Train Loss: 4.497e-01 | Dynamic Loss: 4.497e-01 | Regularization Loss: 1.867e-07 | Val Loss: 4.451e-01 | Time: 8.86s
2025-08-15 02:50:57,703:INFO:New best model found at epoch 3150 with validation loss 4.451e-01. Saving...
2025-08-15 02:51:02,198:INFO:Epoch: 3200/10000 | Train Loss: 4.481e-01 | Dynamic Loss: 4.481e-01 | Regularization Loss: 1.851e-07 | Val Loss: 4.441e-01 | Time: 4.48s
2025-08-15 02:51:02,198:INFO:New best model found at epoch 3200 with validation loss 4.441e-01. Saving...
2025-08-15 02:51:06,703:INFO:Epoch: 3250/10000 | Train Loss: 4.468e-01 | Dynamic Loss: 4.468e-01 | Regularization Loss: 1.833e-07 | Val Loss: 4.432e-01 | Time: 4.50s
2025-08-15 02:51:06,703:INFO:New best model found at epoch 3250 with validation loss 4.432e-01. Saving...
2025-08-15 02:51:11,207:INFO:Epoch: 3300/10000 | Train Loss: 4.447e-01 | Dynamic Loss: 4.447e-01 | Regularization Loss: 1.814e-07 | Val Loss: 4.432e-01 | Time: 4.49s
2025-08-15 02:51:11,207:INFO:New best model found at epoch 3300 with validation loss 4.432e-01. Saving...
2025-08-15 02:51:15,656:INFO:Epoch: 3350/10000 | Train Loss: 4.446e-01 | Dynamic Loss: 4.446e-01 | Regularization Loss: 1.792e-07 | Val Loss: 4.413e-01 | Time: 4.44s
2025-08-15 02:51:15,656:INFO:New best model found at epoch 3350 with validation loss 4.413e-01. Saving...
2025-08-15 02:51:26,347:INFO:Epoch: 3400/10000 | Train Loss: 4.442e-01 | Dynamic Loss: 4.442e-01 | Regularization Loss: 1.785e-07 | Val Loss: 4.438e-01 | Time: 10.68s
2025-08-15 02:51:30,858:INFO:Epoch: 3450/10000 | Train Loss: 4.437e-01 | Dynamic Loss: 4.437e-01 | Regularization Loss: 1.759e-07 | Val Loss: 4.418e-01 | Time: 4.51s
2025-08-15 02:51:35,330:INFO:Epoch: 3500/10000 | Train Loss: 4.428e-01 | Dynamic Loss: 4.428e-01 | Regularization Loss: 1.747e-07 | Val Loss: 4.412e-01 | Time: 4.47s
2025-08-15 02:51:35,330:INFO:New best model found at epoch 3500 with validation loss 4.412e-01. Saving...
2025-08-15 02:51:39,773:INFO:Epoch: 3550/10000 | Train Loss: 4.423e-01 | Dynamic Loss: 4.423e-01 | Regularization Loss: 1.732e-07 | Val Loss: 4.406e-01 | Time: 4.43s
2025-08-15 02:51:39,773:INFO:New best model found at epoch 3550 with validation loss 4.406e-01. Saving...
2025-08-15 02:51:48,619:INFO:Epoch: 3600/10000 | Train Loss: 4.419e-01 | Dynamic Loss: 4.419e-01 | Regularization Loss: 1.733e-07 | Val Loss: 4.401e-01 | Time: 8.84s
2025-08-15 02:51:48,619:INFO:New best model found at epoch 3600 with validation loss 4.401e-01. Saving...
2025-08-15 02:51:53,126:INFO:Epoch: 3650/10000 | Train Loss: 4.414e-01 | Dynamic Loss: 4.414e-01 | Regularization Loss: 1.716e-07 | Val Loss: 4.400e-01 | Time: 4.50s
2025-08-15 02:51:53,126:INFO:New best model found at epoch 3650 with validation loss 4.400e-01. Saving...
2025-08-15 02:51:57,591:INFO:Epoch: 3700/10000 | Train Loss: 4.402e-01 | Dynamic Loss: 4.402e-01 | Regularization Loss: 1.708e-07 | Val Loss: 4.397e-01 | Time: 4.46s
2025-08-15 02:51:57,592:INFO:New best model found at epoch 3700 with validation loss 4.397e-01. Saving...
2025-08-15 02:52:02,060:INFO:Epoch: 3750/10000 | Train Loss: 4.394e-01 | Dynamic Loss: 4.394e-01 | Regularization Loss: 1.684e-07 | Val Loss: 4.394e-01 | Time: 4.46s
2025-08-15 02:52:02,060:INFO:New best model found at epoch 3750 with validation loss 4.394e-01. Saving...
2025-08-15 02:52:06,563:INFO:Epoch: 3800/10000 | Train Loss: 4.394e-01 | Dynamic Loss: 4.394e-01 | Regularization Loss: 1.678e-07 | Val Loss: 4.381e-01 | Time: 4.49s
2025-08-15 02:52:06,563:INFO:New best model found at epoch 3800 with validation loss 4.381e-01. Saving...
2025-08-15 02:52:16,753:INFO:Epoch: 3850/10000 | Train Loss: 4.389e-01 | Dynamic Loss: 4.389e-01 | Regularization Loss: 1.660e-07 | Val Loss: 4.379e-01 | Time: 10.18s
2025-08-15 02:52:16,753:INFO:New best model found at epoch 3850 with validation loss 4.379e-01. Saving...
2025-08-15 02:52:34,381:INFO:Epoch: 3900/10000 | Train Loss: 4.366e-01 | Dynamic Loss: 4.366e-01 | Regularization Loss: 1.651e-07 | Val Loss: 4.384e-01 | Time: 17.62s
2025-08-15 02:52:38,874:INFO:Epoch: 3950/10000 | Train Loss: 4.363e-01 | Dynamic Loss: 4.363e-01 | Regularization Loss: 1.634e-07 | Val Loss: 4.370e-01 | Time: 4.49s
2025-08-15 02:52:38,874:INFO:New best model found at epoch 3950 with validation loss 4.370e-01. Saving...
2025-08-15 02:52:43,383:INFO:Epoch: 4000/10000 | Train Loss: 4.360e-01 | Dynamic Loss: 4.360e-01 | Regularization Loss: 1.629e-07 | Val Loss: 4.362e-01 | Time: 4.50s
2025-08-15 02:52:43,384:INFO:New best model found at epoch 4000 with validation loss 4.362e-01. Saving...
2025-08-15 02:52:47,899:INFO:Epoch: 4050/10000 | Train Loss: 4.351e-01 | Dynamic Loss: 4.351e-01 | Regularization Loss: 1.617e-07 | Val Loss: 4.357e-01 | Time: 4.51s
2025-08-15 02:52:47,899:INFO:New best model found at epoch 4050 with validation loss 4.357e-01. Saving...
2025-08-15 02:52:52,370:INFO:Epoch: 4100/10000 | Train Loss: 4.330e-01 | Dynamic Loss: 4.330e-01 | Regularization Loss: 1.595e-07 | Val Loss: 4.360e-01 | Time: 4.46s
2025-08-15 02:52:56,836:INFO:Epoch: 4150/10000 | Train Loss: 4.323e-01 | Dynamic Loss: 4.323e-01 | Regularization Loss: 1.579e-07 | Val Loss: 4.343e-01 | Time: 4.47s
2025-08-15 02:52:56,837:INFO:New best model found at epoch 4150 with validation loss 4.343e-01. Saving...
2025-08-15 02:53:01,312:INFO:Epoch: 4200/10000 | Train Loss: 4.317e-01 | Dynamic Loss: 4.317e-01 | Regularization Loss: 1.558e-07 | Val Loss: 4.316e-01 | Time: 4.47s
2025-08-15 02:53:01,312:INFO:New best model found at epoch 4200 with validation loss 4.316e-01. Saving...
2025-08-15 02:53:05,767:INFO:Epoch: 4250/10000 | Train Loss: 4.294e-01 | Dynamic Loss: 4.294e-01 | Regularization Loss: 1.539e-07 | Val Loss: 4.325e-01 | Time: 4.44s
2025-08-15 02:53:15,788:INFO:Epoch: 4300/10000 | Train Loss: 4.275e-01 | Dynamic Loss: 4.275e-01 | Regularization Loss: 1.517e-07 | Val Loss: 4.299e-01 | Time: 10.02s
2025-08-15 02:53:15,789:INFO:New best model found at epoch 4300 with validation loss 4.299e-01. Saving...
2025-08-15 02:53:20,301:INFO:Epoch: 4350/10000 | Train Loss: 4.273e-01 | Dynamic Loss: 4.273e-01 | Regularization Loss: 1.501e-07 | Val Loss: 4.288e-01 | Time: 4.50s
2025-08-15 02:53:20,301:INFO:New best model found at epoch 4350 with validation loss 4.288e-01. Saving...
2025-08-15 02:53:24,813:INFO:Epoch: 4400/10000 | Train Loss: 4.260e-01 | Dynamic Loss: 4.260e-01 | Regularization Loss: 1.489e-07 | Val Loss: 4.288e-01 | Time: 4.50s
2025-08-15 02:53:24,813:INFO:New best model found at epoch 4400 with validation loss 4.288e-01. Saving...
2025-08-15 02:53:29,278:INFO:Epoch: 4450/10000 | Train Loss: 4.247e-01 | Dynamic Loss: 4.247e-01 | Regularization Loss: 1.473e-07 | Val Loss: 4.279e-01 | Time: 4.46s
2025-08-15 02:53:29,278:INFO:New best model found at epoch 4450 with validation loss 4.279e-01. Saving...
2025-08-15 02:53:33,760:INFO:Epoch: 4500/10000 | Train Loss: 4.246e-01 | Dynamic Loss: 4.246e-01 | Regularization Loss: 1.467e-07 | Val Loss: 4.269e-01 | Time: 4.47s
2025-08-15 02:53:33,760:INFO:New best model found at epoch 4500 with validation loss 4.269e-01. Saving...
2025-08-15 02:53:44,151:INFO:Epoch: 4550/10000 | Train Loss: 4.242e-01 | Dynamic Loss: 4.242e-01 | Regularization Loss: 1.448e-07 | Val Loss: 4.264e-01 | Time: 10.38s
2025-08-15 02:53:44,151:INFO:New best model found at epoch 4550 with validation loss 4.264e-01. Saving...
2025-08-15 02:53:48,633:INFO:Epoch: 4600/10000 | Train Loss: 4.207e-01 | Dynamic Loss: 4.207e-01 | Regularization Loss: 1.436e-07 | Val Loss: 4.254e-01 | Time: 4.47s
2025-08-15 02:53:48,633:INFO:New best model found at epoch 4600 with validation loss 4.254e-01. Saving...
2025-08-15 02:53:53,100:INFO:Epoch: 4650/10000 | Train Loss: 4.209e-01 | Dynamic Loss: 4.209e-01 | Regularization Loss: 1.426e-07 | Val Loss: 4.241e-01 | Time: 4.46s
2025-08-15 02:53:53,100:INFO:New best model found at epoch 4650 with validation loss 4.241e-01. Saving...
2025-08-15 02:53:57,604:INFO:Epoch: 4700/10000 | Train Loss: 4.196e-01 | Dynamic Loss: 4.196e-01 | Regularization Loss: 1.421e-07 | Val Loss: 4.236e-01 | Time: 4.50s
2025-08-15 02:53:57,604:INFO:New best model found at epoch 4700 with validation loss 4.236e-01. Saving...
2025-08-15 02:54:02,042:INFO:Epoch: 4750/10000 | Train Loss: 4.176e-01 | Dynamic Loss: 4.176e-01 | Regularization Loss: 1.396e-07 | Val Loss: 4.209e-01 | Time: 4.43s
2025-08-15 02:54:02,042:INFO:New best model found at epoch 4750 with validation loss 4.209e-01. Saving...
2025-08-15 02:54:12,743:INFO:Epoch: 4800/10000 | Train Loss: 4.172e-01 | Dynamic Loss: 4.172e-01 | Regularization Loss: 1.398e-07 | Val Loss: 4.207e-01 | Time: 10.69s
2025-08-15 02:54:12,743:INFO:New best model found at epoch 4800 with validation loss 4.207e-01. Saving...
2025-08-15 02:54:17,302:INFO:Epoch: 4850/10000 | Train Loss: 4.140e-01 | Dynamic Loss: 4.140e-01 | Regularization Loss: 1.374e-07 | Val Loss: 4.194e-01 | Time: 4.55s
2025-08-15 02:54:17,302:INFO:New best model found at epoch 4850 with validation loss 4.194e-01. Saving...
2025-08-15 02:54:21,851:INFO:Epoch: 4900/10000 | Train Loss: 4.126e-01 | Dynamic Loss: 4.126e-01 | Regularization Loss: 1.357e-07 | Val Loss: 4.191e-01 | Time: 4.54s
2025-08-15 02:54:21,851:INFO:New best model found at epoch 4900 with validation loss 4.191e-01. Saving...
2025-08-15 02:54:26,341:INFO:Epoch: 4950/10000 | Train Loss: 4.120e-01 | Dynamic Loss: 4.120e-01 | Regularization Loss: 1.349e-07 | Val Loss: 4.181e-01 | Time: 4.48s
2025-08-15 02:54:26,342:INFO:New best model found at epoch 4950 with validation loss 4.181e-01. Saving...
2025-08-15 02:54:30,859:INFO:Epoch: 5000/10000 | Train Loss: 4.110e-01 | Dynamic Loss: 4.110e-01 | Regularization Loss: 1.322e-07 | Val Loss: 4.173e-01 | Time: 4.51s
2025-08-15 02:54:30,859:INFO:New best model found at epoch 5000 with validation loss 4.173e-01. Saving...
2025-08-15 02:54:35,383:INFO:Epoch: 5050/10000 | Train Loss: 4.097e-01 | Dynamic Loss: 4.097e-01 | Regularization Loss: 1.337e-07 | Val Loss: 4.163e-01 | Time: 4.52s
2025-08-15 02:54:35,384:INFO:New best model found at epoch 5050 with validation loss 4.163e-01. Saving...
2025-08-15 02:54:39,898:INFO:Epoch: 5100/10000 | Train Loss: 4.085e-01 | Dynamic Loss: 4.085e-01 | Regularization Loss: 1.294e-07 | Val Loss: 4.159e-01 | Time: 4.51s
2025-08-15 02:54:39,898:INFO:New best model found at epoch 5100 with validation loss 4.159e-01. Saving...
2025-08-15 02:54:44,388:INFO:Epoch: 5150/10000 | Train Loss: 4.090e-01 | Dynamic Loss: 4.090e-01 | Regularization Loss: 1.281e-07 | Val Loss: 4.151e-01 | Time: 4.48s
2025-08-15 02:54:44,388:INFO:New best model found at epoch 5150 with validation loss 4.151e-01. Saving...
2025-08-15 02:54:48,867:INFO:Epoch: 5200/10000 | Train Loss: 4.063e-01 | Dynamic Loss: 4.063e-01 | Regularization Loss: 1.275e-07 | Val Loss: 4.142e-01 | Time: 4.47s
2025-08-15 02:54:48,867:INFO:New best model found at epoch 5200 with validation loss 4.142e-01. Saving...
2025-08-15 02:54:56,965:INFO:Epoch: 5250/10000 | Train Loss: 4.074e-01 | Dynamic Loss: 4.074e-01 | Regularization Loss: 1.252e-07 | Val Loss: 4.133e-01 | Time: 8.09s
2025-08-15 02:54:56,966:INFO:New best model found at epoch 5250 with validation loss 4.133e-01. Saving...
2025-08-15 02:55:01,530:INFO:Epoch: 5300/10000 | Train Loss: 4.066e-01 | Dynamic Loss: 4.066e-01 | Regularization Loss: 1.259e-07 | Val Loss: 4.125e-01 | Time: 4.55s
2025-08-15 02:55:01,530:INFO:New best model found at epoch 5300 with validation loss 4.125e-01. Saving...
2025-08-15 02:55:06,034:INFO:Epoch: 5350/10000 | Train Loss: 4.053e-01 | Dynamic Loss: 4.053e-01 | Regularization Loss: 1.240e-07 | Val Loss: 4.122e-01 | Time: 4.50s
2025-08-15 02:55:06,035:INFO:New best model found at epoch 5350 with validation loss 4.122e-01. Saving...
2025-08-15 02:55:10,536:INFO:Epoch: 5400/10000 | Train Loss: 4.040e-01 | Dynamic Loss: 4.040e-01 | Regularization Loss: 1.237e-07 | Val Loss: 4.115e-01 | Time: 4.49s
2025-08-15 02:55:10,536:INFO:New best model found at epoch 5400 with validation loss 4.115e-01. Saving...
2025-08-15 02:55:15,006:INFO:Epoch: 5450/10000 | Train Loss: 4.042e-01 | Dynamic Loss: 4.042e-01 | Regularization Loss: 1.238e-07 | Val Loss: 4.108e-01 | Time: 4.46s
2025-08-15 02:55:15,006:INFO:New best model found at epoch 5450 with validation loss 4.108e-01. Saving...
2025-08-15 02:55:20,786:INFO:Epoch: 5500/10000 | Train Loss: 4.037e-01 | Dynamic Loss: 4.037e-01 | Regularization Loss: 1.227e-07 | Val Loss: 4.108e-01 | Time: 5.77s
2025-08-15 02:55:20,786:INFO:New best model found at epoch 5500 with validation loss 4.108e-01. Saving...
2025-08-15 02:55:25,331:INFO:Epoch: 5550/10000 | Train Loss: 4.024e-01 | Dynamic Loss: 4.024e-01 | Regularization Loss: 1.195e-07 | Val Loss: 4.101e-01 | Time: 4.54s
2025-08-15 02:55:25,331:INFO:New best model found at epoch 5550 with validation loss 4.101e-01. Saving...
2025-08-15 02:55:29,837:INFO:Epoch: 5600/10000 | Train Loss: 4.034e-01 | Dynamic Loss: 4.034e-01 | Regularization Loss: 1.199e-07 | Val Loss: 4.096e-01 | Time: 4.50s
2025-08-15 02:55:29,837:INFO:New best model found at epoch 5600 with validation loss 4.096e-01. Saving...
2025-08-15 02:55:34,332:INFO:Epoch: 5650/10000 | Train Loss: 4.012e-01 | Dynamic Loss: 4.012e-01 | Regularization Loss: 1.214e-07 | Val Loss: 4.100e-01 | Time: 4.49s
2025-08-15 02:55:38,856:INFO:Epoch: 5700/10000 | Train Loss: 4.011e-01 | Dynamic Loss: 4.011e-01 | Regularization Loss: 1.201e-07 | Val Loss: 4.088e-01 | Time: 4.52s
2025-08-15 02:55:38,856:INFO:New best model found at epoch 5700 with validation loss 4.088e-01. Saving...
2025-08-15 02:55:46,692:INFO:Epoch: 5750/10000 | Train Loss: 3.999e-01 | Dynamic Loss: 3.999e-01 | Regularization Loss: 1.166e-07 | Val Loss: 4.083e-01 | Time: 7.83s
2025-08-15 02:55:46,692:INFO:New best model found at epoch 5750 with validation loss 4.083e-01. Saving...
2025-08-15 02:55:51,228:INFO:Epoch: 5800/10000 | Train Loss: 3.993e-01 | Dynamic Loss: 3.993e-01 | Regularization Loss: 1.217e-07 | Val Loss: 4.080e-01 | Time: 4.53s
2025-08-15 02:55:51,229:INFO:New best model found at epoch 5800 with validation loss 4.080e-01. Saving...
2025-08-15 02:55:55,701:INFO:Epoch: 5850/10000 | Train Loss: 3.999e-01 | Dynamic Loss: 3.999e-01 | Regularization Loss: 1.157e-07 | Val Loss: 4.089e-01 | Time: 4.46s
2025-08-15 02:56:00,200:INFO:Epoch: 5900/10000 | Train Loss: 3.973e-01 | Dynamic Loss: 3.973e-01 | Regularization Loss: 1.179e-07 | Val Loss: 4.068e-01 | Time: 4.50s
2025-08-15 02:56:00,200:INFO:New best model found at epoch 5900 with validation loss 4.068e-01. Saving...
2025-08-15 02:56:04,706:INFO:Epoch: 5950/10000 | Train Loss: 3.971e-01 | Dynamic Loss: 3.971e-01 | Regularization Loss: 9.384e-08 | Val Loss: 4.060e-01 | Time: 4.50s
2025-08-15 02:56:04,706:INFO:New best model found at epoch 5950 with validation loss 4.060e-01. Saving...
2025-08-15 02:56:13,724:INFO:Epoch: 6000/10000 | Train Loss: 3.952e-01 | Dynamic Loss: 3.952e-01 | Regularization Loss: 1.158e-07 | Val Loss: 4.050e-01 | Time: 9.01s
2025-08-15 02:56:13,724:INFO:New best model found at epoch 6000 with validation loss 4.050e-01. Saving...
2025-08-15 02:56:18,257:INFO:Epoch: 6050/10000 | Train Loss: 3.979e-01 | Dynamic Loss: 3.979e-01 | Regularization Loss: 0.000e+00 | Val Loss: 4.070e-01 | Time: 4.52s
2025-08-15 02:56:22,818:INFO:Epoch: 6100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.56s
2025-08-15 02:56:27,368:INFO:Epoch: 6150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.55s
2025-08-15 02:56:31,875:INFO:Epoch: 6200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.51s
2025-08-15 02:56:42,166:INFO:Epoch: 6250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 10.29s
2025-08-15 02:56:46,747:INFO:Epoch: 6300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.58s
2025-08-15 02:56:51,277:INFO:Epoch: 6350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.53s
2025-08-15 02:56:55,762:INFO:Epoch: 6400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.49s
2025-08-15 02:57:00,635:INFO:Epoch: 6450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.87s
2025-08-15 02:57:05,169:INFO:Epoch: 6500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.53s
2025-08-15 02:57:09,700:INFO:Epoch: 6550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.53s
2025-08-15 02:57:14,270:INFO:Epoch: 6600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.57s
2025-08-15 02:57:18,769:INFO:Epoch: 6650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.50s
2025-08-15 02:57:27,499:INFO:Epoch: 6700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 8.73s
2025-08-15 02:57:32,063:INFO:Epoch: 6750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.56s
2025-08-15 02:57:36,578:INFO:Epoch: 6800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.51s
2025-08-15 02:57:41,105:INFO:Epoch: 6850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.53s
2025-08-15 02:57:45,656:INFO:Epoch: 6900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.55s
2025-08-15 02:57:52,177:INFO:Epoch: 6950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 6.52s
2025-08-15 02:57:56,812:INFO:Epoch: 7000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.64s
2025-08-15 02:58:01,414:INFO:Epoch: 7050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.60s
2025-08-15 02:58:05,924:INFO:Epoch: 7100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.51s
2025-08-15 02:58:10,458:INFO:Epoch: 7150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.53s
2025-08-15 02:58:18,530:INFO:Epoch: 7200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 8.07s
2025-08-15 02:58:23,078:INFO:Epoch: 7250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.55s
2025-08-15 02:58:27,666:INFO:Epoch: 7300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.59s
2025-08-15 02:58:32,202:INFO:Epoch: 7350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.54s
2025-08-15 02:58:36,715:INFO:Epoch: 7400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.51s
2025-08-15 02:58:44,175:INFO:Epoch: 7450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 7.46s
2025-08-15 02:58:48,692:INFO:Epoch: 7500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.52s
2025-08-15 02:58:53,321:INFO:Epoch: 7550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.63s
2025-08-15 02:58:57,873:INFO:Epoch: 7600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.55s
2025-08-15 02:59:02,412:INFO:Epoch: 7650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.54s
2025-08-15 02:59:09,719:INFO:Epoch: 7700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 7.31s
2025-08-15 02:59:14,253:INFO:Epoch: 7750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.53s
2025-08-15 02:59:18,847:INFO:Epoch: 7800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.59s
2025-08-15 02:59:23,395:INFO:Epoch: 7850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.55s
2025-08-15 02:59:27,899:INFO:Epoch: 7900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.50s
2025-08-15 02:59:37,392:INFO:Epoch: 7950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 9.49s
2025-08-15 02:59:41,935:INFO:Epoch: 8000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.54s
2025-08-15 02:59:46,460:INFO:Epoch: 8050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.52s
2025-08-15 02:59:50,965:INFO:Epoch: 8100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.51s
2025-08-15 02:59:55,486:INFO:Epoch: 8150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.52s
2025-08-15 03:00:03,000:INFO:Epoch: 8200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 7.51s
2025-08-15 03:00:07,588:INFO:Epoch: 8250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.59s
2025-08-15 03:00:12,199:INFO:Epoch: 8300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.61s
2025-08-15 03:00:16,747:INFO:Epoch: 8350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.55s
2025-08-15 03:00:21,284:INFO:Epoch: 8400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.54s
2025-08-15 03:00:32,705:INFO:Epoch: 8450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 11.42s
2025-08-15 03:00:37,237:INFO:Epoch: 8500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.53s
2025-08-15 03:00:41,850:INFO:Epoch: 8550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.61s
2025-08-15 03:00:46,440:INFO:Epoch: 8600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.59s
2025-08-15 03:00:50,965:INFO:Epoch: 8650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.52s
2025-08-15 03:01:02,228:INFO:Epoch: 8700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 11.26s
2025-08-15 03:01:06,807:INFO:Epoch: 8750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.58s
2025-08-15 03:01:11,366:INFO:Epoch: 8800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.56s
2025-08-15 03:01:15,950:INFO:Epoch: 8850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.58s
2025-08-15 03:01:20,507:INFO:Epoch: 8900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.56s
2025-08-15 03:01:25,099:INFO:Epoch: 8950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.59s
2025-08-15 03:01:29,720:INFO:Epoch: 9000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.62s
2025-08-15 03:01:34,276:INFO:Epoch: 9050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.56s
2025-08-15 03:01:38,822:INFO:Epoch: 9100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.55s
2025-08-15 03:01:43,327:INFO:Epoch: 9150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.50s
2025-08-15 03:01:54,711:INFO:Epoch: 9200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 11.38s
2025-08-15 03:01:59,320:INFO:Epoch: 9250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.61s
2025-08-15 03:02:03,963:INFO:Epoch: 9300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.64s
2025-08-15 03:02:08,557:INFO:Epoch: 9350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.59s
2025-08-15 03:02:13,161:INFO:Epoch: 9400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.60s
2025-08-15 03:02:20,529:INFO:Epoch: 9450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 7.37s
2025-08-15 03:02:25,160:INFO:Epoch: 9500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.63s
2025-08-15 03:02:29,756:INFO:Epoch: 9550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.60s
2025-08-15 03:02:34,330:INFO:Epoch: 9600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.57s
2025-08-15 03:02:38,870:INFO:Epoch: 9650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.54s
2025-08-15 03:02:44,747:INFO:Epoch: 9700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.88s
2025-08-15 03:02:49,337:INFO:Epoch: 9750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.59s
2025-08-15 03:02:53,985:INFO:Epoch: 9800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.65s
2025-08-15 03:02:58,560:INFO:Epoch: 9850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.58s
2025-08-15 03:03:03,156:INFO:Epoch: 9900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.60s
2025-08-15 03:03:13,831:INFO:Epoch: 9950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 10.67s
2025-08-15 03:03:18,441:INFO:Epoch: 10000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.61s
