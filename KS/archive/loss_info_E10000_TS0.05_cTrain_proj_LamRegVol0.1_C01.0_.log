2025-08-15 03:06:08,105:INFO:Created DataLoaders with 2994 training samples and 998 validation samples.
2025-08-15 03:06:08,737:INFO:model params: 479490
2025-08-15 03:06:09,492:INFO:Epoch: 0/10000 | Train Loss: 5.094e+00 | Dynamic Loss: 5.094e+00 | Regularization Loss: 6.195e-24 | Val Loss: 3.413e+00 | Time: 0.76s
2025-08-15 03:06:09,493:INFO:New best model found at epoch 0 with validation loss 3.413e+00. Saving...
2025-08-15 03:06:14,172:INFO:Epoch: 50/10000 | Train Loss: 9.023e-01 | Dynamic Loss: 9.023e-01 | Regularization Loss: 2.074e-20 | Val Loss: 9.511e-01 | Time: 4.58s
2025-08-15 03:06:14,172:INFO:New best model found at epoch 50 with validation loss 9.511e-01. Saving...
2025-08-15 03:06:18,673:INFO:Epoch: 100/10000 | Train Loss: 7.129e-01 | Dynamic Loss: 7.129e-01 | Regularization Loss: 1.892e-14 | Val Loss: 7.449e-01 | Time: 4.49s
2025-08-15 03:06:18,673:INFO:New best model found at epoch 100 with validation loss 7.449e-01. Saving...
2025-08-15 03:06:23,310:INFO:Epoch: 150/10000 | Train Loss: 6.419e-01 | Dynamic Loss: 6.419e-01 | Regularization Loss: 2.082e-07 | Val Loss: 6.647e-01 | Time: 4.63s
2025-08-15 03:06:23,311:INFO:New best model found at epoch 150 with validation loss 6.647e-01. Saving...
2025-08-15 03:06:27,854:INFO:Epoch: 200/10000 | Train Loss: 6.087e-01 | Dynamic Loss: 6.086e-01 | Regularization Loss: 6.321e-07 | Val Loss: 6.246e-01 | Time: 4.53s
2025-08-15 03:06:27,854:INFO:New best model found at epoch 200 with validation loss 6.246e-01. Saving...
2025-08-15 03:06:32,399:INFO:Epoch: 250/10000 | Train Loss: 5.900e-01 | Dynamic Loss: 5.900e-01 | Regularization Loss: 6.162e-07 | Val Loss: 6.009e-01 | Time: 4.54s
2025-08-15 03:06:32,400:INFO:New best model found at epoch 250 with validation loss 6.009e-01. Saving...
2025-08-15 03:06:42,169:INFO:Epoch: 300/10000 | Train Loss: 5.803e-01 | Dynamic Loss: 5.803e-01 | Regularization Loss: 5.963e-07 | Val Loss: 5.864e-01 | Time: 9.76s
2025-08-15 03:06:42,170:INFO:New best model found at epoch 300 with validation loss 5.864e-01. Saving...
2025-08-15 03:06:46,761:INFO:Epoch: 350/10000 | Train Loss: 5.717e-01 | Dynamic Loss: 5.717e-01 | Regularization Loss: 5.766e-07 | Val Loss: 5.749e-01 | Time: 4.58s
2025-08-15 03:06:46,761:INFO:New best model found at epoch 350 with validation loss 5.749e-01. Saving...
2025-08-15 03:06:51,354:INFO:Epoch: 400/10000 | Train Loss: 5.636e-01 | Dynamic Loss: 5.636e-01 | Regularization Loss: 5.566e-07 | Val Loss: 5.642e-01 | Time: 4.58s
2025-08-15 03:06:51,355:INFO:New best model found at epoch 400 with validation loss 5.642e-01. Saving...
2025-08-15 03:06:55,893:INFO:Epoch: 450/10000 | Train Loss: 5.583e-01 | Dynamic Loss: 5.583e-01 | Regularization Loss: 5.376e-07 | Val Loss: 5.581e-01 | Time: 4.53s
2025-08-15 03:06:55,893:INFO:New best model found at epoch 450 with validation loss 5.581e-01. Saving...
2025-08-15 03:07:06,073:INFO:Epoch: 500/10000 | Train Loss: 5.562e-01 | Dynamic Loss: 5.562e-01 | Regularization Loss: 5.229e-07 | Val Loss: 5.513e-01 | Time: 10.17s
2025-08-15 03:07:06,073:INFO:New best model found at epoch 500 with validation loss 5.513e-01. Saving...
2025-08-15 03:07:10,762:INFO:Epoch: 550/10000 | Train Loss: 5.532e-01 | Dynamic Loss: 5.532e-01 | Regularization Loss: 5.086e-07 | Val Loss: 5.472e-01 | Time: 4.68s
2025-08-15 03:07:10,762:INFO:New best model found at epoch 550 with validation loss 5.472e-01. Saving...
2025-08-15 03:07:15,406:INFO:Epoch: 600/10000 | Train Loss: 5.500e-01 | Dynamic Loss: 5.500e-01 | Regularization Loss: 4.920e-07 | Val Loss: 5.401e-01 | Time: 4.64s
2025-08-15 03:07:15,406:INFO:New best model found at epoch 600 with validation loss 5.401e-01. Saving...
2025-08-15 03:07:20,004:INFO:Epoch: 650/10000 | Train Loss: 5.428e-01 | Dynamic Loss: 5.428e-01 | Regularization Loss: 4.776e-07 | Val Loss: 5.353e-01 | Time: 4.59s
2025-08-15 03:07:20,004:INFO:New best model found at epoch 650 with validation loss 5.353e-01. Saving...
2025-08-15 03:07:24,725:INFO:Epoch: 700/10000 | Train Loss: 5.407e-01 | Dynamic Loss: 5.407e-01 | Regularization Loss: 4.639e-07 | Val Loss: 5.311e-01 | Time: 4.71s
2025-08-15 03:07:24,725:INFO:New best model found at epoch 700 with validation loss 5.311e-01. Saving...
2025-08-15 03:07:29,417:INFO:Epoch: 750/10000 | Train Loss: 5.354e-01 | Dynamic Loss: 5.354e-01 | Regularization Loss: 4.494e-07 | Val Loss: 5.260e-01 | Time: 4.68s
2025-08-15 03:07:29,418:INFO:New best model found at epoch 750 with validation loss 5.260e-01. Saving...
2025-08-15 03:07:34,107:INFO:Epoch: 800/10000 | Train Loss: 5.333e-01 | Dynamic Loss: 5.333e-01 | Regularization Loss: 4.386e-07 | Val Loss: 5.233e-01 | Time: 4.68s
2025-08-15 03:07:34,107:INFO:New best model found at epoch 800 with validation loss 5.233e-01. Saving...
2025-08-15 03:07:38,777:INFO:Epoch: 850/10000 | Train Loss: 5.307e-01 | Dynamic Loss: 5.307e-01 | Regularization Loss: 4.276e-07 | Val Loss: 5.193e-01 | Time: 4.66s
2025-08-15 03:07:38,777:INFO:New best model found at epoch 850 with validation loss 5.193e-01. Saving...
2025-08-15 03:07:43,369:INFO:Epoch: 900/10000 | Train Loss: 5.255e-01 | Dynamic Loss: 5.255e-01 | Regularization Loss: 4.167e-07 | Val Loss: 5.165e-01 | Time: 4.58s
2025-08-15 03:07:43,369:INFO:New best model found at epoch 900 with validation loss 5.165e-01. Saving...
2025-08-15 03:07:53,712:INFO:Epoch: 950/10000 | Train Loss: 5.230e-01 | Dynamic Loss: 5.230e-01 | Regularization Loss: 4.055e-07 | Val Loss: 5.135e-01 | Time: 10.33s
2025-08-15 03:07:53,712:INFO:New best model found at epoch 950 with validation loss 5.135e-01. Saving...
2025-08-15 03:07:58,356:INFO:Epoch: 1000/10000 | Train Loss: 5.215e-01 | Dynamic Loss: 5.215e-01 | Regularization Loss: 3.958e-07 | Val Loss: 5.096e-01 | Time: 4.63s
2025-08-15 03:07:58,356:INFO:New best model found at epoch 1000 with validation loss 5.096e-01. Saving...
2025-08-15 03:08:03,116:INFO:Epoch: 1050/10000 | Train Loss: 5.192e-01 | Dynamic Loss: 5.192e-01 | Regularization Loss: 3.842e-07 | Val Loss: 5.068e-01 | Time: 4.75s
2025-08-15 03:08:03,116:INFO:New best model found at epoch 1050 with validation loss 5.068e-01. Saving...
2025-08-15 03:08:07,834:INFO:Epoch: 1100/10000 | Train Loss: 5.151e-01 | Dynamic Loss: 5.151e-01 | Regularization Loss: 3.767e-07 | Val Loss: 5.045e-01 | Time: 4.71s
2025-08-15 03:08:07,834:INFO:New best model found at epoch 1100 with validation loss 5.045e-01. Saving...
2025-08-15 03:08:14,054:INFO:Epoch: 1150/10000 | Train Loss: 5.117e-01 | Dynamic Loss: 5.117e-01 | Regularization Loss: 3.671e-07 | Val Loss: 5.026e-01 | Time: 6.21s
2025-08-15 03:08:14,054:INFO:New best model found at epoch 1150 with validation loss 5.026e-01. Saving...
2025-08-15 03:08:18,748:INFO:Epoch: 1200/10000 | Train Loss: 5.103e-01 | Dynamic Loss: 5.103e-01 | Regularization Loss: 3.605e-07 | Val Loss: 4.985e-01 | Time: 4.68s
2025-08-15 03:08:18,748:INFO:New best model found at epoch 1200 with validation loss 4.985e-01. Saving...
2025-08-15 03:08:23,448:INFO:Epoch: 1250/10000 | Train Loss: 5.079e-01 | Dynamic Loss: 5.079e-01 | Regularization Loss: 3.540e-07 | Val Loss: 4.968e-01 | Time: 4.69s
2025-08-15 03:08:23,448:INFO:New best model found at epoch 1250 with validation loss 4.968e-01. Saving...
2025-08-15 03:08:28,155:INFO:Epoch: 1300/10000 | Train Loss: 5.066e-01 | Dynamic Loss: 5.066e-01 | Regularization Loss: 3.453e-07 | Val Loss: 4.957e-01 | Time: 4.70s
2025-08-15 03:08:28,155:INFO:New best model found at epoch 1300 with validation loss 4.957e-01. Saving...
2025-08-15 03:08:33,278:INFO:Epoch: 1350/10000 | Train Loss: 5.041e-01 | Dynamic Loss: 5.041e-01 | Regularization Loss: 3.397e-07 | Val Loss: 4.933e-01 | Time: 5.11s
2025-08-15 03:08:33,278:INFO:New best model found at epoch 1350 with validation loss 4.933e-01. Saving...
2025-08-15 03:08:37,982:INFO:Epoch: 1400/10000 | Train Loss: 4.997e-01 | Dynamic Loss: 4.997e-01 | Regularization Loss: 3.314e-07 | Val Loss: 4.896e-01 | Time: 4.69s
2025-08-15 03:08:37,982:INFO:New best model found at epoch 1400 with validation loss 4.896e-01. Saving...
2025-08-15 03:08:42,774:INFO:Epoch: 1450/10000 | Train Loss: 4.996e-01 | Dynamic Loss: 4.996e-01 | Regularization Loss: 3.255e-07 | Val Loss: 4.873e-01 | Time: 4.78s
2025-08-15 03:08:42,774:INFO:New best model found at epoch 1450 with validation loss 4.873e-01. Saving...
2025-08-15 03:08:47,445:INFO:Epoch: 1500/10000 | Train Loss: 4.975e-01 | Dynamic Loss: 4.975e-01 | Regularization Loss: 3.184e-07 | Val Loss: 4.860e-01 | Time: 4.66s
2025-08-15 03:08:47,446:INFO:New best model found at epoch 1500 with validation loss 4.860e-01. Saving...
2025-08-15 03:08:53,027:INFO:Epoch: 1550/10000 | Train Loss: 4.945e-01 | Dynamic Loss: 4.945e-01 | Regularization Loss: 3.146e-07 | Val Loss: 4.832e-01 | Time: 5.57s
2025-08-15 03:08:53,027:INFO:New best model found at epoch 1550 with validation loss 4.832e-01. Saving...
2025-08-15 03:08:57,769:INFO:Epoch: 1600/10000 | Train Loss: 4.932e-01 | Dynamic Loss: 4.932e-01 | Regularization Loss: 3.085e-07 | Val Loss: 4.812e-01 | Time: 4.73s
2025-08-15 03:08:57,769:INFO:New best model found at epoch 1600 with validation loss 4.812e-01. Saving...
2025-08-15 03:09:02,447:INFO:Epoch: 1650/10000 | Train Loss: 4.913e-01 | Dynamic Loss: 4.913e-01 | Regularization Loss: 3.036e-07 | Val Loss: 4.799e-01 | Time: 4.67s
2025-08-15 03:09:02,447:INFO:New best model found at epoch 1650 with validation loss 4.799e-01. Saving...
2025-08-15 03:09:07,133:INFO:Epoch: 1700/10000 | Train Loss: 4.917e-01 | Dynamic Loss: 4.917e-01 | Regularization Loss: 2.980e-07 | Val Loss: 4.792e-01 | Time: 4.68s
2025-08-15 03:09:07,133:INFO:New best model found at epoch 1700 with validation loss 4.792e-01. Saving...
2025-08-15 03:09:11,817:INFO:Epoch: 1750/10000 | Train Loss: 4.906e-01 | Dynamic Loss: 4.906e-01 | Regularization Loss: 2.928e-07 | Val Loss: 4.782e-01 | Time: 4.67s
2025-08-15 03:09:11,817:INFO:New best model found at epoch 1750 with validation loss 4.782e-01. Saving...
2025-08-15 03:09:20,907:INFO:Epoch: 1800/10000 | Train Loss: 4.866e-01 | Dynamic Loss: 4.866e-01 | Regularization Loss: 2.890e-07 | Val Loss: 4.755e-01 | Time: 9.08s
2025-08-15 03:09:20,907:INFO:New best model found at epoch 1800 with validation loss 4.755e-01. Saving...
2025-08-15 03:09:25,621:INFO:Epoch: 1850/10000 | Train Loss: 4.845e-01 | Dynamic Loss: 4.845e-01 | Regularization Loss: 2.838e-07 | Val Loss: 4.744e-01 | Time: 4.70s
2025-08-15 03:09:25,621:INFO:New best model found at epoch 1850 with validation loss 4.744e-01. Saving...
2025-08-15 03:09:30,278:INFO:Epoch: 1900/10000 | Train Loss: 4.826e-01 | Dynamic Loss: 4.826e-01 | Regularization Loss: 2.791e-07 | Val Loss: 4.728e-01 | Time: 4.65s
2025-08-15 03:09:30,278:INFO:New best model found at epoch 1900 with validation loss 4.728e-01. Saving...
2025-08-15 03:09:34,870:INFO:Epoch: 1950/10000 | Train Loss: 4.810e-01 | Dynamic Loss: 4.810e-01 | Regularization Loss: 2.724e-07 | Val Loss: 4.703e-01 | Time: 4.58s
2025-08-15 03:09:34,870:INFO:New best model found at epoch 1950 with validation loss 4.703e-01. Saving...
2025-08-15 03:09:43,975:INFO:Epoch: 2000/10000 | Train Loss: 4.788e-01 | Dynamic Loss: 4.788e-01 | Regularization Loss: 2.686e-07 | Val Loss: 4.698e-01 | Time: 9.10s
2025-08-15 03:09:43,975:INFO:New best model found at epoch 2000 with validation loss 4.698e-01. Saving...
2025-08-15 03:09:48,688:INFO:Epoch: 2050/10000 | Train Loss: 4.777e-01 | Dynamic Loss: 4.777e-01 | Regularization Loss: 2.649e-07 | Val Loss: 4.699e-01 | Time: 4.70s
2025-08-15 03:09:53,540:INFO:Epoch: 2100/10000 | Train Loss: 4.758e-01 | Dynamic Loss: 4.758e-01 | Regularization Loss: 2.599e-07 | Val Loss: 4.687e-01 | Time: 4.85s
2025-08-15 03:09:53,540:INFO:New best model found at epoch 2100 with validation loss 4.687e-01. Saving...
2025-08-15 03:09:58,186:INFO:Epoch: 2150/10000 | Train Loss: 4.730e-01 | Dynamic Loss: 4.730e-01 | Regularization Loss: 2.535e-07 | Val Loss: 4.645e-01 | Time: 4.64s
2025-08-15 03:09:58,187:INFO:New best model found at epoch 2150 with validation loss 4.645e-01. Saving...
2025-08-15 03:10:02,888:INFO:Epoch: 2200/10000 | Train Loss: 4.708e-01 | Dynamic Loss: 4.708e-01 | Regularization Loss: 2.492e-07 | Val Loss: 4.650e-01 | Time: 4.69s
2025-08-15 03:10:13,648:INFO:Epoch: 2250/10000 | Train Loss: 4.671e-01 | Dynamic Loss: 4.671e-01 | Regularization Loss: 2.432e-07 | Val Loss: 4.627e-01 | Time: 10.76s
2025-08-15 03:10:13,648:INFO:New best model found at epoch 2250 with validation loss 4.627e-01. Saving...
2025-08-15 03:10:18,376:INFO:Epoch: 2300/10000 | Train Loss: 4.668e-01 | Dynamic Loss: 4.668e-01 | Regularization Loss: 2.394e-07 | Val Loss: 4.617e-01 | Time: 4.72s
2025-08-15 03:10:18,376:INFO:New best model found at epoch 2300 with validation loss 4.617e-01. Saving...
2025-08-15 03:10:23,071:INFO:Epoch: 2350/10000 | Train Loss: 4.641e-01 | Dynamic Loss: 4.641e-01 | Regularization Loss: 2.347e-07 | Val Loss: 4.603e-01 | Time: 4.69s
2025-08-15 03:10:23,071:INFO:New best model found at epoch 2350 with validation loss 4.603e-01. Saving...
2025-08-15 03:10:27,700:INFO:Epoch: 2400/10000 | Train Loss: 4.633e-01 | Dynamic Loss: 4.633e-01 | Regularization Loss: 2.316e-07 | Val Loss: 4.569e-01 | Time: 4.62s
2025-08-15 03:10:27,700:INFO:New best model found at epoch 2400 with validation loss 4.569e-01. Saving...
2025-08-15 03:10:33,076:INFO:Epoch: 2450/10000 | Train Loss: 4.619e-01 | Dynamic Loss: 4.619e-01 | Regularization Loss: 2.303e-07 | Val Loss: 4.561e-01 | Time: 5.37s
2025-08-15 03:10:33,076:INFO:New best model found at epoch 2450 with validation loss 4.561e-01. Saving...
2025-08-15 03:10:37,868:INFO:Epoch: 2500/10000 | Train Loss: 4.606e-01 | Dynamic Loss: 4.606e-01 | Regularization Loss: 2.265e-07 | Val Loss: 4.547e-01 | Time: 4.78s
2025-08-15 03:10:37,868:INFO:New best model found at epoch 2500 with validation loss 4.547e-01. Saving...
2025-08-15 03:10:42,592:INFO:Epoch: 2550/10000 | Train Loss: 4.585e-01 | Dynamic Loss: 4.585e-01 | Regularization Loss: 2.242e-07 | Val Loss: 4.547e-01 | Time: 4.71s
2025-08-15 03:10:42,592:INFO:New best model found at epoch 2550 with validation loss 4.547e-01. Saving...
2025-08-15 03:10:47,241:INFO:Epoch: 2600/10000 | Train Loss: 4.585e-01 | Dynamic Loss: 4.585e-01 | Regularization Loss: 2.213e-07 | Val Loss: 4.535e-01 | Time: 4.64s
2025-08-15 03:10:47,241:INFO:New best model found at epoch 2600 with validation loss 4.535e-01. Saving...
2025-08-15 03:10:51,935:INFO:Epoch: 2650/10000 | Train Loss: 4.581e-01 | Dynamic Loss: 4.581e-01 | Regularization Loss: 2.198e-07 | Val Loss: 4.534e-01 | Time: 4.69s
2025-08-15 03:10:51,935:INFO:New best model found at epoch 2650 with validation loss 4.534e-01. Saving...
2025-08-15 03:10:59,416:INFO:Epoch: 2700/10000 | Train Loss: 4.577e-01 | Dynamic Loss: 4.577e-01 | Regularization Loss: 2.182e-07 | Val Loss: 4.514e-01 | Time: 7.47s
2025-08-15 03:10:59,416:INFO:New best model found at epoch 2700 with validation loss 4.514e-01. Saving...
2025-08-15 03:11:04,129:INFO:Epoch: 2750/10000 | Train Loss: 4.543e-01 | Dynamic Loss: 4.543e-01 | Regularization Loss: 2.149e-07 | Val Loss: 4.511e-01 | Time: 4.70s
2025-08-15 03:11:04,129:INFO:New best model found at epoch 2750 with validation loss 4.511e-01. Saving...
2025-08-15 03:11:08,915:INFO:Epoch: 2800/10000 | Train Loss: 4.536e-01 | Dynamic Loss: 4.536e-01 | Regularization Loss: 2.135e-07 | Val Loss: 4.495e-01 | Time: 4.78s
2025-08-15 03:11:08,915:INFO:New best model found at epoch 2800 with validation loss 4.495e-01. Saving...
2025-08-15 03:11:13,589:INFO:Epoch: 2850/10000 | Train Loss: 4.527e-01 | Dynamic Loss: 4.527e-01 | Regularization Loss: 2.097e-07 | Val Loss: 4.501e-01 | Time: 4.66s
2025-08-15 03:11:18,326:INFO:Epoch: 2900/10000 | Train Loss: 4.519e-01 | Dynamic Loss: 4.519e-01 | Regularization Loss: 2.082e-07 | Val Loss: 4.491e-01 | Time: 4.74s
2025-08-15 03:11:18,326:INFO:New best model found at epoch 2900 with validation loss 4.491e-01. Saving...
2025-08-15 03:11:27,422:INFO:Epoch: 2950/10000 | Train Loss: 4.521e-01 | Dynamic Loss: 4.521e-01 | Regularization Loss: 2.054e-07 | Val Loss: 4.477e-01 | Time: 9.09s
2025-08-15 03:11:27,422:INFO:New best model found at epoch 2950 with validation loss 4.477e-01. Saving...
2025-08-15 03:11:32,151:INFO:Epoch: 3000/10000 | Train Loss: 4.503e-01 | Dynamic Loss: 4.503e-01 | Regularization Loss: 2.022e-07 | Val Loss: 4.464e-01 | Time: 4.72s
2025-08-15 03:11:32,151:INFO:New best model found at epoch 3000 with validation loss 4.464e-01. Saving...
2025-08-15 03:11:36,890:INFO:Epoch: 3050/10000 | Train Loss: 4.487e-01 | Dynamic Loss: 4.487e-01 | Regularization Loss: 2.007e-07 | Val Loss: 4.461e-01 | Time: 4.73s
2025-08-15 03:11:36,890:INFO:New best model found at epoch 3050 with validation loss 4.461e-01. Saving...
2025-08-15 03:11:41,583:INFO:Epoch: 3100/10000 | Train Loss: 4.474e-01 | Dynamic Loss: 4.474e-01 | Regularization Loss: 1.980e-07 | Val Loss: 4.449e-01 | Time: 4.68s
2025-08-15 03:11:41,583:INFO:New best model found at epoch 3100 with validation loss 4.449e-01. Saving...
2025-08-15 03:11:46,331:INFO:Epoch: 3150/10000 | Train Loss: 4.479e-01 | Dynamic Loss: 4.479e-01 | Regularization Loss: 1.968e-07 | Val Loss: 4.436e-01 | Time: 4.74s
2025-08-15 03:11:46,331:INFO:New best model found at epoch 3150 with validation loss 4.436e-01. Saving...
2025-08-15 03:11:56,863:INFO:Epoch: 3200/10000 | Train Loss: 4.460e-01 | Dynamic Loss: 4.460e-01 | Regularization Loss: 1.940e-07 | Val Loss: 4.422e-01 | Time: 10.52s
2025-08-15 03:11:56,863:INFO:New best model found at epoch 3200 with validation loss 4.422e-01. Saving...
2025-08-15 03:12:01,604:INFO:Epoch: 3250/10000 | Train Loss: 4.444e-01 | Dynamic Loss: 4.444e-01 | Regularization Loss: 1.927e-07 | Val Loss: 4.427e-01 | Time: 4.73s
2025-08-15 03:12:06,376:INFO:Epoch: 3300/10000 | Train Loss: 4.429e-01 | Dynamic Loss: 4.429e-01 | Regularization Loss: 1.909e-07 | Val Loss: 4.414e-01 | Time: 4.77s
2025-08-15 03:12:06,376:INFO:New best model found at epoch 3300 with validation loss 4.414e-01. Saving...
2025-08-15 03:12:11,066:INFO:Epoch: 3350/10000 | Train Loss: 4.421e-01 | Dynamic Loss: 4.421e-01 | Regularization Loss: 1.882e-07 | Val Loss: 4.402e-01 | Time: 4.68s
2025-08-15 03:12:11,066:INFO:New best model found at epoch 3350 with validation loss 4.402e-01. Saving...
2025-08-15 03:12:19,482:INFO:Epoch: 3400/10000 | Train Loss: 4.419e-01 | Dynamic Loss: 4.419e-01 | Regularization Loss: 1.871e-07 | Val Loss: 4.395e-01 | Time: 8.41s
2025-08-15 03:12:19,482:INFO:New best model found at epoch 3400 with validation loss 4.395e-01. Saving...
2025-08-15 03:12:24,248:INFO:Epoch: 3450/10000 | Train Loss: 4.418e-01 | Dynamic Loss: 4.418e-01 | Regularization Loss: 1.851e-07 | Val Loss: 4.403e-01 | Time: 4.76s
2025-08-15 03:12:29,024:INFO:Epoch: 3500/10000 | Train Loss: 4.411e-01 | Dynamic Loss: 4.411e-01 | Regularization Loss: 1.847e-07 | Val Loss: 4.384e-01 | Time: 4.78s
2025-08-15 03:12:29,024:INFO:New best model found at epoch 3500 with validation loss 4.384e-01. Saving...
2025-08-15 03:12:33,677:INFO:Epoch: 3550/10000 | Train Loss: 4.406e-01 | Dynamic Loss: 4.406e-01 | Regularization Loss: 1.836e-07 | Val Loss: 4.381e-01 | Time: 4.64s
2025-08-15 03:12:33,677:INFO:New best model found at epoch 3550 with validation loss 4.381e-01. Saving...
2025-08-15 03:12:38,419:INFO:Epoch: 3600/10000 | Train Loss: 4.396e-01 | Dynamic Loss: 4.396e-01 | Regularization Loss: 1.820e-07 | Val Loss: 4.384e-01 | Time: 4.73s
2025-08-15 03:12:47,950:INFO:Epoch: 3650/10000 | Train Loss: 4.389e-01 | Dynamic Loss: 4.389e-01 | Regularization Loss: 1.805e-07 | Val Loss: 4.381e-01 | Time: 9.53s
2025-08-15 03:12:52,675:INFO:Epoch: 3700/10000 | Train Loss: 4.380e-01 | Dynamic Loss: 4.380e-01 | Regularization Loss: 1.795e-07 | Val Loss: 4.372e-01 | Time: 4.72s
2025-08-15 03:12:52,675:INFO:New best model found at epoch 3700 with validation loss 4.372e-01. Saving...
2025-08-15 03:12:57,403:INFO:Epoch: 3750/10000 | Train Loss: 4.374e-01 | Dynamic Loss: 4.374e-01 | Regularization Loss: 1.776e-07 | Val Loss: 4.371e-01 | Time: 4.72s
2025-08-15 03:12:57,404:INFO:New best model found at epoch 3750 with validation loss 4.371e-01. Saving...
2025-08-15 03:13:02,147:INFO:Epoch: 3800/10000 | Train Loss: 4.382e-01 | Dynamic Loss: 4.382e-01 | Regularization Loss: 1.768e-07 | Val Loss: 4.364e-01 | Time: 4.73s
2025-08-15 03:13:02,147:INFO:New best model found at epoch 3800 with validation loss 4.364e-01. Saving...
2025-08-15 03:13:06,977:INFO:Epoch: 3850/10000 | Train Loss: 4.366e-01 | Dynamic Loss: 4.366e-01 | Regularization Loss: 1.749e-07 | Val Loss: 4.351e-01 | Time: 4.82s
2025-08-15 03:13:06,977:INFO:New best model found at epoch 3850 with validation loss 4.351e-01. Saving...
2025-08-15 03:13:11,743:INFO:Epoch: 3900/10000 | Train Loss: 4.350e-01 | Dynamic Loss: 4.350e-01 | Regularization Loss: 1.730e-07 | Val Loss: 4.361e-01 | Time: 4.76s
2025-08-15 03:13:16,520:INFO:Epoch: 3950/10000 | Train Loss: 4.342e-01 | Dynamic Loss: 4.342e-01 | Regularization Loss: 1.715e-07 | Val Loss: 4.332e-01 | Time: 4.78s
2025-08-15 03:13:16,520:INFO:New best model found at epoch 3950 with validation loss 4.332e-01. Saving...
2025-08-15 03:13:21,342:INFO:Epoch: 4000/10000 | Train Loss: 4.320e-01 | Dynamic Loss: 4.320e-01 | Regularization Loss: 1.696e-07 | Val Loss: 4.326e-01 | Time: 4.81s
2025-08-15 03:13:21,343:INFO:New best model found at epoch 4000 with validation loss 4.326e-01. Saving...
2025-08-15 03:13:26,118:INFO:Epoch: 4050/10000 | Train Loss: 4.313e-01 | Dynamic Loss: 4.313e-01 | Regularization Loss: 1.675e-07 | Val Loss: 4.306e-01 | Time: 4.76s
2025-08-15 03:13:26,118:INFO:New best model found at epoch 4050 with validation loss 4.306e-01. Saving...
2025-08-15 03:13:35,495:INFO:Epoch: 4100/10000 | Train Loss: 4.281e-01 | Dynamic Loss: 4.281e-01 | Regularization Loss: 1.650e-07 | Val Loss: 4.296e-01 | Time: 9.37s
2025-08-15 03:13:35,495:INFO:New best model found at epoch 4100 with validation loss 4.296e-01. Saving...
2025-08-15 03:13:40,246:INFO:Epoch: 4150/10000 | Train Loss: 4.273e-01 | Dynamic Loss: 4.273e-01 | Regularization Loss: 1.638e-07 | Val Loss: 4.282e-01 | Time: 4.74s
2025-08-15 03:13:40,246:INFO:New best model found at epoch 4150 with validation loss 4.282e-01. Saving...
2025-08-15 03:13:45,384:INFO:Epoch: 4200/10000 | Train Loss: 4.281e-01 | Dynamic Loss: 4.281e-01 | Regularization Loss: 1.608e-07 | Val Loss: 4.282e-01 | Time: 5.13s
2025-08-15 03:13:45,384:INFO:New best model found at epoch 4200 with validation loss 4.282e-01. Saving...
2025-08-15 03:13:50,121:INFO:Epoch: 4250/10000 | Train Loss: 4.251e-01 | Dynamic Loss: 4.251e-01 | Regularization Loss: 1.594e-07 | Val Loss: 4.267e-01 | Time: 4.73s
2025-08-15 03:13:50,121:INFO:New best model found at epoch 4250 with validation loss 4.267e-01. Saving...
2025-08-15 03:13:54,809:INFO:Epoch: 4300/10000 | Train Loss: 4.243e-01 | Dynamic Loss: 4.243e-01 | Regularization Loss: 1.572e-07 | Val Loss: 4.265e-01 | Time: 4.68s
2025-08-15 03:13:54,809:INFO:New best model found at epoch 4300 with validation loss 4.265e-01. Saving...
2025-08-15 03:14:03,985:INFO:Epoch: 4350/10000 | Train Loss: 4.227e-01 | Dynamic Loss: 4.227e-01 | Regularization Loss: 1.563e-07 | Val Loss: 4.259e-01 | Time: 9.17s
2025-08-15 03:14:03,985:INFO:New best model found at epoch 4350 with validation loss 4.259e-01. Saving...
2025-08-15 03:14:08,761:INFO:Epoch: 4400/10000 | Train Loss: 4.225e-01 | Dynamic Loss: 4.225e-01 | Regularization Loss: 1.558e-07 | Val Loss: 4.249e-01 | Time: 4.77s
2025-08-15 03:14:08,761:INFO:New best model found at epoch 4400 with validation loss 4.249e-01. Saving...
2025-08-15 03:14:13,577:INFO:Epoch: 4450/10000 | Train Loss: 4.222e-01 | Dynamic Loss: 4.222e-01 | Regularization Loss: 1.547e-07 | Val Loss: 4.253e-01 | Time: 4.81s
2025-08-15 03:14:18,306:INFO:Epoch: 4500/10000 | Train Loss: 4.217e-01 | Dynamic Loss: 4.217e-01 | Regularization Loss: 1.530e-07 | Val Loss: 4.264e-01 | Time: 4.73s
2025-08-15 03:14:23,064:INFO:Epoch: 4550/10000 | Train Loss: 4.217e-01 | Dynamic Loss: 4.217e-01 | Regularization Loss: 1.516e-07 | Val Loss: 4.241e-01 | Time: 4.76s
2025-08-15 03:14:23,064:INFO:New best model found at epoch 4550 with validation loss 4.241e-01. Saving...
2025-08-15 03:14:30,782:INFO:Epoch: 4600/10000 | Train Loss: 4.188e-01 | Dynamic Loss: 4.188e-01 | Regularization Loss: 1.504e-07 | Val Loss: 4.233e-01 | Time: 7.71s
2025-08-15 03:14:30,782:INFO:New best model found at epoch 4600 with validation loss 4.233e-01. Saving...
2025-08-15 03:14:35,568:INFO:Epoch: 4650/10000 | Train Loss: 4.190e-01 | Dynamic Loss: 4.190e-01 | Regularization Loss: 1.498e-07 | Val Loss: 4.230e-01 | Time: 4.78s
2025-08-15 03:14:35,568:INFO:New best model found at epoch 4650 with validation loss 4.230e-01. Saving...
2025-08-15 03:14:40,299:INFO:Epoch: 4700/10000 | Train Loss: 4.189e-01 | Dynamic Loss: 4.189e-01 | Regularization Loss: 1.497e-07 | Val Loss: 4.225e-01 | Time: 4.72s
2025-08-15 03:14:40,299:INFO:New best model found at epoch 4700 with validation loss 4.225e-01. Saving...
2025-08-15 03:14:45,006:INFO:Epoch: 4750/10000 | Train Loss: 4.199e-01 | Dynamic Loss: 4.199e-01 | Regularization Loss: 1.483e-07 | Val Loss: 4.224e-01 | Time: 4.70s
2025-08-15 03:14:45,006:INFO:New best model found at epoch 4750 with validation loss 4.224e-01. Saving...
2025-08-15 03:14:49,726:INFO:Epoch: 4800/10000 | Train Loss: 4.189e-01 | Dynamic Loss: 4.189e-01 | Regularization Loss: 1.475e-07 | Val Loss: 4.229e-01 | Time: 4.71s
2025-08-15 03:14:57,983:INFO:Epoch: 4850/10000 | Train Loss: 4.173e-01 | Dynamic Loss: 4.173e-01 | Regularization Loss: 1.458e-07 | Val Loss: 4.215e-01 | Time: 8.26s
2025-08-15 03:14:57,983:INFO:New best model found at epoch 4850 with validation loss 4.215e-01. Saving...
2025-08-15 03:15:02,772:INFO:Epoch: 4900/10000 | Train Loss: 4.156e-01 | Dynamic Loss: 4.156e-01 | Regularization Loss: 1.449e-07 | Val Loss: 4.222e-01 | Time: 4.78s
2025-08-15 03:15:07,590:INFO:Epoch: 4950/10000 | Train Loss: 4.160e-01 | Dynamic Loss: 4.160e-01 | Regularization Loss: 1.429e-07 | Val Loss: 4.208e-01 | Time: 4.82s
2025-08-15 03:15:07,591:INFO:New best model found at epoch 4950 with validation loss 4.208e-01. Saving...
2025-08-15 03:15:12,461:INFO:Epoch: 5000/10000 | Train Loss: 4.147e-01 | Dynamic Loss: 4.147e-01 | Regularization Loss: 1.429e-07 | Val Loss: 4.207e-01 | Time: 4.86s
2025-08-15 03:15:12,461:INFO:New best model found at epoch 5000 with validation loss 4.207e-01. Saving...
2025-08-15 03:15:17,179:INFO:Epoch: 5050/10000 | Train Loss: 4.144e-01 | Dynamic Loss: 4.144e-01 | Regularization Loss: 1.420e-07 | Val Loss: 4.198e-01 | Time: 4.71s
2025-08-15 03:15:17,180:INFO:New best model found at epoch 5050 with validation loss 4.198e-01. Saving...
2025-08-15 03:15:25,577:INFO:Epoch: 5100/10000 | Train Loss: 4.131e-01 | Dynamic Loss: 4.131e-01 | Regularization Loss: 1.412e-07 | Val Loss: 4.186e-01 | Time: 8.39s
2025-08-15 03:15:25,577:INFO:New best model found at epoch 5100 with validation loss 4.186e-01. Saving...
2025-08-15 03:15:30,334:INFO:Epoch: 5150/10000 | Train Loss: 4.119e-01 | Dynamic Loss: 4.119e-01 | Regularization Loss: 1.385e-07 | Val Loss: 4.162e-01 | Time: 4.75s
2025-08-15 03:15:30,334:INFO:New best model found at epoch 5150 with validation loss 4.162e-01. Saving...
2025-08-15 03:15:35,050:INFO:Epoch: 5200/10000 | Train Loss: 4.086e-01 | Dynamic Loss: 4.086e-01 | Regularization Loss: 1.370e-07 | Val Loss: 4.156e-01 | Time: 4.71s
2025-08-15 03:15:35,050:INFO:New best model found at epoch 5200 with validation loss 4.156e-01. Saving...
2025-08-15 03:15:39,921:INFO:Epoch: 5250/10000 | Train Loss: 4.101e-01 | Dynamic Loss: 4.101e-01 | Regularization Loss: 1.355e-07 | Val Loss: 4.142e-01 | Time: 4.86s
2025-08-15 03:15:39,921:INFO:New best model found at epoch 5250 with validation loss 4.142e-01. Saving...
2025-08-15 03:15:44,634:INFO:Epoch: 5300/10000 | Train Loss: 4.092e-01 | Dynamic Loss: 4.092e-01 | Regularization Loss: 1.351e-07 | Val Loss: 4.142e-01 | Time: 4.70s
2025-08-15 03:15:54,989:INFO:Epoch: 5350/10000 | Train Loss: 4.070e-01 | Dynamic Loss: 4.070e-01 | Regularization Loss: 1.331e-07 | Val Loss: 4.133e-01 | Time: 10.35s
2025-08-15 03:15:54,989:INFO:New best model found at epoch 5350 with validation loss 4.133e-01. Saving...
2025-08-15 03:15:59,934:INFO:Epoch: 5400/10000 | Train Loss: 4.054e-01 | Dynamic Loss: 4.054e-01 | Regularization Loss: 1.333e-07 | Val Loss: 4.120e-01 | Time: 4.94s
2025-08-15 03:15:59,934:INFO:New best model found at epoch 5400 with validation loss 4.120e-01. Saving...
2025-08-15 03:16:04,666:INFO:Epoch: 5450/10000 | Train Loss: 4.055e-01 | Dynamic Loss: 4.055e-01 | Regularization Loss: 1.324e-07 | Val Loss: 4.116e-01 | Time: 4.72s
2025-08-15 03:16:04,666:INFO:New best model found at epoch 5450 with validation loss 4.116e-01. Saving...
2025-08-15 03:16:09,402:INFO:Epoch: 5500/10000 | Train Loss: 4.065e-01 | Dynamic Loss: 4.065e-01 | Regularization Loss: 1.316e-07 | Val Loss: 4.116e-01 | Time: 4.73s
2025-08-15 03:16:14,421:INFO:Epoch: 5550/10000 | Train Loss: 4.037e-01 | Dynamic Loss: 4.037e-01 | Regularization Loss: 1.289e-07 | Val Loss: 4.103e-01 | Time: 5.02s
2025-08-15 03:16:14,421:INFO:New best model found at epoch 5550 with validation loss 4.103e-01. Saving...
2025-08-15 03:16:19,185:INFO:Epoch: 5600/10000 | Train Loss: 4.046e-01 | Dynamic Loss: 4.046e-01 | Regularization Loss: 1.285e-07 | Val Loss: 4.097e-01 | Time: 4.76s
2025-08-15 03:16:19,186:INFO:New best model found at epoch 5600 with validation loss 4.097e-01. Saving...
2025-08-15 03:16:24,000:INFO:Epoch: 5650/10000 | Train Loss: 4.017e-01 | Dynamic Loss: 4.017e-01 | Regularization Loss: 1.297e-07 | Val Loss: 4.095e-01 | Time: 4.80s
2025-08-15 03:16:24,000:INFO:New best model found at epoch 5650 with validation loss 4.095e-01. Saving...
2025-08-15 03:16:28,745:INFO:Epoch: 5700/10000 | Train Loss: 4.027e-01 | Dynamic Loss: 4.027e-01 | Regularization Loss: 1.279e-07 | Val Loss: 4.092e-01 | Time: 4.74s
2025-08-15 03:16:28,745:INFO:New best model found at epoch 5700 with validation loss 4.092e-01. Saving...
2025-08-15 03:16:33,477:INFO:Epoch: 5750/10000 | Train Loss: 4.011e-01 | Dynamic Loss: 4.011e-01 | Regularization Loss: 1.246e-07 | Val Loss: 4.087e-01 | Time: 4.72s
2025-08-15 03:16:33,477:INFO:New best model found at epoch 5750 with validation loss 4.087e-01. Saving...
2025-08-15 03:16:43,970:INFO:Epoch: 5800/10000 | Train Loss: 4.007e-01 | Dynamic Loss: 4.007e-01 | Regularization Loss: 1.258e-07 | Val Loss: 4.086e-01 | Time: 10.48s
2025-08-15 03:16:43,970:INFO:New best model found at epoch 5800 with validation loss 4.086e-01. Saving...
2025-08-15 03:16:48,932:INFO:Epoch: 5850/10000 | Train Loss: 4.003e-01 | Dynamic Loss: 4.003e-01 | Regularization Loss: 1.250e-07 | Val Loss: 4.098e-01 | Time: 4.95s
2025-08-15 03:16:53,754:INFO:Epoch: 5900/10000 | Train Loss: 3.978e-01 | Dynamic Loss: 3.978e-01 | Regularization Loss: 1.224e-07 | Val Loss: 4.073e-01 | Time: 4.82s
2025-08-15 03:16:53,754:INFO:New best model found at epoch 5900 with validation loss 4.073e-01. Saving...
2025-08-15 03:16:58,564:INFO:Epoch: 5950/10000 | Train Loss: 3.980e-01 | Dynamic Loss: 3.980e-01 | Regularization Loss: 1.213e-07 | Val Loss: 4.070e-01 | Time: 4.80s
2025-08-15 03:16:58,564:INFO:New best model found at epoch 5950 with validation loss 4.070e-01. Saving...
2025-08-15 03:17:03,356:INFO:Epoch: 6000/10000 | Train Loss: 3.963e-01 | Dynamic Loss: 3.963e-01 | Regularization Loss: 1.197e-07 | Val Loss: 4.066e-01 | Time: 4.78s
2025-08-15 03:17:03,356:INFO:New best model found at epoch 6000 with validation loss 4.066e-01. Saving...
2025-08-15 03:17:14,104:INFO:Epoch: 6050/10000 | Train Loss: 3.969e-01 | Dynamic Loss: 3.969e-01 | Regularization Loss: 1.197e-07 | Val Loss: 4.073e-01 | Time: 10.74s
2025-08-15 03:17:18,922:INFO:Epoch: 6100/10000 | Train Loss: 3.952e-01 | Dynamic Loss: 3.952e-01 | Regularization Loss: 1.189e-07 | Val Loss: 4.073e-01 | Time: 4.82s
2025-08-15 03:17:24,022:INFO:Epoch: 6150/10000 | Train Loss: 3.939e-01 | Dynamic Loss: 3.939e-01 | Regularization Loss: 1.171e-07 | Val Loss: 4.057e-01 | Time: 5.10s
2025-08-15 03:17:24,022:INFO:New best model found at epoch 6150 with validation loss 4.057e-01. Saving...
2025-08-15 03:17:28,836:INFO:Epoch: 6200/10000 | Train Loss: 3.914e-01 | Dynamic Loss: 3.914e-01 | Regularization Loss: 1.151e-07 | Val Loss: 4.045e-01 | Time: 4.80s
2025-08-15 03:17:28,836:INFO:New best model found at epoch 6200 with validation loss 4.045e-01. Saving...
2025-08-15 03:17:33,629:INFO:Epoch: 6250/10000 | Train Loss: 3.917e-01 | Dynamic Loss: 3.917e-01 | Regularization Loss: 1.137e-07 | Val Loss: 4.041e-01 | Time: 4.78s
2025-08-15 03:17:33,630:INFO:New best model found at epoch 6250 with validation loss 4.041e-01. Saving...
2025-08-15 03:17:45,337:INFO:Epoch: 6300/10000 | Train Loss: 3.913e-01 | Dynamic Loss: 3.913e-01 | Regularization Loss: 1.133e-07 | Val Loss: 4.040e-01 | Time: 11.70s
2025-08-15 03:17:45,337:INFO:New best model found at epoch 6300 with validation loss 4.040e-01. Saving...
2025-08-15 03:17:50,251:INFO:Epoch: 6350/10000 | Train Loss: 3.892e-01 | Dynamic Loss: 3.892e-01 | Regularization Loss: 1.131e-07 | Val Loss: 4.028e-01 | Time: 4.90s
2025-08-15 03:17:50,252:INFO:New best model found at epoch 6350 with validation loss 4.028e-01. Saving...
2025-08-15 03:17:55,143:INFO:Epoch: 6400/10000 | Train Loss: 3.908e-01 | Dynamic Loss: 3.908e-01 | Regularization Loss: 1.120e-07 | Val Loss: 4.027e-01 | Time: 4.88s
2025-08-15 03:17:55,143:INFO:New best model found at epoch 6400 with validation loss 4.027e-01. Saving...
2025-08-15 03:17:59,906:INFO:Epoch: 6450/10000 | Train Loss: 3.907e-01 | Dynamic Loss: 3.907e-01 | Regularization Loss: 1.113e-07 | Val Loss: 4.051e-01 | Time: 4.75s
2025-08-15 03:18:04,658:INFO:Epoch: 6500/10000 | Train Loss: 3.900e-01 | Dynamic Loss: 3.900e-01 | Regularization Loss: 1.095e-07 | Val Loss: 4.027e-01 | Time: 4.75s
2025-08-15 03:18:16,317:INFO:Epoch: 6550/10000 | Train Loss: 3.841e-01 | Dynamic Loss: 3.840e-01 | Regularization Loss: 1.096e-07 | Val Loss: 3.998e-01 | Time: 11.66s
2025-08-15 03:18:16,317:INFO:New best model found at epoch 6550 with validation loss 3.998e-01. Saving...
2025-08-15 03:18:21,113:INFO:Epoch: 6600/10000 | Train Loss: 3.837e-01 | Dynamic Loss: 3.837e-01 | Regularization Loss: 1.056e-07 | Val Loss: 3.995e-01 | Time: 4.79s
2025-08-15 03:18:21,113:INFO:New best model found at epoch 6600 with validation loss 3.995e-01. Saving...
2025-08-15 03:18:25,904:INFO:Epoch: 6650/10000 | Train Loss: 3.815e-01 | Dynamic Loss: 3.815e-01 | Regularization Loss: 1.062e-07 | Val Loss: 3.987e-01 | Time: 4.78s
2025-08-15 03:18:25,904:INFO:New best model found at epoch 6650 with validation loss 3.987e-01. Saving...
2025-08-15 03:18:30,751:INFO:Epoch: 6700/10000 | Train Loss: 3.814e-01 | Dynamic Loss: 3.814e-01 | Regularization Loss: 1.051e-07 | Val Loss: 3.961e-01 | Time: 4.84s
2025-08-15 03:18:30,751:INFO:New best model found at epoch 6700 with validation loss 3.961e-01. Saving...
2025-08-15 03:18:38,358:INFO:Epoch: 6750/10000 | Train Loss: 3.798e-01 | Dynamic Loss: 3.798e-01 | Regularization Loss: 1.061e-07 | Val Loss: 3.949e-01 | Time: 7.60s
2025-08-15 03:18:38,359:INFO:New best model found at epoch 6750 with validation loss 3.949e-01. Saving...
2025-08-15 03:18:43,136:INFO:Epoch: 6800/10000 | Train Loss: 3.790e-01 | Dynamic Loss: 3.790e-01 | Regularization Loss: 1.081e-07 | Val Loss: 3.942e-01 | Time: 4.77s
2025-08-15 03:18:43,136:INFO:New best model found at epoch 6800 with validation loss 3.942e-01. Saving...
2025-08-15 03:18:48,005:INFO:Epoch: 6850/10000 | Train Loss: 3.797e-01 | Dynamic Loss: 3.797e-01 | Regularization Loss: 1.160e-07 | Val Loss: 3.958e-01 | Time: 4.86s
2025-08-15 03:18:52,782:INFO:Epoch: 6900/10000 | Train Loss: 3.767e-01 | Dynamic Loss: 3.767e-01 | Regularization Loss: 9.085e-08 | Val Loss: 3.940e-01 | Time: 4.78s
2025-08-15 03:18:52,782:INFO:New best model found at epoch 6900 with validation loss 3.940e-01. Saving...
2025-08-15 03:18:57,540:INFO:Epoch: 6950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.75s
2025-08-15 03:19:05,384:INFO:Epoch: 7000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 7.84s
2025-08-15 03:19:10,269:INFO:Epoch: 7050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.89s
2025-08-15 03:19:15,075:INFO:Epoch: 7100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.81s
2025-08-15 03:19:19,825:INFO:Epoch: 7150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.75s
2025-08-15 03:19:24,624:INFO:Epoch: 7200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.80s
2025-08-15 03:19:32,274:INFO:Epoch: 7250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 7.65s
2025-08-15 03:19:37,092:INFO:Epoch: 7300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.82s
2025-08-15 03:19:41,884:INFO:Epoch: 7350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.79s
2025-08-15 03:19:46,658:INFO:Epoch: 7400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.77s
2025-08-15 03:19:51,440:INFO:Epoch: 7450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.78s
2025-08-15 03:19:58,627:INFO:Epoch: 7500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 7.19s
2025-08-15 03:20:03,438:INFO:Epoch: 7550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.81s
2025-08-15 03:20:08,251:INFO:Epoch: 7600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.81s
2025-08-15 03:20:13,043:INFO:Epoch: 7650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.79s
2025-08-15 03:20:17,845:INFO:Epoch: 7700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.80s
2025-08-15 03:20:26,752:INFO:Epoch: 7750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 8.91s
2025-08-15 03:20:31,590:INFO:Epoch: 7800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.84s
2025-08-15 03:20:36,504:INFO:Epoch: 7850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.91s
2025-08-15 03:20:41,405:INFO:Epoch: 7900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.90s
2025-08-15 03:20:46,236:INFO:Epoch: 7950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.83s
2025-08-15 03:20:55,243:INFO:Epoch: 8000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 9.01s
2025-08-15 03:21:00,039:INFO:Epoch: 8050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.80s
2025-08-15 03:21:04,842:INFO:Epoch: 8100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.80s
2025-08-15 03:21:09,665:INFO:Epoch: 8150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.82s
2025-08-15 03:21:14,413:INFO:Epoch: 8200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.75s
2025-08-15 03:21:21,955:INFO:Epoch: 8250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 7.54s
2025-08-15 03:21:26,842:INFO:Epoch: 8300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.89s
2025-08-15 03:21:31,728:INFO:Epoch: 8350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.89s
2025-08-15 03:21:36,584:INFO:Epoch: 8400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.86s
2025-08-15 03:21:41,436:INFO:Epoch: 8450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.85s
2025-08-15 03:21:52,177:INFO:Epoch: 8500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 10.74s
2025-08-15 03:21:57,001:INFO:Epoch: 8550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.82s
2025-08-15 03:22:01,761:INFO:Epoch: 8600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.76s
2025-08-15 03:22:06,570:INFO:Epoch: 8650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.81s
2025-08-15 03:22:11,348:INFO:Epoch: 8700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.78s
2025-08-15 03:22:22,638:INFO:Epoch: 8750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 11.29s
2025-08-15 03:22:27,575:INFO:Epoch: 8800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.94s
2025-08-15 03:22:32,463:INFO:Epoch: 8850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.89s
2025-08-15 03:22:37,208:INFO:Epoch: 8900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.74s
2025-08-15 03:22:41,970:INFO:Epoch: 8950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.76s
2025-08-15 03:22:54,086:INFO:Epoch: 9000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 12.12s
2025-08-15 03:22:58,952:INFO:Epoch: 9050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.87s
2025-08-15 03:23:03,856:INFO:Epoch: 9100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.90s
2025-08-15 03:23:08,693:INFO:Epoch: 9150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.84s
2025-08-15 03:23:13,516:INFO:Epoch: 9200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.82s
2025-08-15 03:23:21,831:INFO:Epoch: 9250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 8.31s
2025-08-15 03:23:26,647:INFO:Epoch: 9300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.82s
2025-08-15 03:23:31,499:INFO:Epoch: 9350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.85s
2025-08-15 03:23:36,281:INFO:Epoch: 9400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.78s
2025-08-15 03:23:41,106:INFO:Epoch: 9450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.82s
2025-08-15 03:23:48,673:INFO:Epoch: 9500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 7.57s
2025-08-15 03:23:53,592:INFO:Epoch: 9550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.92s
2025-08-15 03:23:58,485:INFO:Epoch: 9600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.89s
2025-08-15 03:24:03,419:INFO:Epoch: 9650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.93s
2025-08-15 03:24:08,319:INFO:Epoch: 9700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.90s
2025-08-15 03:24:15,327:INFO:Epoch: 9750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 7.01s
2025-08-15 03:24:20,207:INFO:Epoch: 9800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.88s
2025-08-15 03:24:25,019:INFO:Epoch: 9850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.81s
2025-08-15 03:24:29,923:INFO:Epoch: 9900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.90s
2025-08-15 03:24:34,814:INFO:Epoch: 9950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.89s
2025-08-15 03:24:42,057:INFO:Epoch: 10000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 7.24s
