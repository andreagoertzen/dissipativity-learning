2025-08-15 02:45:30,074:INFO:Created DataLoaders with 2994 training samples and 998 validation samples.
2025-08-15 02:45:30,734:INFO:model params: 479490
2025-08-15 02:45:31,519:INFO:Epoch: 0/10000 | Train Loss: 5.094e+00 | Dynamic Loss: 5.094e+00 | Regularization Loss: 6.195e-18 | Val Loss: 3.413e+00 | Time: 0.78s
2025-08-15 02:45:31,520:INFO:New best model found at epoch 0 with validation loss 3.413e+00. Saving...
2025-08-15 02:45:36,227:INFO:Epoch: 50/10000 | Train Loss: 9.023e-01 | Dynamic Loss: 9.023e-01 | Regularization Loss: 2.074e-14 | Val Loss: 9.511e-01 | Time: 4.60s
2025-08-15 02:45:36,227:INFO:New best model found at epoch 50 with validation loss 9.511e-01. Saving...
2025-08-15 02:45:40,945:INFO:Epoch: 100/10000 | Train Loss: 7.129e-01 | Dynamic Loss: 7.129e-01 | Regularization Loss: 1.868e-08 | Val Loss: 7.449e-01 | Time: 4.71s
2025-08-15 02:45:40,945:INFO:New best model found at epoch 100 with validation loss 7.449e-01. Saving...
2025-08-15 02:45:45,510:INFO:Epoch: 150/10000 | Train Loss: 6.439e-01 | Dynamic Loss: 6.439e-01 | Regularization Loss: 5.893e-07 | Val Loss: 6.644e-01 | Time: 4.56s
2025-08-15 02:45:45,510:INFO:New best model found at epoch 150 with validation loss 6.644e-01. Saving...
2025-08-15 02:45:50,041:INFO:Epoch: 200/10000 | Train Loss: 6.105e-01 | Dynamic Loss: 6.105e-01 | Regularization Loss: 5.887e-07 | Val Loss: 6.242e-01 | Time: 4.52s
2025-08-15 02:45:50,041:INFO:New best model found at epoch 200 with validation loss 6.242e-01. Saving...
2025-08-15 02:45:54,642:INFO:Epoch: 250/10000 | Train Loss: 5.887e-01 | Dynamic Loss: 5.887e-01 | Regularization Loss: 5.724e-07 | Val Loss: 6.002e-01 | Time: 4.59s
2025-08-15 02:45:54,642:INFO:New best model found at epoch 250 with validation loss 6.002e-01. Saving...
2025-08-15 02:46:04,565:INFO:Epoch: 300/10000 | Train Loss: 5.786e-01 | Dynamic Loss: 5.786e-01 | Regularization Loss: 5.559e-07 | Val Loss: 5.843e-01 | Time: 9.91s
2025-08-15 02:46:04,565:INFO:New best model found at epoch 300 with validation loss 5.843e-01. Saving...
2025-08-15 02:46:09,217:INFO:Epoch: 350/10000 | Train Loss: 5.733e-01 | Dynamic Loss: 5.733e-01 | Regularization Loss: 5.397e-07 | Val Loss: 5.730e-01 | Time: 4.64s
2025-08-15 02:46:09,217:INFO:New best model found at epoch 350 with validation loss 5.730e-01. Saving...
2025-08-15 02:46:13,764:INFO:Epoch: 400/10000 | Train Loss: 5.640e-01 | Dynamic Loss: 5.640e-01 | Regularization Loss: 5.216e-07 | Val Loss: 5.668e-01 | Time: 4.54s
2025-08-15 02:46:13,764:INFO:New best model found at epoch 400 with validation loss 5.668e-01. Saving...
2025-08-15 02:46:18,326:INFO:Epoch: 450/10000 | Train Loss: 5.602e-01 | Dynamic Loss: 5.602e-01 | Regularization Loss: 5.070e-07 | Val Loss: 5.572e-01 | Time: 4.55s
2025-08-15 02:46:18,326:INFO:New best model found at epoch 450 with validation loss 5.572e-01. Saving...
2025-08-15 02:46:29,115:INFO:Epoch: 500/10000 | Train Loss: 5.577e-01 | Dynamic Loss: 5.577e-01 | Regularization Loss: 4.926e-07 | Val Loss: 5.512e-01 | Time: 10.78s
2025-08-15 02:46:29,116:INFO:New best model found at epoch 500 with validation loss 5.512e-01. Saving...
2025-08-15 02:46:33,794:INFO:Epoch: 550/10000 | Train Loss: 5.514e-01 | Dynamic Loss: 5.514e-01 | Regularization Loss: 4.780e-07 | Val Loss: 5.470e-01 | Time: 4.67s
2025-08-15 02:46:33,794:INFO:New best model found at epoch 550 with validation loss 5.470e-01. Saving...
2025-08-15 02:46:38,516:INFO:Epoch: 600/10000 | Train Loss: 5.481e-01 | Dynamic Loss: 5.481e-01 | Regularization Loss: 4.632e-07 | Val Loss: 5.399e-01 | Time: 4.71s
2025-08-15 02:46:38,516:INFO:New best model found at epoch 600 with validation loss 5.399e-01. Saving...
2025-08-15 02:46:43,126:INFO:Epoch: 650/10000 | Train Loss: 5.429e-01 | Dynamic Loss: 5.429e-01 | Regularization Loss: 4.505e-07 | Val Loss: 5.368e-01 | Time: 4.60s
2025-08-15 02:46:43,127:INFO:New best model found at epoch 650 with validation loss 5.368e-01. Saving...
2025-08-15 02:46:47,843:INFO:Epoch: 700/10000 | Train Loss: 5.400e-01 | Dynamic Loss: 5.400e-01 | Regularization Loss: 4.356e-07 | Val Loss: 5.303e-01 | Time: 4.71s
2025-08-15 02:46:47,843:INFO:New best model found at epoch 700 with validation loss 5.303e-01. Saving...
2025-08-15 02:46:52,508:INFO:Epoch: 750/10000 | Train Loss: 5.349e-01 | Dynamic Loss: 5.349e-01 | Regularization Loss: 4.247e-07 | Val Loss: 5.274e-01 | Time: 4.66s
2025-08-15 02:46:52,508:INFO:New best model found at epoch 750 with validation loss 5.274e-01. Saving...
2025-08-15 02:46:57,199:INFO:Epoch: 800/10000 | Train Loss: 5.336e-01 | Dynamic Loss: 5.336e-01 | Regularization Loss: 4.138e-07 | Val Loss: 5.242e-01 | Time: 4.68s
2025-08-15 02:46:57,199:INFO:New best model found at epoch 800 with validation loss 5.242e-01. Saving...
2025-08-15 02:47:01,887:INFO:Epoch: 850/10000 | Train Loss: 5.299e-01 | Dynamic Loss: 5.299e-01 | Regularization Loss: 4.027e-07 | Val Loss: 5.188e-01 | Time: 4.68s
2025-08-15 02:47:01,887:INFO:New best model found at epoch 850 with validation loss 5.188e-01. Saving...
2025-08-15 02:47:07,335:INFO:Epoch: 900/10000 | Train Loss: 5.263e-01 | Dynamic Loss: 5.263e-01 | Regularization Loss: 3.933e-07 | Val Loss: 5.155e-01 | Time: 5.44s
2025-08-15 02:47:07,336:INFO:New best model found at epoch 900 with validation loss 5.155e-01. Saving...
2025-08-15 02:47:11,947:INFO:Epoch: 950/10000 | Train Loss: 5.239e-01 | Dynamic Loss: 5.239e-01 | Regularization Loss: 3.826e-07 | Val Loss: 5.125e-01 | Time: 4.60s
2025-08-15 02:47:11,947:INFO:New best model found at epoch 950 with validation loss 5.125e-01. Saving...
2025-08-15 02:47:16,593:INFO:Epoch: 1000/10000 | Train Loss: 5.238e-01 | Dynamic Loss: 5.238e-01 | Regularization Loss: 3.729e-07 | Val Loss: 5.099e-01 | Time: 4.64s
2025-08-15 02:47:16,594:INFO:New best model found at epoch 1000 with validation loss 5.099e-01. Saving...
2025-08-15 02:47:21,326:INFO:Epoch: 1050/10000 | Train Loss: 5.184e-01 | Dynamic Loss: 5.184e-01 | Regularization Loss: 3.636e-07 | Val Loss: 5.074e-01 | Time: 4.72s
2025-08-15 02:47:21,326:INFO:New best model found at epoch 1050 with validation loss 5.074e-01. Saving...
2025-08-15 02:47:25,999:INFO:Epoch: 1100/10000 | Train Loss: 5.161e-01 | Dynamic Loss: 5.161e-01 | Regularization Loss: 3.568e-07 | Val Loss: 5.051e-01 | Time: 4.66s
2025-08-15 02:47:25,999:INFO:New best model found at epoch 1100 with validation loss 5.051e-01. Saving...
2025-08-15 02:47:35,789:INFO:Epoch: 1150/10000 | Train Loss: 5.134e-01 | Dynamic Loss: 5.134e-01 | Regularization Loss: 3.478e-07 | Val Loss: 5.027e-01 | Time: 9.78s
2025-08-15 02:47:35,790:INFO:New best model found at epoch 1150 with validation loss 5.027e-01. Saving...
2025-08-15 02:47:40,452:INFO:Epoch: 1200/10000 | Train Loss: 5.113e-01 | Dynamic Loss: 5.113e-01 | Regularization Loss: 3.406e-07 | Val Loss: 4.990e-01 | Time: 4.65s
2025-08-15 02:47:40,452:INFO:New best model found at epoch 1200 with validation loss 4.990e-01. Saving...
2025-08-15 02:47:45,110:INFO:Epoch: 1250/10000 | Train Loss: 5.088e-01 | Dynamic Loss: 5.088e-01 | Regularization Loss: 3.352e-07 | Val Loss: 4.967e-01 | Time: 4.65s
2025-08-15 02:47:45,110:INFO:New best model found at epoch 1250 with validation loss 4.967e-01. Saving...
2025-08-15 02:47:49,823:INFO:Epoch: 1300/10000 | Train Loss: 5.076e-01 | Dynamic Loss: 5.076e-01 | Regularization Loss: 3.274e-07 | Val Loss: 4.947e-01 | Time: 4.70s
2025-08-15 02:47:49,824:INFO:New best model found at epoch 1300 with validation loss 4.947e-01. Saving...
2025-08-15 02:47:59,935:INFO:Epoch: 1350/10000 | Train Loss: 5.044e-01 | Dynamic Loss: 5.044e-01 | Regularization Loss: 3.217e-07 | Val Loss: 4.935e-01 | Time: 10.10s
2025-08-15 02:47:59,935:INFO:New best model found at epoch 1350 with validation loss 4.935e-01. Saving...
2025-08-15 02:48:04,546:INFO:Epoch: 1400/10000 | Train Loss: 5.022e-01 | Dynamic Loss: 5.022e-01 | Regularization Loss: 3.148e-07 | Val Loss: 4.905e-01 | Time: 4.60s
2025-08-15 02:48:04,547:INFO:New best model found at epoch 1400 with validation loss 4.905e-01. Saving...
2025-08-15 02:48:09,177:INFO:Epoch: 1450/10000 | Train Loss: 5.026e-01 | Dynamic Loss: 5.026e-01 | Regularization Loss: 3.090e-07 | Val Loss: 4.900e-01 | Time: 4.62s
2025-08-15 02:48:09,177:INFO:New best model found at epoch 1450 with validation loss 4.900e-01. Saving...
2025-08-15 02:48:13,787:INFO:Epoch: 1500/10000 | Train Loss: 5.005e-01 | Dynamic Loss: 5.005e-01 | Regularization Loss: 3.031e-07 | Val Loss: 4.871e-01 | Time: 4.60s
2025-08-15 02:48:13,787:INFO:New best model found at epoch 1500 with validation loss 4.871e-01. Saving...
2025-08-15 02:48:18,697:INFO:Epoch: 1550/10000 | Train Loss: 4.955e-01 | Dynamic Loss: 4.955e-01 | Regularization Loss: 2.977e-07 | Val Loss: 4.844e-01 | Time: 4.90s
2025-08-15 02:48:18,697:INFO:New best model found at epoch 1550 with validation loss 4.844e-01. Saving...
2025-08-15 02:48:23,351:INFO:Epoch: 1600/10000 | Train Loss: 4.958e-01 | Dynamic Loss: 4.958e-01 | Regularization Loss: 2.939e-07 | Val Loss: 4.834e-01 | Time: 4.65s
2025-08-15 02:48:23,352:INFO:New best model found at epoch 1600 with validation loss 4.834e-01. Saving...
2025-08-15 02:48:27,980:INFO:Epoch: 1650/10000 | Train Loss: 4.937e-01 | Dynamic Loss: 4.937e-01 | Regularization Loss: 2.891e-07 | Val Loss: 4.817e-01 | Time: 4.62s
2025-08-15 02:48:27,980:INFO:New best model found at epoch 1650 with validation loss 4.817e-01. Saving...
2025-08-15 02:48:32,632:INFO:Epoch: 1700/10000 | Train Loss: 4.914e-01 | Dynamic Loss: 4.914e-01 | Regularization Loss: 2.827e-07 | Val Loss: 4.817e-01 | Time: 4.64s
2025-08-15 02:48:32,632:INFO:New best model found at epoch 1700 with validation loss 4.817e-01. Saving...
2025-08-15 02:48:40,270:INFO:Epoch: 1750/10000 | Train Loss: 4.916e-01 | Dynamic Loss: 4.916e-01 | Regularization Loss: 2.792e-07 | Val Loss: 4.793e-01 | Time: 7.63s
2025-08-15 02:48:40,270:INFO:New best model found at epoch 1750 with validation loss 4.793e-01. Saving...
2025-08-15 02:48:45,046:INFO:Epoch: 1800/10000 | Train Loss: 4.892e-01 | Dynamic Loss: 4.892e-01 | Regularization Loss: 2.756e-07 | Val Loss: 4.793e-01 | Time: 4.77s
2025-08-15 02:48:45,046:INFO:New best model found at epoch 1800 with validation loss 4.793e-01. Saving...
2025-08-15 02:48:49,782:INFO:Epoch: 1850/10000 | Train Loss: 4.854e-01 | Dynamic Loss: 4.854e-01 | Regularization Loss: 2.693e-07 | Val Loss: 4.756e-01 | Time: 4.73s
2025-08-15 02:48:49,782:INFO:New best model found at epoch 1850 with validation loss 4.756e-01. Saving...
2025-08-15 02:48:54,392:INFO:Epoch: 1900/10000 | Train Loss: 4.848e-01 | Dynamic Loss: 4.848e-01 | Regularization Loss: 2.658e-07 | Val Loss: 4.770e-01 | Time: 4.60s
2025-08-15 02:48:59,041:INFO:Epoch: 1950/10000 | Train Loss: 4.847e-01 | Dynamic Loss: 4.847e-01 | Regularization Loss: 2.608e-07 | Val Loss: 4.728e-01 | Time: 4.65s
2025-08-15 02:48:59,041:INFO:New best model found at epoch 1950 with validation loss 4.728e-01. Saving...
2025-08-15 02:49:08,294:INFO:Epoch: 2000/10000 | Train Loss: 4.788e-01 | Dynamic Loss: 4.788e-01 | Regularization Loss: 2.565e-07 | Val Loss: 4.709e-01 | Time: 9.24s
2025-08-15 02:49:08,294:INFO:New best model found at epoch 2000 with validation loss 4.709e-01. Saving...
2025-08-15 02:49:12,955:INFO:Epoch: 2050/10000 | Train Loss: 4.828e-01 | Dynamic Loss: 4.828e-01 | Regularization Loss: 2.539e-07 | Val Loss: 4.737e-01 | Time: 4.65s
2025-08-15 02:49:17,590:INFO:Epoch: 2100/10000 | Train Loss: 4.773e-01 | Dynamic Loss: 4.773e-01 | Regularization Loss: 2.476e-07 | Val Loss: 4.677e-01 | Time: 4.63s
2025-08-15 02:49:17,590:INFO:New best model found at epoch 2100 with validation loss 4.677e-01. Saving...
2025-08-15 02:49:22,173:INFO:Epoch: 2150/10000 | Train Loss: 4.775e-01 | Dynamic Loss: 4.775e-01 | Regularization Loss: 2.418e-07 | Val Loss: 4.679e-01 | Time: 4.57s
2025-08-15 02:49:30,564:INFO:Epoch: 2200/10000 | Train Loss: 4.738e-01 | Dynamic Loss: 4.738e-01 | Regularization Loss: 2.368e-07 | Val Loss: 4.648e-01 | Time: 8.39s
2025-08-15 02:49:30,564:INFO:New best model found at epoch 2200 with validation loss 4.648e-01. Saving...
2025-08-15 02:49:35,320:INFO:Epoch: 2250/10000 | Train Loss: 4.680e-01 | Dynamic Loss: 4.680e-01 | Regularization Loss: 2.315e-07 | Val Loss: 4.625e-01 | Time: 4.75s
2025-08-15 02:49:35,320:INFO:New best model found at epoch 2250 with validation loss 4.625e-01. Saving...
2025-08-15 02:49:40,153:INFO:Epoch: 2300/10000 | Train Loss: 4.668e-01 | Dynamic Loss: 4.668e-01 | Regularization Loss: 2.278e-07 | Val Loss: 4.612e-01 | Time: 4.82s
2025-08-15 02:49:40,153:INFO:New best model found at epoch 2300 with validation loss 4.612e-01. Saving...
2025-08-15 02:49:44,815:INFO:Epoch: 2350/10000 | Train Loss: 4.638e-01 | Dynamic Loss: 4.638e-01 | Regularization Loss: 2.229e-07 | Val Loss: 4.593e-01 | Time: 4.65s
2025-08-15 02:49:44,815:INFO:New best model found at epoch 2350 with validation loss 4.593e-01. Saving...
2025-08-15 02:49:49,568:INFO:Epoch: 2400/10000 | Train Loss: 4.646e-01 | Dynamic Loss: 4.646e-01 | Regularization Loss: 2.202e-07 | Val Loss: 4.587e-01 | Time: 4.74s
2025-08-15 02:49:49,568:INFO:New best model found at epoch 2400 with validation loss 4.587e-01. Saving...
2025-08-15 02:49:54,295:INFO:Epoch: 2450/10000 | Train Loss: 4.627e-01 | Dynamic Loss: 4.627e-01 | Regularization Loss: 2.188e-07 | Val Loss: 4.564e-01 | Time: 4.72s
2025-08-15 02:49:54,295:INFO:New best model found at epoch 2450 with validation loss 4.564e-01. Saving...
2025-08-15 02:49:59,055:INFO:Epoch: 2500/10000 | Train Loss: 4.608e-01 | Dynamic Loss: 4.608e-01 | Regularization Loss: 2.156e-07 | Val Loss: 4.573e-01 | Time: 4.75s
2025-08-15 02:50:03,766:INFO:Epoch: 2550/10000 | Train Loss: 4.608e-01 | Dynamic Loss: 4.608e-01 | Regularization Loss: 2.134e-07 | Val Loss: 4.546e-01 | Time: 4.71s
2025-08-15 02:50:03,766:INFO:New best model found at epoch 2550 with validation loss 4.546e-01. Saving...
2025-08-15 02:50:08,355:INFO:Epoch: 2600/10000 | Train Loss: 4.587e-01 | Dynamic Loss: 4.587e-01 | Regularization Loss: 2.105e-07 | Val Loss: 4.551e-01 | Time: 4.58s
2025-08-15 02:50:16,964:INFO:Epoch: 2650/10000 | Train Loss: 4.585e-01 | Dynamic Loss: 4.585e-01 | Regularization Loss: 2.089e-07 | Val Loss: 4.537e-01 | Time: 8.61s
2025-08-15 02:50:16,965:INFO:New best model found at epoch 2650 with validation loss 4.537e-01. Saving...
2025-08-15 02:50:21,708:INFO:Epoch: 2700/10000 | Train Loss: 4.579e-01 | Dynamic Loss: 4.579e-01 | Regularization Loss: 2.067e-07 | Val Loss: 4.548e-01 | Time: 4.73s
2025-08-15 02:50:26,493:INFO:Epoch: 2750/10000 | Train Loss: 4.566e-01 | Dynamic Loss: 4.566e-01 | Regularization Loss: 2.051e-07 | Val Loss: 4.519e-01 | Time: 4.78s
2025-08-15 02:50:26,493:INFO:New best model found at epoch 2750 with validation loss 4.519e-01. Saving...
2025-08-15 02:50:31,162:INFO:Epoch: 2800/10000 | Train Loss: 4.556e-01 | Dynamic Loss: 4.556e-01 | Regularization Loss: 2.033e-07 | Val Loss: 4.532e-01 | Time: 4.66s
2025-08-15 02:50:35,786:INFO:Epoch: 2850/10000 | Train Loss: 4.535e-01 | Dynamic Loss: 4.535e-01 | Regularization Loss: 2.000e-07 | Val Loss: 4.515e-01 | Time: 4.62s
2025-08-15 02:50:35,786:INFO:New best model found at epoch 2850 with validation loss 4.515e-01. Saving...
2025-08-15 02:50:46,000:INFO:Epoch: 2900/10000 | Train Loss: 4.541e-01 | Dynamic Loss: 4.541e-01 | Regularization Loss: 1.989e-07 | Val Loss: 4.493e-01 | Time: 10.21s
2025-08-15 02:50:46,001:INFO:New best model found at epoch 2900 with validation loss 4.493e-01. Saving...
2025-08-15 02:50:50,723:INFO:Epoch: 2950/10000 | Train Loss: 4.535e-01 | Dynamic Loss: 4.535e-01 | Regularization Loss: 1.966e-07 | Val Loss: 4.504e-01 | Time: 4.71s
2025-08-15 02:50:55,555:INFO:Epoch: 3000/10000 | Train Loss: 4.514e-01 | Dynamic Loss: 4.514e-01 | Regularization Loss: 1.935e-07 | Val Loss: 4.478e-01 | Time: 4.83s
2025-08-15 02:50:55,555:INFO:New best model found at epoch 3000 with validation loss 4.478e-01. Saving...
2025-08-15 02:51:00,293:INFO:Epoch: 3050/10000 | Train Loss: 4.499e-01 | Dynamic Loss: 4.499e-01 | Regularization Loss: 1.918e-07 | Val Loss: 4.463e-01 | Time: 4.73s
2025-08-15 02:51:00,293:INFO:New best model found at epoch 3050 with validation loss 4.463e-01. Saving...
2025-08-15 02:51:05,132:INFO:Epoch: 3100/10000 | Train Loss: 4.490e-01 | Dynamic Loss: 4.490e-01 | Regularization Loss: 1.893e-07 | Val Loss: 4.471e-01 | Time: 4.83s
2025-08-15 02:51:09,862:INFO:Epoch: 3150/10000 | Train Loss: 4.486e-01 | Dynamic Loss: 4.486e-01 | Regularization Loss: 1.883e-07 | Val Loss: 4.449e-01 | Time: 4.73s
2025-08-15 02:51:09,862:INFO:New best model found at epoch 3150 with validation loss 4.449e-01. Saving...
2025-08-15 02:51:14,624:INFO:Epoch: 3200/10000 | Train Loss: 4.486e-01 | Dynamic Loss: 4.486e-01 | Regularization Loss: 1.870e-07 | Val Loss: 4.461e-01 | Time: 4.75s
2025-08-15 02:51:19,298:INFO:Epoch: 3250/10000 | Train Loss: 4.456e-01 | Dynamic Loss: 4.456e-01 | Regularization Loss: 1.848e-07 | Val Loss: 4.438e-01 | Time: 4.67s
2025-08-15 02:51:19,298:INFO:New best model found at epoch 3250 with validation loss 4.438e-01. Saving...
2025-08-15 02:51:24,105:INFO:Epoch: 3300/10000 | Train Loss: 4.455e-01 | Dynamic Loss: 4.455e-01 | Regularization Loss: 1.832e-07 | Val Loss: 4.446e-01 | Time: 4.80s
2025-08-15 02:51:34,832:INFO:Epoch: 3350/10000 | Train Loss: 4.438e-01 | Dynamic Loss: 4.438e-01 | Regularization Loss: 1.811e-07 | Val Loss: 4.416e-01 | Time: 10.73s
2025-08-15 02:51:34,832:INFO:New best model found at epoch 3350 with validation loss 4.416e-01. Saving...
2025-08-15 02:51:39,653:INFO:Epoch: 3400/10000 | Train Loss: 4.442e-01 | Dynamic Loss: 4.442e-01 | Regularization Loss: 1.800e-07 | Val Loss: 4.414e-01 | Time: 4.81s
2025-08-15 02:51:39,653:INFO:New best model found at epoch 3400 with validation loss 4.414e-01. Saving...
2025-08-15 02:51:44,400:INFO:Epoch: 3450/10000 | Train Loss: 4.443e-01 | Dynamic Loss: 4.443e-01 | Regularization Loss: 1.780e-07 | Val Loss: 4.410e-01 | Time: 4.74s
2025-08-15 02:51:44,400:INFO:New best model found at epoch 3450 with validation loss 4.410e-01. Saving...
2025-08-15 02:51:49,033:INFO:Epoch: 3500/10000 | Train Loss: 4.436e-01 | Dynamic Loss: 4.436e-01 | Regularization Loss: 1.771e-07 | Val Loss: 4.406e-01 | Time: 4.62s
2025-08-15 02:51:49,033:INFO:New best model found at epoch 3500 with validation loss 4.406e-01. Saving...
2025-08-15 02:51:53,859:INFO:Epoch: 3550/10000 | Train Loss: 4.425e-01 | Dynamic Loss: 4.425e-01 | Regularization Loss: 1.755e-07 | Val Loss: 4.416e-01 | Time: 4.82s
2025-08-15 02:51:58,583:INFO:Epoch: 3600/10000 | Train Loss: 4.422e-01 | Dynamic Loss: 4.422e-01 | Regularization Loss: 1.754e-07 | Val Loss: 4.398e-01 | Time: 4.72s
2025-08-15 02:51:58,583:INFO:New best model found at epoch 3600 with validation loss 4.398e-01. Saving...
2025-08-15 02:52:03,325:INFO:Epoch: 3650/10000 | Train Loss: 4.415e-01 | Dynamic Loss: 4.415e-01 | Regularization Loss: 1.737e-07 | Val Loss: 4.389e-01 | Time: 4.73s
2025-08-15 02:52:03,325:INFO:New best model found at epoch 3650 with validation loss 4.389e-01. Saving...
2025-08-15 02:52:08,056:INFO:Epoch: 3700/10000 | Train Loss: 4.402e-01 | Dynamic Loss: 4.402e-01 | Regularization Loss: 1.728e-07 | Val Loss: 4.406e-01 | Time: 4.72s
2025-08-15 02:52:12,665:INFO:Epoch: 3750/10000 | Train Loss: 4.399e-01 | Dynamic Loss: 4.399e-01 | Regularization Loss: 1.702e-07 | Val Loss: 4.384e-01 | Time: 4.61s
2025-08-15 02:52:12,666:INFO:New best model found at epoch 3750 with validation loss 4.384e-01. Saving...
2025-08-15 02:52:21,573:INFO:Epoch: 3800/10000 | Train Loss: 4.384e-01 | Dynamic Loss: 4.384e-01 | Regularization Loss: 1.692e-07 | Val Loss: 4.387e-01 | Time: 8.90s
2025-08-15 02:52:26,301:INFO:Epoch: 3850/10000 | Train Loss: 4.386e-01 | Dynamic Loss: 4.386e-01 | Regularization Loss: 1.673e-07 | Val Loss: 4.393e-01 | Time: 4.73s
2025-08-15 02:52:31,037:INFO:Epoch: 3900/10000 | Train Loss: 4.371e-01 | Dynamic Loss: 4.371e-01 | Regularization Loss: 1.664e-07 | Val Loss: 4.378e-01 | Time: 4.74s
2025-08-15 02:52:31,038:INFO:New best model found at epoch 3900 with validation loss 4.378e-01. Saving...
2025-08-15 02:52:35,851:INFO:Epoch: 3950/10000 | Train Loss: 4.381e-01 | Dynamic Loss: 4.381e-01 | Regularization Loss: 1.650e-07 | Val Loss: 4.375e-01 | Time: 4.80s
2025-08-15 02:52:35,851:INFO:New best model found at epoch 3950 with validation loss 4.375e-01. Saving...
2025-08-15 02:52:40,546:INFO:Epoch: 4000/10000 | Train Loss: 4.372e-01 | Dynamic Loss: 4.372e-01 | Regularization Loss: 1.640e-07 | Val Loss: 4.382e-01 | Time: 4.69s
2025-08-15 02:52:50,442:INFO:Epoch: 4050/10000 | Train Loss: 4.355e-01 | Dynamic Loss: 4.355e-01 | Regularization Loss: 1.629e-07 | Val Loss: 4.382e-01 | Time: 9.90s
2025-08-15 02:52:55,198:INFO:Epoch: 4100/10000 | Train Loss: 4.357e-01 | Dynamic Loss: 4.357e-01 | Regularization Loss: 1.614e-07 | Val Loss: 4.370e-01 | Time: 4.76s
2025-08-15 02:52:55,198:INFO:New best model found at epoch 4100 with validation loss 4.370e-01. Saving...
2025-08-15 02:53:00,007:INFO:Epoch: 4150/10000 | Train Loss: 4.321e-01 | Dynamic Loss: 4.321e-01 | Regularization Loss: 1.592e-07 | Val Loss: 4.356e-01 | Time: 4.80s
2025-08-15 02:53:00,007:INFO:New best model found at epoch 4150 with validation loss 4.356e-01. Saving...
2025-08-15 02:53:04,761:INFO:Epoch: 4200/10000 | Train Loss: 4.326e-01 | Dynamic Loss: 4.326e-01 | Regularization Loss: 1.573e-07 | Val Loss: 4.345e-01 | Time: 4.74s
2025-08-15 02:53:04,761:INFO:New best model found at epoch 4200 with validation loss 4.345e-01. Saving...
2025-08-15 02:53:09,443:INFO:Epoch: 4250/10000 | Train Loss: 4.287e-01 | Dynamic Loss: 4.287e-01 | Regularization Loss: 1.554e-07 | Val Loss: 4.328e-01 | Time: 4.67s
2025-08-15 02:53:09,443:INFO:New best model found at epoch 4250 with validation loss 4.328e-01. Saving...
2025-08-15 02:53:20,170:INFO:Epoch: 4300/10000 | Train Loss: 4.286e-01 | Dynamic Loss: 4.286e-01 | Regularization Loss: 1.532e-07 | Val Loss: 4.320e-01 | Time: 10.72s
2025-08-15 02:53:20,170:INFO:New best model found at epoch 4300 with validation loss 4.320e-01. Saving...
2025-08-15 02:53:25,031:INFO:Epoch: 4350/10000 | Train Loss: 4.267e-01 | Dynamic Loss: 4.267e-01 | Regularization Loss: 1.518e-07 | Val Loss: 4.307e-01 | Time: 4.85s
2025-08-15 02:53:25,031:INFO:New best model found at epoch 4350 with validation loss 4.307e-01. Saving...
2025-08-15 02:53:29,866:INFO:Epoch: 4400/10000 | Train Loss: 4.262e-01 | Dynamic Loss: 4.262e-01 | Regularization Loss: 1.506e-07 | Val Loss: 4.301e-01 | Time: 4.82s
2025-08-15 02:53:29,866:INFO:New best model found at epoch 4400 with validation loss 4.301e-01. Saving...
2025-08-15 02:53:34,599:INFO:Epoch: 4450/10000 | Train Loss: 4.274e-01 | Dynamic Loss: 4.274e-01 | Regularization Loss: 1.496e-07 | Val Loss: 4.301e-01 | Time: 4.72s
2025-08-15 02:53:39,300:INFO:Epoch: 4500/10000 | Train Loss: 4.245e-01 | Dynamic Loss: 4.245e-01 | Regularization Loss: 1.486e-07 | Val Loss: 4.277e-01 | Time: 4.70s
2025-08-15 02:53:39,300:INFO:New best model found at epoch 4500 with validation loss 4.277e-01. Saving...
2025-08-15 02:53:47,349:INFO:Epoch: 4550/10000 | Train Loss: 4.235e-01 | Dynamic Loss: 4.235e-01 | Regularization Loss: 1.460e-07 | Val Loss: 4.273e-01 | Time: 8.04s
2025-08-15 02:53:47,349:INFO:New best model found at epoch 4550 with validation loss 4.273e-01. Saving...
2025-08-15 02:53:52,079:INFO:Epoch: 4600/10000 | Train Loss: 4.222e-01 | Dynamic Loss: 4.222e-01 | Regularization Loss: 1.452e-07 | Val Loss: 4.280e-01 | Time: 4.72s
2025-08-15 02:53:56,748:INFO:Epoch: 4650/10000 | Train Loss: 4.188e-01 | Dynamic Loss: 4.188e-01 | Regularization Loss: 1.440e-07 | Val Loss: 4.233e-01 | Time: 4.67s
2025-08-15 02:53:56,748:INFO:New best model found at epoch 4650 with validation loss 4.233e-01. Saving...
2025-08-15 02:54:01,400:INFO:Epoch: 4700/10000 | Train Loss: 4.189e-01 | Dynamic Loss: 4.189e-01 | Regularization Loss: 1.426e-07 | Val Loss: 4.245e-01 | Time: 4.64s
2025-08-15 02:54:06,118:INFO:Epoch: 4750/10000 | Train Loss: 4.167e-01 | Dynamic Loss: 4.167e-01 | Regularization Loss: 1.398e-07 | Val Loss: 4.219e-01 | Time: 4.72s
2025-08-15 02:54:06,118:INFO:New best model found at epoch 4750 with validation loss 4.219e-01. Saving...
2025-08-15 02:54:13,935:INFO:Epoch: 4800/10000 | Train Loss: 4.161e-01 | Dynamic Loss: 4.161e-01 | Regularization Loss: 1.397e-07 | Val Loss: 4.213e-01 | Time: 7.81s
2025-08-15 02:54:13,935:INFO:New best model found at epoch 4800 with validation loss 4.213e-01. Saving...
2025-08-15 02:54:18,717:INFO:Epoch: 4850/10000 | Train Loss: 4.134e-01 | Dynamic Loss: 4.134e-01 | Regularization Loss: 1.377e-07 | Val Loss: 4.207e-01 | Time: 4.77s
2025-08-15 02:54:18,717:INFO:New best model found at epoch 4850 with validation loss 4.207e-01. Saving...
2025-08-15 02:54:23,445:INFO:Epoch: 4900/10000 | Train Loss: 4.120e-01 | Dynamic Loss: 4.120e-01 | Regularization Loss: 1.360e-07 | Val Loss: 4.197e-01 | Time: 4.72s
2025-08-15 02:54:23,445:INFO:New best model found at epoch 4900 with validation loss 4.197e-01. Saving...
2025-08-15 02:54:28,132:INFO:Epoch: 4950/10000 | Train Loss: 4.119e-01 | Dynamic Loss: 4.119e-01 | Regularization Loss: 1.349e-07 | Val Loss: 4.191e-01 | Time: 4.68s
2025-08-15 02:54:28,132:INFO:New best model found at epoch 4950 with validation loss 4.191e-01. Saving...
2025-08-15 02:54:33,086:INFO:Epoch: 5000/10000 | Train Loss: 4.112e-01 | Dynamic Loss: 4.112e-01 | Regularization Loss: 1.331e-07 | Val Loss: 4.183e-01 | Time: 4.94s
2025-08-15 02:54:33,086:INFO:New best model found at epoch 5000 with validation loss 4.183e-01. Saving...
2025-08-15 02:54:44,060:INFO:Epoch: 5050/10000 | Train Loss: 4.102e-01 | Dynamic Loss: 4.102e-01 | Regularization Loss: 1.346e-07 | Val Loss: 4.177e-01 | Time: 10.96s
2025-08-15 02:54:44,060:INFO:New best model found at epoch 5050 with validation loss 4.177e-01. Saving...
2025-08-15 02:54:48,855:INFO:Epoch: 5100/10000 | Train Loss: 4.089e-01 | Dynamic Loss: 4.089e-01 | Regularization Loss: 1.310e-07 | Val Loss: 4.173e-01 | Time: 4.79s
2025-08-15 02:54:48,856:INFO:New best model found at epoch 5100 with validation loss 4.173e-01. Saving...
2025-08-15 02:54:53,629:INFO:Epoch: 5150/10000 | Train Loss: 4.096e-01 | Dynamic Loss: 4.096e-01 | Regularization Loss: 1.297e-07 | Val Loss: 4.166e-01 | Time: 4.76s
2025-08-15 02:54:53,629:INFO:New best model found at epoch 5150 with validation loss 4.166e-01. Saving...
2025-08-15 02:54:58,442:INFO:Epoch: 5200/10000 | Train Loss: 4.069e-01 | Dynamic Loss: 4.069e-01 | Regularization Loss: 1.294e-07 | Val Loss: 4.161e-01 | Time: 4.80s
2025-08-15 02:54:58,442:INFO:New best model found at epoch 5200 with validation loss 4.161e-01. Saving...
2025-08-15 02:55:06,119:INFO:Epoch: 5250/10000 | Train Loss: 4.083e-01 | Dynamic Loss: 4.083e-01 | Regularization Loss: 1.271e-07 | Val Loss: 4.153e-01 | Time: 7.67s
2025-08-15 02:55:06,120:INFO:New best model found at epoch 5250 with validation loss 4.153e-01. Saving...
2025-08-15 02:55:11,253:INFO:Epoch: 5300/10000 | Train Loss: 4.076e-01 | Dynamic Loss: 4.076e-01 | Regularization Loss: 1.280e-07 | Val Loss: 4.152e-01 | Time: 5.12s
2025-08-15 02:55:11,253:INFO:New best model found at epoch 5300 with validation loss 4.152e-01. Saving...
2025-08-15 02:55:15,995:INFO:Epoch: 5350/10000 | Train Loss: 4.057e-01 | Dynamic Loss: 4.057e-01 | Regularization Loss: 1.257e-07 | Val Loss: 4.144e-01 | Time: 4.73s
2025-08-15 02:55:15,995:INFO:New best model found at epoch 5350 with validation loss 4.144e-01. Saving...
2025-08-15 02:55:20,747:INFO:Epoch: 5400/10000 | Train Loss: 4.058e-01 | Dynamic Loss: 4.058e-01 | Regularization Loss: 1.255e-07 | Val Loss: 4.147e-01 | Time: 4.74s
2025-08-15 02:55:25,424:INFO:Epoch: 5450/10000 | Train Loss: 4.050e-01 | Dynamic Loss: 4.050e-01 | Regularization Loss: 1.257e-07 | Val Loss: 4.137e-01 | Time: 4.68s
2025-08-15 02:55:25,425:INFO:New best model found at epoch 5450 with validation loss 4.137e-01. Saving...
2025-08-15 02:55:32,228:INFO:Epoch: 5500/10000 | Train Loss: 4.039e-01 | Dynamic Loss: 4.039e-01 | Regularization Loss: 1.243e-07 | Val Loss: 4.128e-01 | Time: 6.79s
2025-08-15 02:55:32,228:INFO:New best model found at epoch 5500 with validation loss 4.128e-01. Saving...
2025-08-15 02:55:36,953:INFO:Epoch: 5550/10000 | Train Loss: 4.041e-01 | Dynamic Loss: 4.041e-01 | Regularization Loss: 1.211e-07 | Val Loss: 4.138e-01 | Time: 4.72s
2025-08-15 02:55:41,722:INFO:Epoch: 5600/10000 | Train Loss: 4.040e-01 | Dynamic Loss: 4.040e-01 | Regularization Loss: 1.214e-07 | Val Loss: 4.117e-01 | Time: 4.77s
2025-08-15 02:55:41,722:INFO:New best model found at epoch 5600 with validation loss 4.117e-01. Saving...
2025-08-15 02:55:46,490:INFO:Epoch: 5650/10000 | Train Loss: 4.014e-01 | Dynamic Loss: 4.014e-01 | Regularization Loss: 1.229e-07 | Val Loss: 4.111e-01 | Time: 4.76s
2025-08-15 02:55:46,490:INFO:New best model found at epoch 5650 with validation loss 4.111e-01. Saving...
2025-08-15 02:55:51,289:INFO:Epoch: 5700/10000 | Train Loss: 4.018e-01 | Dynamic Loss: 4.018e-01 | Regularization Loss: 1.210e-07 | Val Loss: 4.107e-01 | Time: 4.79s
2025-08-15 02:55:51,289:INFO:New best model found at epoch 5700 with validation loss 4.107e-01. Saving...
2025-08-15 02:56:01,582:INFO:Epoch: 5750/10000 | Train Loss: 4.003e-01 | Dynamic Loss: 4.003e-01 | Regularization Loss: 1.183e-07 | Val Loss: 4.100e-01 | Time: 10.28s
2025-08-15 02:56:01,582:INFO:New best model found at epoch 5750 with validation loss 4.100e-01. Saving...
2025-08-15 02:56:06,318:INFO:Epoch: 5800/10000 | Train Loss: 3.998e-01 | Dynamic Loss: 3.998e-01 | Regularization Loss: 1.190e-07 | Val Loss: 4.094e-01 | Time: 4.73s
2025-08-15 02:56:06,318:INFO:New best model found at epoch 5800 with validation loss 4.094e-01. Saving...
2025-08-15 02:56:11,160:INFO:Epoch: 5850/10000 | Train Loss: 3.995e-01 | Dynamic Loss: 3.995e-01 | Regularization Loss: 1.181e-07 | Val Loss: 4.098e-01 | Time: 4.83s
2025-08-15 02:56:15,999:INFO:Epoch: 5900/10000 | Train Loss: 3.981e-01 | Dynamic Loss: 3.981e-01 | Regularization Loss: 1.080e-07 | Val Loss: 4.084e-01 | Time: 4.84s
2025-08-15 02:56:15,999:INFO:New best model found at epoch 5900 with validation loss 4.084e-01. Saving...
2025-08-15 02:56:20,771:INFO:Epoch: 5950/10000 | Train Loss: 3.980e-01 | Dynamic Loss: 3.980e-01 | Regularization Loss: 1.007e-07 | Val Loss: 4.083e-01 | Time: 4.76s
2025-08-15 02:56:20,771:INFO:New best model found at epoch 5950 with validation loss 4.083e-01. Saving...
2025-08-15 02:56:32,061:INFO:Epoch: 6000/10000 | Train Loss: 4.011e-01 | Dynamic Loss: 4.011e-01 | Regularization Loss: 1.169e-07 | Val Loss: 4.102e-01 | Time: 11.28s
2025-08-15 02:56:36,876:INFO:Epoch: 6050/10000 | Train Loss: 3.962e-01 | Dynamic Loss: 3.962e-01 | Regularization Loss: 7.652e-08 | Val Loss: 4.071e-01 | Time: 4.82s
2025-08-15 02:56:36,876:INFO:New best model found at epoch 6050 with validation loss 4.071e-01. Saving...
2025-08-15 02:56:41,689:INFO:Epoch: 6100/10000 | Train Loss: 3.936e-01 | Dynamic Loss: 3.936e-01 | Regularization Loss: 1.741e-07 | Val Loss: 4.067e-01 | Time: 4.80s
2025-08-15 02:56:41,689:INFO:New best model found at epoch 6100 with validation loss 4.067e-01. Saving...
2025-08-15 02:56:46,544:INFO:Epoch: 6150/10000 | Train Loss: 3.932e-01 | Dynamic Loss: 3.932e-01 | Regularization Loss: 0.000e+00 | Val Loss: 4.055e-01 | Time: 4.85s
2025-08-15 02:56:46,544:INFO:New best model found at epoch 6150 with validation loss 4.055e-01. Saving...
2025-08-15 02:56:51,351:INFO:Epoch: 6200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.80s
2025-08-15 02:56:56,124:INFO:Epoch: 6250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.77s
2025-08-15 02:57:00,847:INFO:Epoch: 6300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.72s
2025-08-15 02:57:05,660:INFO:Epoch: 6350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.81s
2025-08-15 02:57:10,399:INFO:Epoch: 6400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.74s
2025-08-15 02:57:20,308:INFO:Epoch: 6450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 9.91s
2025-08-15 02:57:25,115:INFO:Epoch: 6500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.81s
2025-08-15 02:57:29,852:INFO:Epoch: 6550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.74s
2025-08-15 02:57:34,621:INFO:Epoch: 6600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.77s
2025-08-15 02:57:39,348:INFO:Epoch: 6650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.73s
2025-08-15 02:57:50,519:INFO:Epoch: 6700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 11.17s
2025-08-15 02:57:55,388:INFO:Epoch: 6750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.87s
2025-08-15 02:58:00,264:INFO:Epoch: 6800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.88s
2025-08-15 02:58:05,033:INFO:Epoch: 6850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.77s
2025-08-15 02:58:09,841:INFO:Epoch: 6900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.81s
2025-08-15 02:58:14,773:INFO:Epoch: 6950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.93s
2025-08-15 02:58:19,617:INFO:Epoch: 7000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.84s
2025-08-15 02:58:24,465:INFO:Epoch: 7050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.85s
2025-08-15 02:58:29,326:INFO:Epoch: 7100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.86s
2025-08-15 02:58:36,362:INFO:Epoch: 7150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 7.04s
2025-08-15 02:58:41,257:INFO:Epoch: 7200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.89s
2025-08-15 02:58:46,129:INFO:Epoch: 7250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.87s
2025-08-15 02:58:51,015:INFO:Epoch: 7300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.89s
2025-08-15 02:58:55,833:INFO:Epoch: 7350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.82s
2025-08-15 02:59:07,245:INFO:Epoch: 7400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 11.41s
2025-08-15 02:59:12,160:INFO:Epoch: 7450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.91s
2025-08-15 02:59:17,094:INFO:Epoch: 7500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.93s
2025-08-15 02:59:21,944:INFO:Epoch: 7550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.85s
2025-08-15 02:59:26,821:INFO:Epoch: 7600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.88s
2025-08-15 02:59:31,717:INFO:Epoch: 7650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.90s
2025-08-15 02:59:36,525:INFO:Epoch: 7700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.81s
2025-08-15 02:59:41,671:INFO:Epoch: 7750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.15s
2025-08-15 02:59:46,481:INFO:Epoch: 7800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.81s
2025-08-15 02:59:56,020:INFO:Epoch: 7850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 9.54s
2025-08-15 03:00:00,902:INFO:Epoch: 7900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.88s
2025-08-15 03:00:05,714:INFO:Epoch: 7950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.81s
2025-08-15 03:00:10,544:INFO:Epoch: 8000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.83s
2025-08-15 03:00:15,368:INFO:Epoch: 8050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.82s
2025-08-15 03:00:24,184:INFO:Epoch: 8100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 8.82s
2025-08-15 03:00:29,006:INFO:Epoch: 8150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.82s
2025-08-15 03:00:34,183:INFO:Epoch: 8200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.18s
2025-08-15 03:00:39,003:INFO:Epoch: 8250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.82s
2025-08-15 03:00:43,774:INFO:Epoch: 8300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.77s
2025-08-15 03:00:51,728:INFO:Epoch: 8350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 7.95s
2025-08-15 03:00:56,684:INFO:Epoch: 8400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.96s
2025-08-15 03:01:01,452:INFO:Epoch: 8450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.77s
2025-08-15 03:01:06,233:INFO:Epoch: 8500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.78s
2025-08-15 03:01:11,004:INFO:Epoch: 8550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.77s
2025-08-15 03:01:20,034:INFO:Epoch: 8600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 9.03s
2025-08-15 03:01:24,806:INFO:Epoch: 8650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.77s
2025-08-15 03:01:29,596:INFO:Epoch: 8700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.79s
2025-08-15 03:01:34,384:INFO:Epoch: 8750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.79s
2025-08-15 03:01:39,319:INFO:Epoch: 8800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.93s
2025-08-15 03:01:49,142:INFO:Epoch: 8850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 9.82s
2025-08-15 03:01:53,989:INFO:Epoch: 8900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.85s
2025-08-15 03:01:58,819:INFO:Epoch: 8950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.83s
2025-08-15 03:02:03,644:INFO:Epoch: 9000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.82s
2025-08-15 03:02:08,399:INFO:Epoch: 9050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.76s
2025-08-15 03:02:19,641:INFO:Epoch: 9100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 11.24s
2025-08-15 03:02:24,436:INFO:Epoch: 9150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.80s
2025-08-15 03:02:29,424:INFO:Epoch: 9200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.99s
2025-08-15 03:02:34,272:INFO:Epoch: 9250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.85s
2025-08-15 03:02:39,164:INFO:Epoch: 9300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.89s
2025-08-15 03:02:44,018:INFO:Epoch: 9350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.85s
2025-08-15 03:02:48,901:INFO:Epoch: 9400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.88s
2025-08-15 03:02:53,732:INFO:Epoch: 9450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.83s
2025-08-15 03:02:58,565:INFO:Epoch: 9500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.83s
2025-08-15 03:03:04,679:INFO:Epoch: 9550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 6.11s
2025-08-15 03:03:09,604:INFO:Epoch: 9600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.92s
2025-08-15 03:03:14,534:INFO:Epoch: 9650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.93s
2025-08-15 03:03:19,387:INFO:Epoch: 9700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.85s
2025-08-15 03:03:24,182:INFO:Epoch: 9750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.80s
2025-08-15 03:03:34,645:INFO:Epoch: 9800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 10.46s
2025-08-15 03:03:39,587:INFO:Epoch: 9850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.94s
2025-08-15 03:03:44,546:INFO:Epoch: 9900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.96s
2025-08-15 03:03:49,450:INFO:Epoch: 9950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.90s
2025-08-15 03:03:54,306:INFO:Epoch: 10000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.86s
