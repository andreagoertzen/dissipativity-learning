2025-08-15 02:45:30,119:INFO:Created DataLoaders with 2994 training samples and 998 validation samples.
2025-08-15 02:45:30,718:INFO:model params: 479490
2025-08-15 02:45:31,422:INFO:Epoch: 0/10000 | Train Loss: 5.094e+00 | Dynamic Loss: 5.094e+00 | Regularization Loss: 6.195e-19 | Val Loss: 3.413e+00 | Time: 0.70s
2025-08-15 02:45:31,422:INFO:New best model found at epoch 0 with validation loss 3.413e+00. Saving...
2025-08-15 02:45:36,060:INFO:Epoch: 50/10000 | Train Loss: 9.023e-01 | Dynamic Loss: 9.023e-01 | Regularization Loss: 2.074e-15 | Val Loss: 9.511e-01 | Time: 4.58s
2025-08-15 02:45:36,060:INFO:New best model found at epoch 50 with validation loss 9.511e-01. Saving...
2025-08-15 02:45:40,569:INFO:Epoch: 100/10000 | Train Loss: 7.129e-01 | Dynamic Loss: 7.129e-01 | Regularization Loss: 1.890e-09 | Val Loss: 7.449e-01 | Time: 4.50s
2025-08-15 02:45:40,569:INFO:New best model found at epoch 100 with validation loss 7.449e-01. Saving...
2025-08-15 02:45:45,152:INFO:Epoch: 150/10000 | Train Loss: 6.439e-01 | Dynamic Loss: 6.439e-01 | Regularization Loss: 6.176e-07 | Val Loss: 6.643e-01 | Time: 4.57s
2025-08-15 02:45:45,152:INFO:New best model found at epoch 150 with validation loss 6.643e-01. Saving...
2025-08-15 02:45:49,743:INFO:Epoch: 200/10000 | Train Loss: 6.067e-01 | Dynamic Loss: 6.067e-01 | Regularization Loss: 5.954e-07 | Val Loss: 6.247e-01 | Time: 4.58s
2025-08-15 02:45:49,743:INFO:New best model found at epoch 200 with validation loss 6.247e-01. Saving...
2025-08-15 02:45:54,620:INFO:Epoch: 250/10000 | Train Loss: 5.892e-01 | Dynamic Loss: 5.892e-01 | Regularization Loss: 5.798e-07 | Val Loss: 6.010e-01 | Time: 4.87s
2025-08-15 02:45:54,620:INFO:New best model found at epoch 250 with validation loss 6.010e-01. Saving...
2025-08-15 02:46:04,358:INFO:Epoch: 300/10000 | Train Loss: 5.781e-01 | Dynamic Loss: 5.781e-01 | Regularization Loss: 5.614e-07 | Val Loss: 5.846e-01 | Time: 9.73s
2025-08-15 02:46:04,358:INFO:New best model found at epoch 300 with validation loss 5.846e-01. Saving...
2025-08-15 02:46:09,015:INFO:Epoch: 350/10000 | Train Loss: 5.722e-01 | Dynamic Loss: 5.722e-01 | Regularization Loss: 5.445e-07 | Val Loss: 5.748e-01 | Time: 4.65s
2025-08-15 02:46:09,015:INFO:New best model found at epoch 350 with validation loss 5.748e-01. Saving...
2025-08-15 02:46:13,643:INFO:Epoch: 400/10000 | Train Loss: 5.643e-01 | Dynamic Loss: 5.643e-01 | Regularization Loss: 5.259e-07 | Val Loss: 5.650e-01 | Time: 4.62s
2025-08-15 02:46:13,644:INFO:New best model found at epoch 400 with validation loss 5.650e-01. Saving...
2025-08-15 02:46:18,246:INFO:Epoch: 450/10000 | Train Loss: 5.589e-01 | Dynamic Loss: 5.589e-01 | Regularization Loss: 5.116e-07 | Val Loss: 5.568e-01 | Time: 4.59s
2025-08-15 02:46:18,247:INFO:New best model found at epoch 450 with validation loss 5.568e-01. Saving...
2025-08-15 02:46:28,823:INFO:Epoch: 500/10000 | Train Loss: 5.579e-01 | Dynamic Loss: 5.579e-01 | Regularization Loss: 4.971e-07 | Val Loss: 5.529e-01 | Time: 10.57s
2025-08-15 02:46:28,823:INFO:New best model found at epoch 500 with validation loss 5.529e-01. Saving...
2025-08-15 02:46:33,530:INFO:Epoch: 550/10000 | Train Loss: 5.524e-01 | Dynamic Loss: 5.524e-01 | Regularization Loss: 4.845e-07 | Val Loss: 5.469e-01 | Time: 4.70s
2025-08-15 02:46:33,530:INFO:New best model found at epoch 550 with validation loss 5.469e-01. Saving...
2025-08-15 02:46:38,283:INFO:Epoch: 600/10000 | Train Loss: 5.473e-01 | Dynamic Loss: 5.473e-01 | Regularization Loss: 4.672e-07 | Val Loss: 5.402e-01 | Time: 4.74s
2025-08-15 02:46:38,283:INFO:New best model found at epoch 600 with validation loss 5.402e-01. Saving...
2025-08-15 02:46:42,934:INFO:Epoch: 650/10000 | Train Loss: 5.427e-01 | Dynamic Loss: 5.427e-01 | Regularization Loss: 4.544e-07 | Val Loss: 5.356e-01 | Time: 4.64s
2025-08-15 02:46:42,934:INFO:New best model found at epoch 650 with validation loss 5.356e-01. Saving...
2025-08-15 02:46:47,651:INFO:Epoch: 700/10000 | Train Loss: 5.399e-01 | Dynamic Loss: 5.399e-01 | Regularization Loss: 4.385e-07 | Val Loss: 5.305e-01 | Time: 4.71s
2025-08-15 02:46:47,651:INFO:New best model found at epoch 700 with validation loss 5.305e-01. Saving...
2025-08-15 02:46:52,294:INFO:Epoch: 750/10000 | Train Loss: 5.346e-01 | Dynamic Loss: 5.346e-01 | Regularization Loss: 4.282e-07 | Val Loss: 5.262e-01 | Time: 4.63s
2025-08-15 02:46:52,294:INFO:New best model found at epoch 750 with validation loss 5.262e-01. Saving...
2025-08-15 02:46:57,005:INFO:Epoch: 800/10000 | Train Loss: 5.358e-01 | Dynamic Loss: 5.358e-01 | Regularization Loss: 4.175e-07 | Val Loss: 5.232e-01 | Time: 4.70s
2025-08-15 02:46:57,005:INFO:New best model found at epoch 800 with validation loss 5.232e-01. Saving...
2025-08-15 02:47:01,651:INFO:Epoch: 850/10000 | Train Loss: 5.297e-01 | Dynamic Loss: 5.297e-01 | Regularization Loss: 4.063e-07 | Val Loss: 5.196e-01 | Time: 4.64s
2025-08-15 02:47:01,651:INFO:New best model found at epoch 850 with validation loss 5.196e-01. Saving...
2025-08-15 02:47:07,084:INFO:Epoch: 900/10000 | Train Loss: 5.258e-01 | Dynamic Loss: 5.258e-01 | Regularization Loss: 3.965e-07 | Val Loss: 5.153e-01 | Time: 5.42s
2025-08-15 02:47:07,084:INFO:New best model found at epoch 900 with validation loss 5.153e-01. Saving...
2025-08-15 02:47:11,709:INFO:Epoch: 950/10000 | Train Loss: 5.227e-01 | Dynamic Loss: 5.227e-01 | Regularization Loss: 3.871e-07 | Val Loss: 5.138e-01 | Time: 4.61s
2025-08-15 02:47:11,709:INFO:New best model found at epoch 950 with validation loss 5.138e-01. Saving...
2025-08-15 02:47:16,346:INFO:Epoch: 1000/10000 | Train Loss: 5.224e-01 | Dynamic Loss: 5.224e-01 | Regularization Loss: 3.773e-07 | Val Loss: 5.097e-01 | Time: 4.63s
2025-08-15 02:47:16,346:INFO:New best model found at epoch 1000 with validation loss 5.097e-01. Saving...
2025-08-15 02:47:20,996:INFO:Epoch: 1050/10000 | Train Loss: 5.175e-01 | Dynamic Loss: 5.175e-01 | Regularization Loss: 3.669e-07 | Val Loss: 5.066e-01 | Time: 4.64s
2025-08-15 02:47:20,996:INFO:New best model found at epoch 1050 with validation loss 5.066e-01. Saving...
2025-08-15 02:47:25,596:INFO:Epoch: 1100/10000 | Train Loss: 5.141e-01 | Dynamic Loss: 5.141e-01 | Regularization Loss: 3.591e-07 | Val Loss: 5.042e-01 | Time: 4.59s
2025-08-15 02:47:25,596:INFO:New best model found at epoch 1100 with validation loss 5.042e-01. Saving...
2025-08-15 02:47:35,202:INFO:Epoch: 1150/10000 | Train Loss: 5.114e-01 | Dynamic Loss: 5.114e-01 | Regularization Loss: 3.494e-07 | Val Loss: 5.019e-01 | Time: 9.60s
2025-08-15 02:47:35,202:INFO:New best model found at epoch 1150 with validation loss 5.019e-01. Saving...
2025-08-15 02:47:39,856:INFO:Epoch: 1200/10000 | Train Loss: 5.100e-01 | Dynamic Loss: 5.100e-01 | Regularization Loss: 3.434e-07 | Val Loss: 4.993e-01 | Time: 4.64s
2025-08-15 02:47:39,856:INFO:New best model found at epoch 1200 with validation loss 4.993e-01. Saving...
2025-08-15 02:47:44,518:INFO:Epoch: 1250/10000 | Train Loss: 5.087e-01 | Dynamic Loss: 5.087e-01 | Regularization Loss: 3.379e-07 | Val Loss: 4.962e-01 | Time: 4.65s
2025-08-15 02:47:44,518:INFO:New best model found at epoch 1250 with validation loss 4.962e-01. Saving...
2025-08-15 02:47:49,168:INFO:Epoch: 1300/10000 | Train Loss: 5.070e-01 | Dynamic Loss: 5.070e-01 | Regularization Loss: 3.292e-07 | Val Loss: 4.949e-01 | Time: 4.64s
2025-08-15 02:47:49,168:INFO:New best model found at epoch 1300 with validation loss 4.949e-01. Saving...
2025-08-15 02:47:59,359:INFO:Epoch: 1350/10000 | Train Loss: 5.040e-01 | Dynamic Loss: 5.040e-01 | Regularization Loss: 3.245e-07 | Val Loss: 4.931e-01 | Time: 10.18s
2025-08-15 02:47:59,359:INFO:New best model found at epoch 1350 with validation loss 4.931e-01. Saving...
2025-08-15 02:48:04,022:INFO:Epoch: 1400/10000 | Train Loss: 5.011e-01 | Dynamic Loss: 5.011e-01 | Regularization Loss: 3.155e-07 | Val Loss: 4.914e-01 | Time: 4.65s
2025-08-15 02:48:04,022:INFO:New best model found at epoch 1400 with validation loss 4.914e-01. Saving...
2025-08-15 02:48:08,724:INFO:Epoch: 1450/10000 | Train Loss: 5.016e-01 | Dynamic Loss: 5.016e-01 | Regularization Loss: 3.113e-07 | Val Loss: 4.884e-01 | Time: 4.69s
2025-08-15 02:48:08,725:INFO:New best model found at epoch 1450 with validation loss 4.884e-01. Saving...
2025-08-15 02:48:13,369:INFO:Epoch: 1500/10000 | Train Loss: 4.980e-01 | Dynamic Loss: 4.980e-01 | Regularization Loss: 3.034e-07 | Val Loss: 4.850e-01 | Time: 4.64s
2025-08-15 02:48:13,369:INFO:New best model found at epoch 1500 with validation loss 4.850e-01. Saving...
2025-08-15 02:48:18,468:INFO:Epoch: 1550/10000 | Train Loss: 4.952e-01 | Dynamic Loss: 4.952e-01 | Regularization Loss: 3.006e-07 | Val Loss: 4.858e-01 | Time: 5.09s
2025-08-15 02:48:23,531:INFO:Epoch: 1600/10000 | Train Loss: 4.932e-01 | Dynamic Loss: 4.932e-01 | Regularization Loss: 2.946e-07 | Val Loss: 4.824e-01 | Time: 5.06s
2025-08-15 02:48:23,531:INFO:New best model found at epoch 1600 with validation loss 4.824e-01. Saving...
2025-08-15 02:48:28,170:INFO:Epoch: 1650/10000 | Train Loss: 4.913e-01 | Dynamic Loss: 4.913e-01 | Regularization Loss: 2.898e-07 | Val Loss: 4.809e-01 | Time: 4.63s
2025-08-15 02:48:28,170:INFO:New best model found at epoch 1650 with validation loss 4.809e-01. Saving...
2025-08-15 02:48:32,860:INFO:Epoch: 1700/10000 | Train Loss: 4.902e-01 | Dynamic Loss: 4.902e-01 | Regularization Loss: 2.833e-07 | Val Loss: 4.782e-01 | Time: 4.68s
2025-08-15 02:48:32,860:INFO:New best model found at epoch 1700 with validation loss 4.782e-01. Saving...
2025-08-15 02:48:40,473:INFO:Epoch: 1750/10000 | Train Loss: 4.897e-01 | Dynamic Loss: 4.897e-01 | Regularization Loss: 2.798e-07 | Val Loss: 4.773e-01 | Time: 7.60s
2025-08-15 02:48:40,473:INFO:New best model found at epoch 1750 with validation loss 4.773e-01. Saving...
2025-08-15 02:48:45,178:INFO:Epoch: 1800/10000 | Train Loss: 4.873e-01 | Dynamic Loss: 4.873e-01 | Regularization Loss: 2.754e-07 | Val Loss: 4.768e-01 | Time: 4.70s
2025-08-15 02:48:45,178:INFO:New best model found at epoch 1800 with validation loss 4.768e-01. Saving...
2025-08-15 02:48:49,888:INFO:Epoch: 1850/10000 | Train Loss: 4.850e-01 | Dynamic Loss: 4.850e-01 | Regularization Loss: 2.700e-07 | Val Loss: 4.743e-01 | Time: 4.70s
2025-08-15 02:48:49,888:INFO:New best model found at epoch 1850 with validation loss 4.743e-01. Saving...
2025-08-15 02:48:54,490:INFO:Epoch: 1900/10000 | Train Loss: 4.836e-01 | Dynamic Loss: 4.836e-01 | Regularization Loss: 2.664e-07 | Val Loss: 4.759e-01 | Time: 4.59s
2025-08-15 02:48:59,106:INFO:Epoch: 1950/10000 | Train Loss: 4.820e-01 | Dynamic Loss: 4.820e-01 | Regularization Loss: 2.603e-07 | Val Loss: 4.723e-01 | Time: 4.62s
2025-08-15 02:48:59,106:INFO:New best model found at epoch 1950 with validation loss 4.723e-01. Saving...
2025-08-15 02:49:08,004:INFO:Epoch: 2000/10000 | Train Loss: 4.783e-01 | Dynamic Loss: 4.783e-01 | Regularization Loss: 2.570e-07 | Val Loss: 4.715e-01 | Time: 8.89s
2025-08-15 02:49:08,004:INFO:New best model found at epoch 2000 with validation loss 4.715e-01. Saving...
2025-08-15 02:49:12,650:INFO:Epoch: 2050/10000 | Train Loss: 4.785e-01 | Dynamic Loss: 4.785e-01 | Regularization Loss: 2.526e-07 | Val Loss: 4.676e-01 | Time: 4.64s
2025-08-15 02:49:12,650:INFO:New best model found at epoch 2050 with validation loss 4.676e-01. Saving...
2025-08-15 02:49:17,508:INFO:Epoch: 2100/10000 | Train Loss: 4.745e-01 | Dynamic Loss: 4.745e-01 | Regularization Loss: 2.467e-07 | Val Loss: 4.661e-01 | Time: 4.85s
2025-08-15 02:49:17,508:INFO:New best model found at epoch 2100 with validation loss 4.661e-01. Saving...
2025-08-15 02:49:22,108:INFO:Epoch: 2150/10000 | Train Loss: 4.728e-01 | Dynamic Loss: 4.728e-01 | Regularization Loss: 2.417e-07 | Val Loss: 4.655e-01 | Time: 4.59s
2025-08-15 02:49:22,108:INFO:New best model found at epoch 2150 with validation loss 4.655e-01. Saving...
2025-08-15 02:49:30,379:INFO:Epoch: 2200/10000 | Train Loss: 4.746e-01 | Dynamic Loss: 4.746e-01 | Regularization Loss: 2.373e-07 | Val Loss: 4.655e-01 | Time: 8.26s
2025-08-15 02:49:35,082:INFO:Epoch: 2250/10000 | Train Loss: 4.666e-01 | Dynamic Loss: 4.666e-01 | Regularization Loss: 2.318e-07 | Val Loss: 4.625e-01 | Time: 4.70s
2025-08-15 02:49:35,082:INFO:New best model found at epoch 2250 with validation loss 4.625e-01. Saving...
2025-08-15 02:49:39,769:INFO:Epoch: 2300/10000 | Train Loss: 4.642e-01 | Dynamic Loss: 4.642e-01 | Regularization Loss: 2.273e-07 | Val Loss: 4.598e-01 | Time: 4.68s
2025-08-15 02:49:39,769:INFO:New best model found at epoch 2300 with validation loss 4.598e-01. Saving...
2025-08-15 02:49:44,393:INFO:Epoch: 2350/10000 | Train Loss: 4.632e-01 | Dynamic Loss: 4.632e-01 | Regularization Loss: 2.227e-07 | Val Loss: 4.587e-01 | Time: 4.61s
2025-08-15 02:49:44,393:INFO:New best model found at epoch 2350 with validation loss 4.587e-01. Saving...
2025-08-15 02:49:49,128:INFO:Epoch: 2400/10000 | Train Loss: 4.637e-01 | Dynamic Loss: 4.637e-01 | Regularization Loss: 2.204e-07 | Val Loss: 4.560e-01 | Time: 4.73s
2025-08-15 02:49:49,128:INFO:New best model found at epoch 2400 with validation loss 4.560e-01. Saving...
2025-08-15 02:49:53,880:INFO:Epoch: 2450/10000 | Train Loss: 4.608e-01 | Dynamic Loss: 4.608e-01 | Regularization Loss: 2.191e-07 | Val Loss: 4.563e-01 | Time: 4.74s
2025-08-15 02:49:58,663:INFO:Epoch: 2500/10000 | Train Loss: 4.598e-01 | Dynamic Loss: 4.598e-01 | Regularization Loss: 2.152e-07 | Val Loss: 4.554e-01 | Time: 4.78s
2025-08-15 02:49:58,664:INFO:New best model found at epoch 2500 with validation loss 4.554e-01. Saving...
2025-08-15 02:50:04,085:INFO:Epoch: 2550/10000 | Train Loss: 4.587e-01 | Dynamic Loss: 4.587e-01 | Regularization Loss: 2.132e-07 | Val Loss: 4.542e-01 | Time: 5.41s
2025-08-15 02:50:04,085:INFO:New best model found at epoch 2550 with validation loss 4.542e-01. Saving...
2025-08-15 02:50:08,995:INFO:Epoch: 2600/10000 | Train Loss: 4.579e-01 | Dynamic Loss: 4.579e-01 | Regularization Loss: 2.100e-07 | Val Loss: 4.523e-01 | Time: 4.90s
2025-08-15 02:50:08,995:INFO:New best model found at epoch 2600 with validation loss 4.523e-01. Saving...
2025-08-15 02:50:17,393:INFO:Epoch: 2650/10000 | Train Loss: 4.566e-01 | Dynamic Loss: 4.566e-01 | Regularization Loss: 2.088e-07 | Val Loss: 4.527e-01 | Time: 8.39s
2025-08-15 02:50:22,114:INFO:Epoch: 2700/10000 | Train Loss: 4.562e-01 | Dynamic Loss: 4.562e-01 | Regularization Loss: 2.062e-07 | Val Loss: 4.522e-01 | Time: 4.72s
2025-08-15 02:50:22,115:INFO:New best model found at epoch 2700 with validation loss 4.522e-01. Saving...
2025-08-15 02:50:26,889:INFO:Epoch: 2750/10000 | Train Loss: 4.538e-01 | Dynamic Loss: 4.538e-01 | Regularization Loss: 2.046e-07 | Val Loss: 4.502e-01 | Time: 4.76s
2025-08-15 02:50:26,889:INFO:New best model found at epoch 2750 with validation loss 4.502e-01. Saving...
2025-08-15 02:50:31,548:INFO:Epoch: 2800/10000 | Train Loss: 4.530e-01 | Dynamic Loss: 4.530e-01 | Regularization Loss: 2.023e-07 | Val Loss: 4.490e-01 | Time: 4.65s
2025-08-15 02:50:31,548:INFO:New best model found at epoch 2800 with validation loss 4.490e-01. Saving...
2025-08-15 02:50:36,318:INFO:Epoch: 2850/10000 | Train Loss: 4.515e-01 | Dynamic Loss: 4.515e-01 | Regularization Loss: 1.992e-07 | Val Loss: 4.475e-01 | Time: 4.76s
2025-08-15 02:50:36,318:INFO:New best model found at epoch 2850 with validation loss 4.475e-01. Saving...
2025-08-15 02:50:47,209:INFO:Epoch: 2900/10000 | Train Loss: 4.512e-01 | Dynamic Loss: 4.512e-01 | Regularization Loss: 1.974e-07 | Val Loss: 4.467e-01 | Time: 10.88s
2025-08-15 02:50:47,210:INFO:New best model found at epoch 2900 with validation loss 4.467e-01. Saving...
2025-08-15 02:50:51,997:INFO:Epoch: 2950/10000 | Train Loss: 4.519e-01 | Dynamic Loss: 4.519e-01 | Regularization Loss: 1.954e-07 | Val Loss: 4.483e-01 | Time: 4.78s
2025-08-15 02:50:56,775:INFO:Epoch: 3000/10000 | Train Loss: 4.502e-01 | Dynamic Loss: 4.502e-01 | Regularization Loss: 1.921e-07 | Val Loss: 4.463e-01 | Time: 4.78s
2025-08-15 02:50:56,775:INFO:New best model found at epoch 3000 with validation loss 4.463e-01. Saving...
2025-08-15 02:51:01,470:INFO:Epoch: 3050/10000 | Train Loss: 4.469e-01 | Dynamic Loss: 4.469e-01 | Regularization Loss: 1.900e-07 | Val Loss: 4.443e-01 | Time: 4.68s
2025-08-15 02:51:01,470:INFO:New best model found at epoch 3050 with validation loss 4.443e-01. Saving...
2025-08-15 02:51:07,239:INFO:Epoch: 3100/10000 | Train Loss: 4.459e-01 | Dynamic Loss: 4.459e-01 | Regularization Loss: 1.876e-07 | Val Loss: 4.427e-01 | Time: 5.76s
2025-08-15 02:51:07,239:INFO:New best model found at epoch 3100 with validation loss 4.427e-01. Saving...
2025-08-15 02:51:12,084:INFO:Epoch: 3150/10000 | Train Loss: 4.471e-01 | Dynamic Loss: 4.471e-01 | Regularization Loss: 1.868e-07 | Val Loss: 4.423e-01 | Time: 4.83s
2025-08-15 02:51:12,084:INFO:New best model found at epoch 3150 with validation loss 4.423e-01. Saving...
2025-08-15 02:51:16,902:INFO:Epoch: 3200/10000 | Train Loss: 4.462e-01 | Dynamic Loss: 4.462e-01 | Regularization Loss: 1.851e-07 | Val Loss: 4.408e-01 | Time: 4.81s
2025-08-15 02:51:16,903:INFO:New best model found at epoch 3200 with validation loss 4.408e-01. Saving...
2025-08-15 02:51:21,603:INFO:Epoch: 3250/10000 | Train Loss: 4.438e-01 | Dynamic Loss: 4.438e-01 | Regularization Loss: 1.832e-07 | Val Loss: 4.416e-01 | Time: 4.69s
2025-08-15 02:51:26,279:INFO:Epoch: 3300/10000 | Train Loss: 4.439e-01 | Dynamic Loss: 4.439e-01 | Regularization Loss: 1.815e-07 | Val Loss: 4.403e-01 | Time: 4.68s
2025-08-15 02:51:26,279:INFO:New best model found at epoch 3300 with validation loss 4.403e-01. Saving...
2025-08-15 02:51:34,614:INFO:Epoch: 3350/10000 | Train Loss: 4.418e-01 | Dynamic Loss: 4.418e-01 | Regularization Loss: 1.793e-07 | Val Loss: 4.403e-01 | Time: 8.33s
2025-08-15 02:51:34,615:INFO:New best model found at epoch 3350 with validation loss 4.403e-01. Saving...
2025-08-15 02:51:39,465:INFO:Epoch: 3400/10000 | Train Loss: 4.421e-01 | Dynamic Loss: 4.421e-01 | Regularization Loss: 1.782e-07 | Val Loss: 4.383e-01 | Time: 4.84s
2025-08-15 02:51:39,465:INFO:New best model found at epoch 3400 with validation loss 4.383e-01. Saving...
2025-08-15 02:51:44,297:INFO:Epoch: 3450/10000 | Train Loss: 4.412e-01 | Dynamic Loss: 4.412e-01 | Regularization Loss: 1.764e-07 | Val Loss: 4.390e-01 | Time: 4.82s
2025-08-15 02:51:48,962:INFO:Epoch: 3500/10000 | Train Loss: 4.413e-01 | Dynamic Loss: 4.413e-01 | Regularization Loss: 1.752e-07 | Val Loss: 4.377e-01 | Time: 4.66s
2025-08-15 02:51:48,962:INFO:New best model found at epoch 3500 with validation loss 4.377e-01. Saving...
2025-08-15 02:51:53,673:INFO:Epoch: 3550/10000 | Train Loss: 4.407e-01 | Dynamic Loss: 4.407e-01 | Regularization Loss: 1.742e-07 | Val Loss: 4.373e-01 | Time: 4.70s
2025-08-15 02:51:53,673:INFO:New best model found at epoch 3550 with validation loss 4.373e-01. Saving...
2025-08-15 02:52:03,978:INFO:Epoch: 3600/10000 | Train Loss: 4.398e-01 | Dynamic Loss: 4.398e-01 | Regularization Loss: 1.738e-07 | Val Loss: 4.363e-01 | Time: 10.30s
2025-08-15 02:52:03,980:INFO:New best model found at epoch 3600 with validation loss 4.363e-01. Saving...
2025-08-15 02:52:08,864:INFO:Epoch: 3650/10000 | Train Loss: 4.388e-01 | Dynamic Loss: 4.388e-01 | Regularization Loss: 1.725e-07 | Val Loss: 4.376e-01 | Time: 4.87s
2025-08-15 02:52:13,737:INFO:Epoch: 3700/10000 | Train Loss: 4.379e-01 | Dynamic Loss: 4.379e-01 | Regularization Loss: 1.711e-07 | Val Loss: 4.375e-01 | Time: 4.87s
2025-08-15 02:52:18,553:INFO:Epoch: 3750/10000 | Train Loss: 4.374e-01 | Dynamic Loss: 4.374e-01 | Regularization Loss: 1.685e-07 | Val Loss: 4.354e-01 | Time: 4.82s
2025-08-15 02:52:18,553:INFO:New best model found at epoch 3750 with validation loss 4.354e-01. Saving...
2025-08-15 02:52:23,363:INFO:Epoch: 3800/10000 | Train Loss: 4.360e-01 | Dynamic Loss: 4.360e-01 | Regularization Loss: 1.671e-07 | Val Loss: 4.351e-01 | Time: 4.80s
2025-08-15 02:52:23,363:INFO:New best model found at epoch 3800 with validation loss 4.351e-01. Saving...
2025-08-15 02:52:33,379:INFO:Epoch: 3850/10000 | Train Loss: 4.345e-01 | Dynamic Loss: 4.345e-01 | Regularization Loss: 1.649e-07 | Val Loss: 4.338e-01 | Time: 10.01s
2025-08-15 02:52:33,379:INFO:New best model found at epoch 3850 with validation loss 4.338e-01. Saving...
2025-08-15 02:52:38,167:INFO:Epoch: 3900/10000 | Train Loss: 4.345e-01 | Dynamic Loss: 4.345e-01 | Regularization Loss: 1.635e-07 | Val Loss: 4.346e-01 | Time: 4.78s
2025-08-15 02:52:42,939:INFO:Epoch: 3950/10000 | Train Loss: 4.327e-01 | Dynamic Loss: 4.327e-01 | Regularization Loss: 1.616e-07 | Val Loss: 4.322e-01 | Time: 4.77s
2025-08-15 02:52:42,939:INFO:New best model found at epoch 3950 with validation loss 4.322e-01. Saving...
2025-08-15 02:52:47,620:INFO:Epoch: 4000/10000 | Train Loss: 4.316e-01 | Dynamic Loss: 4.316e-01 | Regularization Loss: 1.595e-07 | Val Loss: 4.313e-01 | Time: 4.67s
2025-08-15 02:52:47,620:INFO:New best model found at epoch 4000 with validation loss 4.313e-01. Saving...
2025-08-15 02:52:56,109:INFO:Epoch: 4050/10000 | Train Loss: 4.292e-01 | Dynamic Loss: 4.292e-01 | Regularization Loss: 1.586e-07 | Val Loss: 4.292e-01 | Time: 8.48s
2025-08-15 02:52:56,109:INFO:New best model found at epoch 4050 with validation loss 4.292e-01. Saving...
2025-08-15 02:53:01,032:INFO:Epoch: 4100/10000 | Train Loss: 4.274e-01 | Dynamic Loss: 4.274e-01 | Regularization Loss: 1.563e-07 | Val Loss: 4.275e-01 | Time: 4.91s
2025-08-15 02:53:01,032:INFO:New best model found at epoch 4100 with validation loss 4.275e-01. Saving...
2025-08-15 02:53:05,791:INFO:Epoch: 4150/10000 | Train Loss: 4.268e-01 | Dynamic Loss: 4.268e-01 | Regularization Loss: 1.551e-07 | Val Loss: 4.273e-01 | Time: 4.75s
2025-08-15 02:53:05,791:INFO:New best model found at epoch 4150 with validation loss 4.273e-01. Saving...
2025-08-15 02:53:10,581:INFO:Epoch: 4200/10000 | Train Loss: 4.267e-01 | Dynamic Loss: 4.267e-01 | Regularization Loss: 1.530e-07 | Val Loss: 4.265e-01 | Time: 4.78s
2025-08-15 02:53:10,581:INFO:New best model found at epoch 4200 with validation loss 4.265e-01. Saving...
2025-08-15 02:53:15,278:INFO:Epoch: 4250/10000 | Train Loss: 4.245e-01 | Dynamic Loss: 4.245e-01 | Regularization Loss: 1.517e-07 | Val Loss: 4.264e-01 | Time: 4.69s
2025-08-15 02:53:15,278:INFO:New best model found at epoch 4250 with validation loss 4.264e-01. Saving...
2025-08-15 02:53:25,801:INFO:Epoch: 4300/10000 | Train Loss: 4.238e-01 | Dynamic Loss: 4.238e-01 | Regularization Loss: 1.498e-07 | Val Loss: 4.248e-01 | Time: 10.51s
2025-08-15 02:53:25,802:INFO:New best model found at epoch 4300 with validation loss 4.248e-01. Saving...
2025-08-15 02:53:30,603:INFO:Epoch: 4350/10000 | Train Loss: 4.216e-01 | Dynamic Loss: 4.216e-01 | Regularization Loss: 1.483e-07 | Val Loss: 4.241e-01 | Time: 4.79s
2025-08-15 02:53:30,603:INFO:New best model found at epoch 4350 with validation loss 4.241e-01. Saving...
2025-08-15 02:53:35,349:INFO:Epoch: 4400/10000 | Train Loss: 4.222e-01 | Dynamic Loss: 4.222e-01 | Regularization Loss: 1.479e-07 | Val Loss: 4.240e-01 | Time: 4.74s
2025-08-15 02:53:35,350:INFO:New best model found at epoch 4400 with validation loss 4.240e-01. Saving...
2025-08-15 02:53:40,229:INFO:Epoch: 4450/10000 | Train Loss: 4.213e-01 | Dynamic Loss: 4.213e-01 | Regularization Loss: 1.465e-07 | Val Loss: 4.228e-01 | Time: 4.87s
2025-08-15 02:53:40,230:INFO:New best model found at epoch 4450 with validation loss 4.228e-01. Saving...
2025-08-15 02:53:44,997:INFO:Epoch: 4500/10000 | Train Loss: 4.207e-01 | Dynamic Loss: 4.207e-01 | Regularization Loss: 1.455e-07 | Val Loss: 4.224e-01 | Time: 4.76s
2025-08-15 02:53:44,997:INFO:New best model found at epoch 4500 with validation loss 4.224e-01. Saving...
2025-08-15 02:53:55,780:INFO:Epoch: 4550/10000 | Train Loss: 4.198e-01 | Dynamic Loss: 4.198e-01 | Regularization Loss: 1.433e-07 | Val Loss: 4.209e-01 | Time: 10.77s
2025-08-15 02:53:55,780:INFO:New best model found at epoch 4550 with validation loss 4.209e-01. Saving...
2025-08-15 02:54:00,547:INFO:Epoch: 4600/10000 | Train Loss: 4.175e-01 | Dynamic Loss: 4.175e-01 | Regularization Loss: 1.424e-07 | Val Loss: 4.203e-01 | Time: 4.76s
2025-08-15 02:54:00,547:INFO:New best model found at epoch 4600 with validation loss 4.203e-01. Saving...
2025-08-15 02:54:05,395:INFO:Epoch: 4650/10000 | Train Loss: 4.175e-01 | Dynamic Loss: 4.175e-01 | Regularization Loss: 1.419e-07 | Val Loss: 4.201e-01 | Time: 4.84s
2025-08-15 02:54:05,395:INFO:New best model found at epoch 4650 with validation loss 4.201e-01. Saving...
2025-08-15 02:54:10,169:INFO:Epoch: 4700/10000 | Train Loss: 4.159e-01 | Dynamic Loss: 4.159e-01 | Regularization Loss: 1.409e-07 | Val Loss: 4.193e-01 | Time: 4.77s
2025-08-15 02:54:10,169:INFO:New best model found at epoch 4700 with validation loss 4.193e-01. Saving...
2025-08-15 02:54:15,686:INFO:Epoch: 4750/10000 | Train Loss: 4.139e-01 | Dynamic Loss: 4.139e-01 | Regularization Loss: 1.382e-07 | Val Loss: 4.167e-01 | Time: 5.51s
2025-08-15 02:54:15,686:INFO:New best model found at epoch 4750 with validation loss 4.167e-01. Saving...
2025-08-15 02:54:20,454:INFO:Epoch: 4800/10000 | Train Loss: 4.135e-01 | Dynamic Loss: 4.135e-01 | Regularization Loss: 1.374e-07 | Val Loss: 4.167e-01 | Time: 4.76s
2025-08-15 02:54:25,232:INFO:Epoch: 4850/10000 | Train Loss: 4.107e-01 | Dynamic Loss: 4.107e-01 | Regularization Loss: 1.357e-07 | Val Loss: 4.151e-01 | Time: 4.78s
2025-08-15 02:54:25,232:INFO:New best model found at epoch 4850 with validation loss 4.151e-01. Saving...
2025-08-15 02:54:30,124:INFO:Epoch: 4900/10000 | Train Loss: 4.092e-01 | Dynamic Loss: 4.092e-01 | Regularization Loss: 1.338e-07 | Val Loss: 4.147e-01 | Time: 4.88s
2025-08-15 02:54:30,124:INFO:New best model found at epoch 4900 with validation loss 4.147e-01. Saving...
2025-08-15 02:54:35,011:INFO:Epoch: 4950/10000 | Train Loss: 4.091e-01 | Dynamic Loss: 4.091e-01 | Regularization Loss: 1.322e-07 | Val Loss: 4.139e-01 | Time: 4.88s
2025-08-15 02:54:35,012:INFO:New best model found at epoch 4950 with validation loss 4.139e-01. Saving...
2025-08-15 02:54:42,677:INFO:Epoch: 5000/10000 | Train Loss: 4.085e-01 | Dynamic Loss: 4.085e-01 | Regularization Loss: 1.313e-07 | Val Loss: 4.133e-01 | Time: 7.66s
2025-08-15 02:54:42,677:INFO:New best model found at epoch 5000 with validation loss 4.133e-01. Saving...
2025-08-15 02:54:47,435:INFO:Epoch: 5050/10000 | Train Loss: 4.073e-01 | Dynamic Loss: 4.073e-01 | Regularization Loss: 1.323e-07 | Val Loss: 4.126e-01 | Time: 4.75s
2025-08-15 02:54:47,435:INFO:New best model found at epoch 5050 with validation loss 4.126e-01. Saving...
2025-08-15 02:54:52,139:INFO:Epoch: 5100/10000 | Train Loss: 4.065e-01 | Dynamic Loss: 4.065e-01 | Regularization Loss: 1.297e-07 | Val Loss: 4.122e-01 | Time: 4.69s
2025-08-15 02:54:52,139:INFO:New best model found at epoch 5100 with validation loss 4.122e-01. Saving...
2025-08-15 02:54:56,859:INFO:Epoch: 5150/10000 | Train Loss: 4.073e-01 | Dynamic Loss: 4.073e-01 | Regularization Loss: 1.280e-07 | Val Loss: 4.117e-01 | Time: 4.71s
2025-08-15 02:54:56,860:INFO:New best model found at epoch 5150 with validation loss 4.117e-01. Saving...
2025-08-15 02:55:01,671:INFO:Epoch: 5200/10000 | Train Loss: 4.045e-01 | Dynamic Loss: 4.045e-01 | Regularization Loss: 1.277e-07 | Val Loss: 4.114e-01 | Time: 4.80s
2025-08-15 02:55:01,671:INFO:New best model found at epoch 5200 with validation loss 4.114e-01. Saving...
2025-08-15 02:55:09,069:INFO:Epoch: 5250/10000 | Train Loss: 4.060e-01 | Dynamic Loss: 4.060e-01 | Regularization Loss: 1.258e-07 | Val Loss: 4.107e-01 | Time: 7.39s
2025-08-15 02:55:09,069:INFO:New best model found at epoch 5250 with validation loss 4.107e-01. Saving...
2025-08-15 02:55:13,848:INFO:Epoch: 5300/10000 | Train Loss: 4.054e-01 | Dynamic Loss: 4.054e-01 | Regularization Loss: 1.263e-07 | Val Loss: 4.105e-01 | Time: 4.77s
2025-08-15 02:55:13,848:INFO:New best model found at epoch 5300 with validation loss 4.105e-01. Saving...
2025-08-15 02:55:18,698:INFO:Epoch: 5350/10000 | Train Loss: 4.036e-01 | Dynamic Loss: 4.036e-01 | Regularization Loss: 1.244e-07 | Val Loss: 4.104e-01 | Time: 4.84s
2025-08-15 02:55:18,698:INFO:New best model found at epoch 5350 with validation loss 4.104e-01. Saving...
2025-08-15 02:55:23,520:INFO:Epoch: 5400/10000 | Train Loss: 4.035e-01 | Dynamic Loss: 4.035e-01 | Regularization Loss: 1.244e-07 | Val Loss: 4.099e-01 | Time: 4.81s
2025-08-15 02:55:23,520:INFO:New best model found at epoch 5400 with validation loss 4.099e-01. Saving...
2025-08-15 02:55:28,315:INFO:Epoch: 5450/10000 | Train Loss: 4.027e-01 | Dynamic Loss: 4.027e-01 | Regularization Loss: 1.245e-07 | Val Loss: 4.093e-01 | Time: 4.79s
2025-08-15 02:55:28,315:INFO:New best model found at epoch 5450 with validation loss 4.093e-01. Saving...
2025-08-15 02:55:36,581:INFO:Epoch: 5500/10000 | Train Loss: 4.021e-01 | Dynamic Loss: 4.021e-01 | Regularization Loss: 1.234e-07 | Val Loss: 4.087e-01 | Time: 8.25s
2025-08-15 02:55:36,581:INFO:New best model found at epoch 5500 with validation loss 4.087e-01. Saving...
2025-08-15 02:55:41,452:INFO:Epoch: 5550/10000 | Train Loss: 4.018e-01 | Dynamic Loss: 4.018e-01 | Regularization Loss: 1.204e-07 | Val Loss: 4.086e-01 | Time: 4.86s
2025-08-15 02:55:41,452:INFO:New best model found at epoch 5550 with validation loss 4.086e-01. Saving...
2025-08-15 02:55:46,291:INFO:Epoch: 5600/10000 | Train Loss: 4.019e-01 | Dynamic Loss: 4.019e-01 | Regularization Loss: 1.204e-07 | Val Loss: 4.084e-01 | Time: 4.83s
2025-08-15 02:55:46,291:INFO:New best model found at epoch 5600 with validation loss 4.084e-01. Saving...
2025-08-15 02:55:51,135:INFO:Epoch: 5650/10000 | Train Loss: 3.994e-01 | Dynamic Loss: 3.994e-01 | Regularization Loss: 1.220e-07 | Val Loss: 4.083e-01 | Time: 4.83s
2025-08-15 02:55:51,135:INFO:New best model found at epoch 5650 with validation loss 4.083e-01. Saving...
2025-08-15 02:55:55,920:INFO:Epoch: 5700/10000 | Train Loss: 4.003e-01 | Dynamic Loss: 4.003e-01 | Regularization Loss: 1.206e-07 | Val Loss: 4.090e-01 | Time: 4.78s
2025-08-15 02:56:06,411:INFO:Epoch: 5750/10000 | Train Loss: 3.980e-01 | Dynamic Loss: 3.980e-01 | Regularization Loss: 1.170e-07 | Val Loss: 4.072e-01 | Time: 10.49s
2025-08-15 02:56:06,412:INFO:New best model found at epoch 5750 with validation loss 4.072e-01. Saving...
2025-08-15 02:56:11,151:INFO:Epoch: 5800/10000 | Train Loss: 3.987e-01 | Dynamic Loss: 3.987e-01 | Regularization Loss: 1.172e-07 | Val Loss: 4.088e-01 | Time: 4.73s
2025-08-15 02:56:15,969:INFO:Epoch: 5850/10000 | Train Loss: 3.951e-01 | Dynamic Loss: 3.951e-01 | Regularization Loss: 1.163e-07 | Val Loss: 4.062e-01 | Time: 4.82s
2025-08-15 02:56:15,969:INFO:New best model found at epoch 5850 with validation loss 4.062e-01. Saving...
2025-08-15 02:56:20,853:INFO:Epoch: 5900/10000 | Train Loss: 3.931e-01 | Dynamic Loss: 3.931e-01 | Regularization Loss: 1.125e-07 | Val Loss: 4.043e-01 | Time: 4.87s
2025-08-15 02:56:20,853:INFO:New best model found at epoch 5900 with validation loss 4.043e-01. Saving...
2025-08-15 02:56:25,674:INFO:Epoch: 5950/10000 | Train Loss: 3.925e-01 | Dynamic Loss: 3.925e-01 | Regularization Loss: 1.117e-07 | Val Loss: 4.030e-01 | Time: 4.81s
2025-08-15 02:56:25,674:INFO:New best model found at epoch 5950 with validation loss 4.030e-01. Saving...
2025-08-15 02:56:36,730:INFO:Epoch: 6000/10000 | Train Loss: 3.909e-01 | Dynamic Loss: 3.909e-01 | Regularization Loss: 1.103e-07 | Val Loss: 4.026e-01 | Time: 11.05s
2025-08-15 02:56:36,731:INFO:New best model found at epoch 6000 with validation loss 4.026e-01. Saving...
2025-08-15 02:56:41,645:INFO:Epoch: 6050/10000 | Train Loss: 3.905e-01 | Dynamic Loss: 3.905e-01 | Regularization Loss: 1.085e-07 | Val Loss: 4.015e-01 | Time: 4.90s
2025-08-15 02:56:41,647:INFO:New best model found at epoch 6050 with validation loss 4.015e-01. Saving...
2025-08-15 02:56:46,486:INFO:Epoch: 6100/10000 | Train Loss: 3.875e-01 | Dynamic Loss: 3.875e-01 | Regularization Loss: 1.037e-07 | Val Loss: 4.016e-01 | Time: 4.83s
2025-08-15 02:56:51,222:INFO:Epoch: 6150/10000 | Train Loss: 3.877e-01 | Dynamic Loss: 3.877e-01 | Regularization Loss: 1.236e-07 | Val Loss: 3.999e-01 | Time: 4.74s
2025-08-15 02:56:51,222:INFO:New best model found at epoch 6150 with validation loss 3.999e-01. Saving...
2025-08-15 02:56:56,055:INFO:Epoch: 6200/10000 | Train Loss: 3.877e-01 | Dynamic Loss: 3.877e-01 | Regularization Loss: 0.000e+00 | Val Loss: 4.011e-01 | Time: 4.82s
2025-08-15 02:57:00,858:INFO:Epoch: 6250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.80s
2025-08-15 02:57:05,634:INFO:Epoch: 6300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.78s
2025-08-15 02:57:10,377:INFO:Epoch: 6350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.74s
2025-08-15 02:57:15,166:INFO:Epoch: 6400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.79s
2025-08-15 02:57:24,720:INFO:Epoch: 6450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 9.55s
2025-08-15 02:57:29,499:INFO:Epoch: 6500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.78s
2025-08-15 02:57:34,277:INFO:Epoch: 6550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.78s
2025-08-15 02:57:39,068:INFO:Epoch: 6600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.79s
2025-08-15 02:57:43,833:INFO:Epoch: 6650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.76s
2025-08-15 02:57:54,801:INFO:Epoch: 6700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 10.97s
2025-08-15 02:57:59,724:INFO:Epoch: 6750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.92s
2025-08-15 02:58:04,538:INFO:Epoch: 6800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.81s
2025-08-15 02:58:09,395:INFO:Epoch: 6850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.86s
2025-08-15 02:58:14,204:INFO:Epoch: 6900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.81s
2025-08-15 02:58:19,064:INFO:Epoch: 6950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.86s
2025-08-15 02:58:23,873:INFO:Epoch: 7000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.81s
2025-08-15 02:58:28,683:INFO:Epoch: 7050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.81s
2025-08-15 02:58:33,461:INFO:Epoch: 7100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.78s
2025-08-15 02:58:40,173:INFO:Epoch: 7150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 6.71s
2025-08-15 02:58:44,965:INFO:Epoch: 7200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.79s
2025-08-15 02:58:49,705:INFO:Epoch: 7250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.74s
2025-08-15 02:58:55,202:INFO:Epoch: 7300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.50s
2025-08-15 02:58:59,963:INFO:Epoch: 7350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.76s
2025-08-15 02:59:10,980:INFO:Epoch: 7400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 11.02s
2025-08-15 02:59:15,801:INFO:Epoch: 7450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.82s
2025-08-15 02:59:20,646:INFO:Epoch: 7500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.84s
2025-08-15 02:59:25,460:INFO:Epoch: 7550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.81s
2025-08-15 02:59:30,393:INFO:Epoch: 7600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.93s
2025-08-15 02:59:35,164:INFO:Epoch: 7650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.77s
2025-08-15 02:59:39,946:INFO:Epoch: 7700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.78s
2025-08-15 02:59:44,968:INFO:Epoch: 7750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.02s
2025-08-15 02:59:49,786:INFO:Epoch: 7800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.82s
2025-08-15 02:59:59,353:INFO:Epoch: 7850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 9.57s
2025-08-15 03:00:04,181:INFO:Epoch: 7900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.83s
2025-08-15 03:00:09,050:INFO:Epoch: 7950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.87s
2025-08-15 03:00:13,848:INFO:Epoch: 8000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.80s
2025-08-15 03:00:18,699:INFO:Epoch: 8050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.85s
2025-08-15 03:00:27,373:INFO:Epoch: 8100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 8.67s
2025-08-15 03:00:32,209:INFO:Epoch: 8150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.84s
2025-08-15 03:00:37,062:INFO:Epoch: 8200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.85s
2025-08-15 03:00:41,938:INFO:Epoch: 8250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.88s
2025-08-15 03:00:46,808:INFO:Epoch: 8300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.87s
2025-08-15 03:00:54,702:INFO:Epoch: 8350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 7.89s
2025-08-15 03:00:59,603:INFO:Epoch: 8400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.90s
2025-08-15 03:01:04,359:INFO:Epoch: 8450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.76s
2025-08-15 03:01:09,264:INFO:Epoch: 8500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.91s
2025-08-15 03:01:14,094:INFO:Epoch: 8550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.83s
2025-08-15 03:01:23,088:INFO:Epoch: 8600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 8.99s
2025-08-15 03:01:27,968:INFO:Epoch: 8650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.88s
2025-08-15 03:01:32,843:INFO:Epoch: 8700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.87s
2025-08-15 03:01:37,699:INFO:Epoch: 8750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.86s
2025-08-15 03:01:42,502:INFO:Epoch: 8800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.80s
2025-08-15 03:01:52,359:INFO:Epoch: 8850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 9.86s
2025-08-15 03:01:57,247:INFO:Epoch: 8900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.89s
2025-08-15 03:02:02,093:INFO:Epoch: 8950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.85s
2025-08-15 03:02:06,951:INFO:Epoch: 9000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.86s
2025-08-15 03:02:11,773:INFO:Epoch: 9050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.82s
2025-08-15 03:02:22,984:INFO:Epoch: 9100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 11.21s
2025-08-15 03:02:27,862:INFO:Epoch: 9150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.88s
2025-08-15 03:02:32,712:INFO:Epoch: 9200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.85s
2025-08-15 03:02:37,531:INFO:Epoch: 9250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.82s
2025-08-15 03:02:42,491:INFO:Epoch: 9300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.96s
2025-08-15 03:02:47,411:INFO:Epoch: 9350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.92s
2025-08-15 03:02:52,274:INFO:Epoch: 9400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.86s
2025-08-15 03:02:57,149:INFO:Epoch: 9450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.88s
2025-08-15 03:03:01,903:INFO:Epoch: 9500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.75s
2025-08-15 03:03:07,915:INFO:Epoch: 9550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 6.01s
2025-08-15 03:03:12,786:INFO:Epoch: 9600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.87s
2025-08-15 03:03:17,670:INFO:Epoch: 9650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.88s
2025-08-15 03:03:22,570:INFO:Epoch: 9700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.90s
2025-08-15 03:03:27,445:INFO:Epoch: 9750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.87s
2025-08-15 03:03:38,015:INFO:Epoch: 9800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 10.57s
2025-08-15 03:03:42,890:INFO:Epoch: 9850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.87s
2025-08-15 03:03:47,730:INFO:Epoch: 9900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.84s
2025-08-15 03:03:52,621:INFO:Epoch: 9950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.89s
2025-08-15 03:03:57,512:INFO:Epoch: 10000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.89s
