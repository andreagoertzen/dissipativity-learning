2025-08-15 02:45:30,070:INFO:Created DataLoaders with 2994 training samples and 998 validation samples.
2025-08-15 02:45:30,670:INFO:model params: 479490
2025-08-15 02:45:31,443:INFO:Epoch: 0/10000 | Train Loss: 5.094e+00 | Dynamic Loss: 5.094e+00 | Regularization Loss: 6.195e-20 | Val Loss: 3.413e+00 | Time: 0.77s
2025-08-15 02:45:31,444:INFO:New best model found at epoch 0 with validation loss 3.413e+00. Saving...
2025-08-15 02:45:36,209:INFO:Epoch: 50/10000 | Train Loss: 9.023e-01 | Dynamic Loss: 9.023e-01 | Regularization Loss: 2.074e-16 | Val Loss: 9.511e-01 | Time: 4.71s
2025-08-15 02:45:36,209:INFO:New best model found at epoch 50 with validation loss 9.511e-01. Saving...
2025-08-15 02:45:40,796:INFO:Epoch: 100/10000 | Train Loss: 7.129e-01 | Dynamic Loss: 7.129e-01 | Regularization Loss: 1.892e-10 | Val Loss: 7.449e-01 | Time: 4.58s
2025-08-15 02:45:40,796:INFO:New best model found at epoch 100 with validation loss 7.449e-01. Saving...
2025-08-15 02:45:45,563:INFO:Epoch: 150/10000 | Train Loss: 6.428e-01 | Dynamic Loss: 6.428e-01 | Regularization Loss: 6.009e-07 | Val Loss: 6.643e-01 | Time: 4.76s
2025-08-15 02:45:45,563:INFO:New best model found at epoch 150 with validation loss 6.643e-01. Saving...
2025-08-15 02:45:50,367:INFO:Epoch: 200/10000 | Train Loss: 6.072e-01 | Dynamic Loss: 6.072e-01 | Regularization Loss: 6.033e-07 | Val Loss: 6.250e-01 | Time: 4.79s
2025-08-15 02:45:50,367:INFO:New best model found at epoch 200 with validation loss 6.250e-01. Saving...
2025-08-15 02:45:55,152:INFO:Epoch: 250/10000 | Train Loss: 5.945e-01 | Dynamic Loss: 5.945e-01 | Regularization Loss: 5.886e-07 | Val Loss: 6.017e-01 | Time: 4.78s
2025-08-15 02:45:55,152:INFO:New best model found at epoch 250 with validation loss 6.017e-01. Saving...
2025-08-15 02:45:59,935:INFO:Epoch: 300/10000 | Train Loss: 5.789e-01 | Dynamic Loss: 5.789e-01 | Regularization Loss: 5.680e-07 | Val Loss: 5.847e-01 | Time: 4.77s
2025-08-15 02:45:59,935:INFO:New best model found at epoch 300 with validation loss 5.847e-01. Saving...
2025-08-15 02:46:04,767:INFO:Epoch: 350/10000 | Train Loss: 5.727e-01 | Dynamic Loss: 5.727e-01 | Regularization Loss: 5.495e-07 | Val Loss: 5.742e-01 | Time: 4.82s
2025-08-15 02:46:04,767:INFO:New best model found at epoch 350 with validation loss 5.742e-01. Saving...
2025-08-15 02:46:09,609:INFO:Epoch: 400/10000 | Train Loss: 5.669e-01 | Dynamic Loss: 5.669e-01 | Regularization Loss: 5.333e-07 | Val Loss: 5.678e-01 | Time: 4.83s
2025-08-15 02:46:09,609:INFO:New best model found at epoch 400 with validation loss 5.678e-01. Saving...
2025-08-15 02:46:19,839:INFO:Epoch: 450/10000 | Train Loss: 5.642e-01 | Dynamic Loss: 5.642e-01 | Regularization Loss: 5.191e-07 | Val Loss: 5.585e-01 | Time: 10.22s
2025-08-15 02:46:19,839:INFO:New best model found at epoch 450 with validation loss 5.585e-01. Saving...
2025-08-15 02:46:24,723:INFO:Epoch: 500/10000 | Train Loss: 5.556e-01 | Dynamic Loss: 5.556e-01 | Regularization Loss: 5.009e-07 | Val Loss: 5.507e-01 | Time: 4.87s
2025-08-15 02:46:24,723:INFO:New best model found at epoch 500 with validation loss 5.507e-01. Saving...
2025-08-15 02:46:29,597:INFO:Epoch: 550/10000 | Train Loss: 5.512e-01 | Dynamic Loss: 5.512e-01 | Regularization Loss: 4.877e-07 | Val Loss: 5.461e-01 | Time: 4.86s
2025-08-15 02:46:29,597:INFO:New best model found at epoch 550 with validation loss 5.461e-01. Saving...
2025-08-15 02:46:34,422:INFO:Epoch: 600/10000 | Train Loss: 5.478e-01 | Dynamic Loss: 5.478e-01 | Regularization Loss: 4.723e-07 | Val Loss: 5.410e-01 | Time: 4.82s
2025-08-15 02:46:34,422:INFO:New best model found at epoch 600 with validation loss 5.410e-01. Saving...
2025-08-15 02:46:42,190:INFO:Epoch: 650/10000 | Train Loss: 5.436e-01 | Dynamic Loss: 5.436e-01 | Regularization Loss: 4.592e-07 | Val Loss: 5.357e-01 | Time: 7.76s
2025-08-15 02:46:42,190:INFO:New best model found at epoch 650 with validation loss 5.357e-01. Saving...
2025-08-15 02:46:47,080:INFO:Epoch: 700/10000 | Train Loss: 5.396e-01 | Dynamic Loss: 5.396e-01 | Regularization Loss: 4.444e-07 | Val Loss: 5.307e-01 | Time: 4.88s
2025-08-15 02:46:47,080:INFO:New best model found at epoch 700 with validation loss 5.307e-01. Saving...
2025-08-15 02:46:51,985:INFO:Epoch: 750/10000 | Train Loss: 5.373e-01 | Dynamic Loss: 5.373e-01 | Regularization Loss: 4.335e-07 | Val Loss: 5.273e-01 | Time: 4.90s
2025-08-15 02:46:51,985:INFO:New best model found at epoch 750 with validation loss 5.273e-01. Saving...
2025-08-15 02:46:57,218:INFO:Epoch: 800/10000 | Train Loss: 5.355e-01 | Dynamic Loss: 5.355e-01 | Regularization Loss: 4.234e-07 | Val Loss: 5.238e-01 | Time: 5.22s
2025-08-15 02:46:57,218:INFO:New best model found at epoch 800 with validation loss 5.238e-01. Saving...
2025-08-15 02:47:02,122:INFO:Epoch: 850/10000 | Train Loss: 5.289e-01 | Dynamic Loss: 5.289e-01 | Regularization Loss: 4.105e-07 | Val Loss: 5.193e-01 | Time: 4.89s
2025-08-15 02:47:02,122:INFO:New best model found at epoch 850 with validation loss 5.193e-01. Saving...
2025-08-15 02:47:12,846:INFO:Epoch: 900/10000 | Train Loss: 5.267e-01 | Dynamic Loss: 5.267e-01 | Regularization Loss: 4.005e-07 | Val Loss: 5.151e-01 | Time: 10.72s
2025-08-15 02:47:12,846:INFO:New best model found at epoch 900 with validation loss 5.151e-01. Saving...
2025-08-15 02:47:17,707:INFO:Epoch: 950/10000 | Train Loss: 5.225e-01 | Dynamic Loss: 5.225e-01 | Regularization Loss: 3.911e-07 | Val Loss: 5.129e-01 | Time: 4.85s
2025-08-15 02:47:17,707:INFO:New best model found at epoch 950 with validation loss 5.129e-01. Saving...
2025-08-15 02:47:22,546:INFO:Epoch: 1000/10000 | Train Loss: 5.201e-01 | Dynamic Loss: 5.201e-01 | Regularization Loss: 3.805e-07 | Val Loss: 5.092e-01 | Time: 4.83s
2025-08-15 02:47:22,546:INFO:New best model found at epoch 1000 with validation loss 5.092e-01. Saving...
2025-08-15 02:47:27,377:INFO:Epoch: 1050/10000 | Train Loss: 5.181e-01 | Dynamic Loss: 5.181e-01 | Regularization Loss: 3.705e-07 | Val Loss: 5.069e-01 | Time: 4.82s
2025-08-15 02:47:27,377:INFO:New best model found at epoch 1050 with validation loss 5.069e-01. Saving...
2025-08-15 02:47:32,167:INFO:Epoch: 1100/10000 | Train Loss: 5.149e-01 | Dynamic Loss: 5.149e-01 | Regularization Loss: 3.624e-07 | Val Loss: 5.046e-01 | Time: 4.78s
2025-08-15 02:47:32,167:INFO:New best model found at epoch 1100 with validation loss 5.046e-01. Saving...
2025-08-15 02:47:43,524:INFO:Epoch: 1150/10000 | Train Loss: 5.138e-01 | Dynamic Loss: 5.138e-01 | Regularization Loss: 3.537e-07 | Val Loss: 5.022e-01 | Time: 11.35s
2025-08-15 02:47:43,524:INFO:New best model found at epoch 1150 with validation loss 5.022e-01. Saving...
2025-08-15 02:47:48,378:INFO:Epoch: 1200/10000 | Train Loss: 5.100e-01 | Dynamic Loss: 5.100e-01 | Regularization Loss: 3.466e-07 | Val Loss: 4.988e-01 | Time: 4.84s
2025-08-15 02:47:48,378:INFO:New best model found at epoch 1200 with validation loss 4.988e-01. Saving...
2025-08-15 02:47:53,212:INFO:Epoch: 1250/10000 | Train Loss: 5.078e-01 | Dynamic Loss: 5.078e-01 | Regularization Loss: 3.406e-07 | Val Loss: 4.956e-01 | Time: 4.82s
2025-08-15 02:47:53,212:INFO:New best model found at epoch 1250 with validation loss 4.956e-01. Saving...
2025-08-15 02:47:58,148:INFO:Epoch: 1300/10000 | Train Loss: 5.061e-01 | Dynamic Loss: 5.061e-01 | Regularization Loss: 3.317e-07 | Val Loss: 4.939e-01 | Time: 4.93s
2025-08-15 02:47:58,148:INFO:New best model found at epoch 1300 with validation loss 4.939e-01. Saving...
2025-08-15 02:48:02,923:INFO:Epoch: 1350/10000 | Train Loss: 5.039e-01 | Dynamic Loss: 5.039e-01 | Regularization Loss: 3.273e-07 | Val Loss: 4.917e-01 | Time: 4.77s
2025-08-15 02:48:02,923:INFO:New best model found at epoch 1350 with validation loss 4.917e-01. Saving...
2025-08-15 02:48:07,743:INFO:Epoch: 1400/10000 | Train Loss: 5.019e-01 | Dynamic Loss: 5.019e-01 | Regularization Loss: 3.194e-07 | Val Loss: 4.924e-01 | Time: 4.81s
2025-08-15 02:48:12,565:INFO:Epoch: 1450/10000 | Train Loss: 4.994e-01 | Dynamic Loss: 4.994e-01 | Regularization Loss: 3.133e-07 | Val Loss: 4.891e-01 | Time: 4.82s
2025-08-15 02:48:12,565:INFO:New best model found at epoch 1450 with validation loss 4.891e-01. Saving...
2025-08-15 02:48:17,342:INFO:Epoch: 1500/10000 | Train Loss: 4.985e-01 | Dynamic Loss: 4.985e-01 | Regularization Loss: 3.060e-07 | Val Loss: 4.874e-01 | Time: 4.77s
2025-08-15 02:48:17,342:INFO:New best model found at epoch 1500 with validation loss 4.874e-01. Saving...
2025-08-15 02:48:26,204:INFO:Epoch: 1550/10000 | Train Loss: 4.946e-01 | Dynamic Loss: 4.946e-01 | Regularization Loss: 3.027e-07 | Val Loss: 4.836e-01 | Time: 8.85s
2025-08-15 02:48:26,204:INFO:New best model found at epoch 1550 with validation loss 4.836e-01. Saving...
2025-08-15 02:48:31,067:INFO:Epoch: 1600/10000 | Train Loss: 4.944e-01 | Dynamic Loss: 4.944e-01 | Regularization Loss: 2.968e-07 | Val Loss: 4.812e-01 | Time: 4.85s
2025-08-15 02:48:31,067:INFO:New best model found at epoch 1600 with validation loss 4.812e-01. Saving...
2025-08-15 02:48:35,949:INFO:Epoch: 1650/10000 | Train Loss: 4.920e-01 | Dynamic Loss: 4.920e-01 | Regularization Loss: 2.924e-07 | Val Loss: 4.815e-01 | Time: 4.87s
2025-08-15 02:48:42,231:INFO:Epoch: 1700/10000 | Train Loss: 4.911e-01 | Dynamic Loss: 4.911e-01 | Regularization Loss: 2.864e-07 | Val Loss: 4.803e-01 | Time: 6.28s
2025-08-15 02:48:42,231:INFO:New best model found at epoch 1700 with validation loss 4.803e-01. Saving...
2025-08-15 02:48:47,063:INFO:Epoch: 1750/10000 | Train Loss: 4.903e-01 | Dynamic Loss: 4.903e-01 | Regularization Loss: 2.829e-07 | Val Loss: 4.778e-01 | Time: 4.82s
2025-08-15 02:48:47,063:INFO:New best model found at epoch 1750 with validation loss 4.778e-01. Saving...
2025-08-15 02:48:52,039:INFO:Epoch: 1800/10000 | Train Loss: 4.863e-01 | Dynamic Loss: 4.863e-01 | Regularization Loss: 2.778e-07 | Val Loss: 4.756e-01 | Time: 4.97s
2025-08-15 02:48:52,039:INFO:New best model found at epoch 1800 with validation loss 4.756e-01. Saving...
2025-08-15 02:48:56,893:INFO:Epoch: 1850/10000 | Train Loss: 4.848e-01 | Dynamic Loss: 4.848e-01 | Regularization Loss: 2.735e-07 | Val Loss: 4.746e-01 | Time: 4.84s
2025-08-15 02:48:56,893:INFO:New best model found at epoch 1850 with validation loss 4.746e-01. Saving...
2025-08-15 02:49:06,322:INFO:Epoch: 1900/10000 | Train Loss: 4.855e-01 | Dynamic Loss: 4.855e-01 | Regularization Loss: 2.699e-07 | Val Loss: 4.747e-01 | Time: 9.42s
2025-08-15 02:49:11,220:INFO:Epoch: 1950/10000 | Train Loss: 4.846e-01 | Dynamic Loss: 4.846e-01 | Regularization Loss: 2.638e-07 | Val Loss: 4.723e-01 | Time: 4.90s
2025-08-15 02:49:11,220:INFO:New best model found at epoch 1950 with validation loss 4.723e-01. Saving...
2025-08-15 02:49:16,305:INFO:Epoch: 2000/10000 | Train Loss: 4.772e-01 | Dynamic Loss: 4.772e-01 | Regularization Loss: 2.586e-07 | Val Loss: 4.690e-01 | Time: 5.08s
2025-08-15 02:49:16,305:INFO:New best model found at epoch 2000 with validation loss 4.690e-01. Saving...
2025-08-15 02:49:21,215:INFO:Epoch: 2050/10000 | Train Loss: 4.780e-01 | Dynamic Loss: 4.780e-01 | Regularization Loss: 2.533e-07 | Val Loss: 4.706e-01 | Time: 4.90s
2025-08-15 02:49:29,465:INFO:Epoch: 2100/10000 | Train Loss: 4.745e-01 | Dynamic Loss: 4.745e-01 | Regularization Loss: 2.496e-07 | Val Loss: 4.674e-01 | Time: 8.25s
2025-08-15 02:49:29,465:INFO:New best model found at epoch 2100 with validation loss 4.674e-01. Saving...
2025-08-15 02:49:34,411:INFO:Epoch: 2150/10000 | Train Loss: 4.719e-01 | Dynamic Loss: 4.719e-01 | Regularization Loss: 2.434e-07 | Val Loss: 4.662e-01 | Time: 4.94s
2025-08-15 02:49:34,411:INFO:New best model found at epoch 2150 with validation loss 4.662e-01. Saving...
2025-08-15 02:49:39,359:INFO:Epoch: 2200/10000 | Train Loss: 4.706e-01 | Dynamic Loss: 4.706e-01 | Regularization Loss: 2.390e-07 | Val Loss: 4.620e-01 | Time: 4.94s
2025-08-15 02:49:39,359:INFO:New best model found at epoch 2200 with validation loss 4.620e-01. Saving...
2025-08-15 02:49:44,267:INFO:Epoch: 2250/10000 | Train Loss: 4.667e-01 | Dynamic Loss: 4.667e-01 | Regularization Loss: 2.339e-07 | Val Loss: 4.615e-01 | Time: 4.90s
2025-08-15 02:49:44,267:INFO:New best model found at epoch 2250 with validation loss 4.615e-01. Saving...
2025-08-15 02:49:49,252:INFO:Epoch: 2300/10000 | Train Loss: 4.645e-01 | Dynamic Loss: 4.645e-01 | Regularization Loss: 2.297e-07 | Val Loss: 4.598e-01 | Time: 4.98s
2025-08-15 02:49:49,252:INFO:New best model found at epoch 2300 with validation loss 4.598e-01. Saving...
2025-08-15 02:49:57,710:INFO:Epoch: 2350/10000 | Train Loss: 4.631e-01 | Dynamic Loss: 4.631e-01 | Regularization Loss: 2.246e-07 | Val Loss: 4.572e-01 | Time: 8.45s
2025-08-15 02:49:57,710:INFO:New best model found at epoch 2350 with validation loss 4.572e-01. Saving...
2025-08-15 02:50:02,595:INFO:Epoch: 2400/10000 | Train Loss: 4.639e-01 | Dynamic Loss: 4.639e-01 | Regularization Loss: 2.229e-07 | Val Loss: 4.604e-01 | Time: 4.88s
2025-08-15 02:50:07,465:INFO:Epoch: 2450/10000 | Train Loss: 4.603e-01 | Dynamic Loss: 4.603e-01 | Regularization Loss: 2.212e-07 | Val Loss: 4.550e-01 | Time: 4.87s
2025-08-15 02:50:07,466:INFO:New best model found at epoch 2450 with validation loss 4.550e-01. Saving...
2025-08-15 02:50:12,307:INFO:Epoch: 2500/10000 | Train Loss: 4.591e-01 | Dynamic Loss: 4.591e-01 | Regularization Loss: 2.173e-07 | Val Loss: 4.548e-01 | Time: 4.83s
2025-08-15 02:50:12,307:INFO:New best model found at epoch 2500 with validation loss 4.548e-01. Saving...
2025-08-15 02:50:17,871:INFO:Epoch: 2550/10000 | Train Loss: 4.596e-01 | Dynamic Loss: 4.596e-01 | Regularization Loss: 2.163e-07 | Val Loss: 4.562e-01 | Time: 5.56s
2025-08-15 02:50:22,731:INFO:Epoch: 2600/10000 | Train Loss: 4.577e-01 | Dynamic Loss: 4.577e-01 | Regularization Loss: 2.127e-07 | Val Loss: 4.535e-01 | Time: 4.86s
2025-08-15 02:50:22,731:INFO:New best model found at epoch 2600 with validation loss 4.535e-01. Saving...
2025-08-15 02:50:27,598:INFO:Epoch: 2650/10000 | Train Loss: 4.573e-01 | Dynamic Loss: 4.573e-01 | Regularization Loss: 2.108e-07 | Val Loss: 4.527e-01 | Time: 4.86s
2025-08-15 02:50:27,598:INFO:New best model found at epoch 2650 with validation loss 4.527e-01. Saving...
2025-08-15 02:50:32,374:INFO:Epoch: 2700/10000 | Train Loss: 4.554e-01 | Dynamic Loss: 4.554e-01 | Regularization Loss: 2.082e-07 | Val Loss: 4.508e-01 | Time: 4.77s
2025-08-15 02:50:32,374:INFO:New best model found at epoch 2700 with validation loss 4.508e-01. Saving...
2025-08-15 02:50:42,188:INFO:Epoch: 2750/10000 | Train Loss: 4.539e-01 | Dynamic Loss: 4.539e-01 | Regularization Loss: 2.066e-07 | Val Loss: 4.505e-01 | Time: 9.80s
2025-08-15 02:50:42,188:INFO:New best model found at epoch 2750 with validation loss 4.505e-01. Saving...
2025-08-15 02:50:47,067:INFO:Epoch: 2800/10000 | Train Loss: 4.526e-01 | Dynamic Loss: 4.526e-01 | Regularization Loss: 2.041e-07 | Val Loss: 4.487e-01 | Time: 4.87s
2025-08-15 02:50:47,067:INFO:New best model found at epoch 2800 with validation loss 4.487e-01. Saving...
2025-08-15 02:50:52,000:INFO:Epoch: 2850/10000 | Train Loss: 4.518e-01 | Dynamic Loss: 4.518e-01 | Regularization Loss: 2.008e-07 | Val Loss: 4.478e-01 | Time: 4.92s
2025-08-15 02:50:52,000:INFO:New best model found at epoch 2850 with validation loss 4.478e-01. Saving...
2025-08-15 02:50:56,954:INFO:Epoch: 2900/10000 | Train Loss: 4.518e-01 | Dynamic Loss: 4.518e-01 | Regularization Loss: 1.993e-07 | Val Loss: 4.468e-01 | Time: 4.94s
2025-08-15 02:50:56,954:INFO:New best model found at epoch 2900 with validation loss 4.468e-01. Saving...
2025-08-15 02:51:01,766:INFO:Epoch: 2950/10000 | Train Loss: 4.513e-01 | Dynamic Loss: 4.513e-01 | Regularization Loss: 1.968e-07 | Val Loss: 4.460e-01 | Time: 4.80s
2025-08-15 02:51:01,766:INFO:New best model found at epoch 2950 with validation loss 4.460e-01. Saving...
2025-08-15 02:51:06,634:INFO:Epoch: 3000/10000 | Train Loss: 4.495e-01 | Dynamic Loss: 4.495e-01 | Regularization Loss: 1.933e-07 | Val Loss: 4.466e-01 | Time: 4.86s
2025-08-15 02:51:11,507:INFO:Epoch: 3050/10000 | Train Loss: 4.463e-01 | Dynamic Loss: 4.463e-01 | Regularization Loss: 1.919e-07 | Val Loss: 4.435e-01 | Time: 4.87s
2025-08-15 02:51:11,508:INFO:New best model found at epoch 3050 with validation loss 4.435e-01. Saving...
2025-08-15 02:51:21,312:INFO:Epoch: 3100/10000 | Train Loss: 4.483e-01 | Dynamic Loss: 4.483e-01 | Regularization Loss: 1.898e-07 | Val Loss: 4.448e-01 | Time: 9.80s
2025-08-15 02:51:26,224:INFO:Epoch: 3150/10000 | Train Loss: 4.466e-01 | Dynamic Loss: 4.466e-01 | Regularization Loss: 1.882e-07 | Val Loss: 4.428e-01 | Time: 4.91s
2025-08-15 02:51:26,224:INFO:New best model found at epoch 3150 with validation loss 4.428e-01. Saving...
2025-08-15 02:51:31,178:INFO:Epoch: 3200/10000 | Train Loss: 4.455e-01 | Dynamic Loss: 4.455e-01 | Regularization Loss: 1.868e-07 | Val Loss: 4.414e-01 | Time: 4.94s
2025-08-15 02:51:31,179:INFO:New best model found at epoch 3200 with validation loss 4.414e-01. Saving...
2025-08-15 02:51:36,116:INFO:Epoch: 3250/10000 | Train Loss: 4.436e-01 | Dynamic Loss: 4.436e-01 | Regularization Loss: 1.848e-07 | Val Loss: 4.412e-01 | Time: 4.93s
2025-08-15 02:51:36,116:INFO:New best model found at epoch 3250 with validation loss 4.412e-01. Saving...
2025-08-15 02:51:40,951:INFO:Epoch: 3300/10000 | Train Loss: 4.432e-01 | Dynamic Loss: 4.432e-01 | Regularization Loss: 1.832e-07 | Val Loss: 4.402e-01 | Time: 4.83s
2025-08-15 02:51:40,951:INFO:New best model found at epoch 3300 with validation loss 4.402e-01. Saving...
2025-08-15 02:51:52,121:INFO:Epoch: 3350/10000 | Train Loss: 4.417e-01 | Dynamic Loss: 4.417e-01 | Regularization Loss: 1.811e-07 | Val Loss: 4.388e-01 | Time: 11.16s
2025-08-15 02:51:52,121:INFO:New best model found at epoch 3350 with validation loss 4.388e-01. Saving...
2025-08-15 02:51:57,109:INFO:Epoch: 3400/10000 | Train Loss: 4.417e-01 | Dynamic Loss: 4.417e-01 | Regularization Loss: 1.800e-07 | Val Loss: 4.391e-01 | Time: 4.98s
2025-08-15 02:52:02,082:INFO:Epoch: 3450/10000 | Train Loss: 4.416e-01 | Dynamic Loss: 4.416e-01 | Regularization Loss: 1.777e-07 | Val Loss: 4.379e-01 | Time: 4.97s
2025-08-15 02:52:02,083:INFO:New best model found at epoch 3450 with validation loss 4.379e-01. Saving...
2025-08-15 02:52:06,975:INFO:Epoch: 3500/10000 | Train Loss: 4.413e-01 | Dynamic Loss: 4.412e-01 | Regularization Loss: 1.775e-07 | Val Loss: 4.379e-01 | Time: 4.88s
2025-08-15 02:52:14,008:INFO:Epoch: 3550/10000 | Train Loss: 4.406e-01 | Dynamic Loss: 4.406e-01 | Regularization Loss: 1.765e-07 | Val Loss: 4.372e-01 | Time: 7.03s
2025-08-15 02:52:14,008:INFO:New best model found at epoch 3550 with validation loss 4.372e-01. Saving...
2025-08-15 02:52:19,025:INFO:Epoch: 3600/10000 | Train Loss: 4.399e-01 | Dynamic Loss: 4.399e-01 | Regularization Loss: 1.756e-07 | Val Loss: 4.371e-01 | Time: 5.01s
2025-08-15 02:52:19,025:INFO:New best model found at epoch 3600 with validation loss 4.371e-01. Saving...
2025-08-15 02:52:24,008:INFO:Epoch: 3650/10000 | Train Loss: 4.395e-01 | Dynamic Loss: 4.395e-01 | Regularization Loss: 1.740e-07 | Val Loss: 4.364e-01 | Time: 4.97s
2025-08-15 02:52:24,008:INFO:New best model found at epoch 3650 with validation loss 4.364e-01. Saving...
2025-08-15 02:52:28,987:INFO:Epoch: 3700/10000 | Train Loss: 4.384e-01 | Dynamic Loss: 4.384e-01 | Regularization Loss: 1.734e-07 | Val Loss: 4.384e-01 | Time: 4.97s
2025-08-15 02:52:33,947:INFO:Epoch: 3750/10000 | Train Loss: 4.386e-01 | Dynamic Loss: 4.386e-01 | Regularization Loss: 1.713e-07 | Val Loss: 4.368e-01 | Time: 4.96s
2025-08-15 02:52:43,834:INFO:Epoch: 3800/10000 | Train Loss: 4.375e-01 | Dynamic Loss: 4.375e-01 | Regularization Loss: 1.703e-07 | Val Loss: 4.378e-01 | Time: 9.89s
2025-08-15 02:52:48,830:INFO:Epoch: 3850/10000 | Train Loss: 4.373e-01 | Dynamic Loss: 4.373e-01 | Regularization Loss: 1.686e-07 | Val Loss: 4.351e-01 | Time: 5.00s
2025-08-15 02:52:48,830:INFO:New best model found at epoch 3850 with validation loss 4.351e-01. Saving...
2025-08-15 02:52:53,843:INFO:Epoch: 3900/10000 | Train Loss: 4.364e-01 | Dynamic Loss: 4.364e-01 | Regularization Loss: 1.675e-07 | Val Loss: 4.353e-01 | Time: 5.00s
2025-08-15 02:52:58,819:INFO:Epoch: 3950/10000 | Train Loss: 4.359e-01 | Dynamic Loss: 4.359e-01 | Regularization Loss: 1.659e-07 | Val Loss: 4.342e-01 | Time: 4.98s
2025-08-15 02:52:58,819:INFO:New best model found at epoch 3950 with validation loss 4.342e-01. Saving...
2025-08-15 02:53:03,743:INFO:Epoch: 4000/10000 | Train Loss: 4.360e-01 | Dynamic Loss: 4.360e-01 | Regularization Loss: 1.646e-07 | Val Loss: 4.348e-01 | Time: 4.91s
2025-08-15 02:53:13,406:INFO:Epoch: 4050/10000 | Train Loss: 4.341e-01 | Dynamic Loss: 4.341e-01 | Regularization Loss: 1.636e-07 | Val Loss: 4.330e-01 | Time: 9.66s
2025-08-15 02:53:13,406:INFO:New best model found at epoch 4050 with validation loss 4.330e-01. Saving...
2025-08-15 02:53:18,409:INFO:Epoch: 4100/10000 | Train Loss: 4.342e-01 | Dynamic Loss: 4.342e-01 | Regularization Loss: 1.619e-07 | Val Loss: 4.337e-01 | Time: 4.99s
2025-08-15 02:53:23,526:INFO:Epoch: 4150/10000 | Train Loss: 4.313e-01 | Dynamic Loss: 4.313e-01 | Regularization Loss: 1.598e-07 | Val Loss: 4.314e-01 | Time: 5.12s
2025-08-15 02:53:23,526:INFO:New best model found at epoch 4150 with validation loss 4.314e-01. Saving...
2025-08-15 02:53:28,463:INFO:Epoch: 4200/10000 | Train Loss: 4.311e-01 | Dynamic Loss: 4.311e-01 | Regularization Loss: 1.577e-07 | Val Loss: 4.309e-01 | Time: 4.93s
2025-08-15 02:53:28,463:INFO:New best model found at epoch 4200 with validation loss 4.309e-01. Saving...
2025-08-15 02:53:33,362:INFO:Epoch: 4250/10000 | Train Loss: 4.282e-01 | Dynamic Loss: 4.282e-01 | Regularization Loss: 1.562e-07 | Val Loss: 4.297e-01 | Time: 4.89s
2025-08-15 02:53:33,362:INFO:New best model found at epoch 4250 with validation loss 4.297e-01. Saving...
2025-08-15 02:53:39,634:INFO:Epoch: 4300/10000 | Train Loss: 4.278e-01 | Dynamic Loss: 4.278e-01 | Regularization Loss: 1.541e-07 | Val Loss: 4.298e-01 | Time: 6.26s
2025-08-15 02:53:44,591:INFO:Epoch: 4350/10000 | Train Loss: 4.265e-01 | Dynamic Loss: 4.265e-01 | Regularization Loss: 1.523e-07 | Val Loss: 4.280e-01 | Time: 4.96s
2025-08-15 02:53:44,591:INFO:New best model found at epoch 4350 with validation loss 4.280e-01. Saving...
2025-08-15 02:53:49,528:INFO:Epoch: 4400/10000 | Train Loss: 4.255e-01 | Dynamic Loss: 4.255e-01 | Regularization Loss: 1.519e-07 | Val Loss: 4.270e-01 | Time: 4.93s
2025-08-15 02:53:49,528:INFO:New best model found at epoch 4400 with validation loss 4.270e-01. Saving...
2025-08-15 02:53:54,426:INFO:Epoch: 4450/10000 | Train Loss: 4.247e-01 | Dynamic Loss: 4.247e-01 | Regularization Loss: 1.502e-07 | Val Loss: 4.266e-01 | Time: 4.89s
2025-08-15 02:53:54,426:INFO:New best model found at epoch 4450 with validation loss 4.266e-01. Saving...
2025-08-15 02:53:59,504:INFO:Epoch: 4500/10000 | Train Loss: 4.244e-01 | Dynamic Loss: 4.244e-01 | Regularization Loss: 1.492e-07 | Val Loss: 4.265e-01 | Time: 5.07s
2025-08-15 02:53:59,504:INFO:New best model found at epoch 4500 with validation loss 4.265e-01. Saving...
2025-08-15 02:54:11,348:INFO:Epoch: 4550/10000 | Train Loss: 4.241e-01 | Dynamic Loss: 4.241e-01 | Regularization Loss: 1.474e-07 | Val Loss: 4.272e-01 | Time: 11.83s
2025-08-15 02:54:16,225:INFO:Epoch: 4600/10000 | Train Loss: 4.219e-01 | Dynamic Loss: 4.219e-01 | Regularization Loss: 1.466e-07 | Val Loss: 4.266e-01 | Time: 4.88s
2025-08-15 02:54:21,123:INFO:Epoch: 4650/10000 | Train Loss: 4.220e-01 | Dynamic Loss: 4.220e-01 | Regularization Loss: 1.461e-07 | Val Loss: 4.254e-01 | Time: 4.90s
2025-08-15 02:54:21,123:INFO:New best model found at epoch 4650 with validation loss 4.254e-01. Saving...
2025-08-15 02:54:26,115:INFO:Epoch: 4700/10000 | Train Loss: 4.213e-01 | Dynamic Loss: 4.213e-01 | Regularization Loss: 1.457e-07 | Val Loss: 4.258e-01 | Time: 4.98s
2025-08-15 02:54:35,577:INFO:Epoch: 4750/10000 | Train Loss: 4.215e-01 | Dynamic Loss: 4.215e-01 | Regularization Loss: 1.435e-07 | Val Loss: 4.241e-01 | Time: 9.46s
2025-08-15 02:54:35,577:INFO:New best model found at epoch 4750 with validation loss 4.241e-01. Saving...
2025-08-15 02:54:40,501:INFO:Epoch: 4800/10000 | Train Loss: 4.216e-01 | Dynamic Loss: 4.216e-01 | Regularization Loss: 1.440e-07 | Val Loss: 4.258e-01 | Time: 4.92s
2025-08-15 02:54:45,734:INFO:Epoch: 4850/10000 | Train Loss: 4.189e-01 | Dynamic Loss: 4.189e-01 | Regularization Loss: 1.424e-07 | Val Loss: 4.243e-01 | Time: 5.23s
2025-08-15 02:54:50,765:INFO:Epoch: 4900/10000 | Train Loss: 4.176e-01 | Dynamic Loss: 4.176e-01 | Regularization Loss: 1.404e-07 | Val Loss: 4.246e-01 | Time: 5.03s
2025-08-15 02:54:56,784:INFO:Epoch: 4950/10000 | Train Loss: 4.181e-01 | Dynamic Loss: 4.181e-01 | Regularization Loss: 1.393e-07 | Val Loss: 4.242e-01 | Time: 6.02s
2025-08-15 02:55:01,853:INFO:Epoch: 5000/10000 | Train Loss: 4.170e-01 | Dynamic Loss: 4.170e-01 | Regularization Loss: 1.390e-07 | Val Loss: 4.231e-01 | Time: 5.07s
2025-08-15 02:55:01,853:INFO:New best model found at epoch 5000 with validation loss 4.231e-01. Saving...
2025-08-15 02:55:06,888:INFO:Epoch: 5050/10000 | Train Loss: 4.176e-01 | Dynamic Loss: 4.176e-01 | Regularization Loss: 1.398e-07 | Val Loss: 4.229e-01 | Time: 5.03s
2025-08-15 02:55:06,889:INFO:New best model found at epoch 5050 with validation loss 4.229e-01. Saving...
2025-08-15 02:55:11,863:INFO:Epoch: 5100/10000 | Train Loss: 4.157e-01 | Dynamic Loss: 4.157e-01 | Regularization Loss: 1.368e-07 | Val Loss: 4.229e-01 | Time: 4.97s
2025-08-15 02:55:16,836:INFO:Epoch: 5150/10000 | Train Loss: 4.157e-01 | Dynamic Loss: 4.157e-01 | Regularization Loss: 1.348e-07 | Val Loss: 4.221e-01 | Time: 4.97s
2025-08-15 02:55:16,836:INFO:New best model found at epoch 5150 with validation loss 4.221e-01. Saving...
2025-08-15 02:55:21,901:INFO:Epoch: 5200/10000 | Train Loss: 4.135e-01 | Dynamic Loss: 4.135e-01 | Regularization Loss: 1.344e-07 | Val Loss: 4.217e-01 | Time: 5.06s
2025-08-15 02:55:21,902:INFO:New best model found at epoch 5200 with validation loss 4.217e-01. Saving...
2025-08-15 02:55:26,839:INFO:Epoch: 5250/10000 | Train Loss: 4.138e-01 | Dynamic Loss: 4.138e-01 | Regularization Loss: 1.323e-07 | Val Loss: 4.214e-01 | Time: 4.93s
2025-08-15 02:55:26,839:INFO:New best model found at epoch 5250 with validation loss 4.214e-01. Saving...
2025-08-15 02:55:31,811:INFO:Epoch: 5300/10000 | Train Loss: 4.112e-01 | Dynamic Loss: 4.112e-01 | Regularization Loss: 1.321e-07 | Val Loss: 4.189e-01 | Time: 4.96s
2025-08-15 02:55:31,811:INFO:New best model found at epoch 5300 with validation loss 4.189e-01. Saving...
2025-08-15 02:55:36,708:INFO:Epoch: 5350/10000 | Train Loss: 4.093e-01 | Dynamic Loss: 4.093e-01 | Regularization Loss: 1.294e-07 | Val Loss: 4.185e-01 | Time: 4.89s
2025-08-15 02:55:36,708:INFO:New best model found at epoch 5350 with validation loss 4.185e-01. Saving...
2025-08-15 02:55:41,556:INFO:Epoch: 5400/10000 | Train Loss: 4.082e-01 | Dynamic Loss: 4.082e-01 | Regularization Loss: 1.299e-07 | Val Loss: 4.183e-01 | Time: 4.84s
2025-08-15 02:55:41,556:INFO:New best model found at epoch 5400 with validation loss 4.183e-01. Saving...
2025-08-15 02:55:53,643:INFO:Epoch: 5450/10000 | Train Loss: 4.085e-01 | Dynamic Loss: 4.085e-01 | Regularization Loss: 1.296e-07 | Val Loss: 4.176e-01 | Time: 12.08s
2025-08-15 02:55:53,643:INFO:New best model found at epoch 5450 with validation loss 4.176e-01. Saving...
2025-08-15 02:55:58,719:INFO:Epoch: 5500/10000 | Train Loss: 4.072e-01 | Dynamic Loss: 4.072e-01 | Regularization Loss: 1.279e-07 | Val Loss: 4.164e-01 | Time: 5.07s
2025-08-15 02:55:58,719:INFO:New best model found at epoch 5500 with validation loss 4.164e-01. Saving...
2025-08-15 02:56:03,707:INFO:Epoch: 5550/10000 | Train Loss: 4.058e-01 | Dynamic Loss: 4.058e-01 | Regularization Loss: 1.254e-07 | Val Loss: 4.159e-01 | Time: 4.98s
2025-08-15 02:56:03,707:INFO:New best model found at epoch 5550 with validation loss 4.159e-01. Saving...
2025-08-15 02:56:08,645:INFO:Epoch: 5600/10000 | Train Loss: 4.068e-01 | Dynamic Loss: 4.068e-01 | Regularization Loss: 1.249e-07 | Val Loss: 4.159e-01 | Time: 4.93s
2025-08-15 02:56:08,645:INFO:New best model found at epoch 5600 with validation loss 4.159e-01. Saving...
2025-08-15 02:56:13,635:INFO:Epoch: 5650/10000 | Train Loss: 4.039e-01 | Dynamic Loss: 4.039e-01 | Regularization Loss: 1.261e-07 | Val Loss: 4.155e-01 | Time: 4.98s
2025-08-15 02:56:13,635:INFO:New best model found at epoch 5650 with validation loss 4.155e-01. Saving...
2025-08-15 02:56:26,150:INFO:Epoch: 5700/10000 | Train Loss: 4.039e-01 | Dynamic Loss: 4.039e-01 | Regularization Loss: 1.243e-07 | Val Loss: 4.145e-01 | Time: 12.51s
2025-08-15 02:56:26,151:INFO:New best model found at epoch 5700 with validation loss 4.145e-01. Saving...
2025-08-15 02:56:31,489:INFO:Epoch: 5750/10000 | Train Loss: 4.033e-01 | Dynamic Loss: 4.033e-01 | Regularization Loss: 1.212e-07 | Val Loss: 4.139e-01 | Time: 5.33s
2025-08-15 02:56:31,489:INFO:New best model found at epoch 5750 with validation loss 4.139e-01. Saving...
2025-08-15 02:56:36,834:INFO:Epoch: 5800/10000 | Train Loss: 4.033e-01 | Dynamic Loss: 4.033e-01 | Regularization Loss: 1.219e-07 | Val Loss: 4.142e-01 | Time: 5.33s
2025-08-15 02:56:41,984:INFO:Epoch: 5850/10000 | Train Loss: 4.018e-01 | Dynamic Loss: 4.018e-01 | Regularization Loss: 1.215e-07 | Val Loss: 4.128e-01 | Time: 5.15s
2025-08-15 02:56:41,984:INFO:New best model found at epoch 5850 with validation loss 4.128e-01. Saving...
2025-08-15 02:56:47,007:INFO:Epoch: 5900/10000 | Train Loss: 4.001e-01 | Dynamic Loss: 4.001e-01 | Regularization Loss: 1.187e-07 | Val Loss: 4.124e-01 | Time: 5.01s
2025-08-15 02:56:47,007:INFO:New best model found at epoch 5900 with validation loss 4.124e-01. Saving...
2025-08-15 02:56:59,292:INFO:Epoch: 5950/10000 | Train Loss: 4.002e-01 | Dynamic Loss: 4.002e-01 | Regularization Loss: 1.176e-07 | Val Loss: 4.120e-01 | Time: 12.27s
2025-08-15 02:56:59,292:INFO:New best model found at epoch 5950 with validation loss 4.120e-01. Saving...
2025-08-15 02:57:04,393:INFO:Epoch: 6000/10000 | Train Loss: 3.987e-01 | Dynamic Loss: 3.987e-01 | Regularization Loss: 1.160e-07 | Val Loss: 4.113e-01 | Time: 5.09s
2025-08-15 02:57:04,393:INFO:New best model found at epoch 6000 with validation loss 4.113e-01. Saving...
2025-08-15 02:57:09,370:INFO:Epoch: 6050/10000 | Train Loss: 3.979e-01 | Dynamic Loss: 3.979e-01 | Regularization Loss: 1.161e-07 | Val Loss: 4.102e-01 | Time: 4.97s
2025-08-15 02:57:09,370:INFO:New best model found at epoch 6050 with validation loss 4.102e-01. Saving...
2025-08-15 02:57:14,620:INFO:Epoch: 6100/10000 | Train Loss: 3.960e-01 | Dynamic Loss: 3.960e-01 | Regularization Loss: 1.152e-07 | Val Loss: 4.110e-01 | Time: 5.24s
2025-08-15 02:57:25,931:INFO:Epoch: 6150/10000 | Train Loss: 3.960e-01 | Dynamic Loss: 3.960e-01 | Regularization Loss: 1.136e-07 | Val Loss: 4.099e-01 | Time: 11.31s
2025-08-15 02:57:25,931:INFO:New best model found at epoch 6150 with validation loss 4.099e-01. Saving...
2025-08-15 02:57:30,957:INFO:Epoch: 6200/10000 | Train Loss: 3.941e-01 | Dynamic Loss: 3.941e-01 | Regularization Loss: 1.114e-07 | Val Loss: 4.080e-01 | Time: 5.02s
2025-08-15 02:57:30,957:INFO:New best model found at epoch 6200 with validation loss 4.080e-01. Saving...
2025-08-15 02:57:35,998:INFO:Epoch: 6250/10000 | Train Loss: 3.930e-01 | Dynamic Loss: 3.930e-01 | Regularization Loss: 1.100e-07 | Val Loss: 4.082e-01 | Time: 5.03s
2025-08-15 02:57:40,926:INFO:Epoch: 6300/10000 | Train Loss: 3.924e-01 | Dynamic Loss: 3.924e-01 | Regularization Loss: 1.115e-07 | Val Loss: 4.063e-01 | Time: 4.93s
2025-08-15 02:57:40,926:INFO:New best model found at epoch 6300 with validation loss 4.063e-01. Saving...
2025-08-15 02:57:49,533:INFO:Epoch: 6350/10000 | Train Loss: 3.920e-01 | Dynamic Loss: 3.920e-01 | Regularization Loss: 1.130e-07 | Val Loss: 4.064e-01 | Time: 8.60s
2025-08-15 02:57:54,505:INFO:Epoch: 6400/10000 | Train Loss: 3.919e-01 | Dynamic Loss: 3.919e-01 | Regularization Loss: 1.277e-07 | Val Loss: 4.059e-01 | Time: 4.97s
2025-08-15 02:57:54,505:INFO:New best model found at epoch 6400 with validation loss 4.059e-01. Saving...
2025-08-15 02:57:59,479:INFO:Epoch: 6450/10000 | Train Loss: 3.918e-01 | Dynamic Loss: 3.918e-01 | Regularization Loss: 1.422e-07 | Val Loss: 4.049e-01 | Time: 4.96s
2025-08-15 02:57:59,479:INFO:New best model found at epoch 6450 with validation loss 4.049e-01. Saving...
2025-08-15 02:58:04,481:INFO:Epoch: 6500/10000 | Train Loss: 3.913e-01 | Dynamic Loss: 3.913e-01 | Regularization Loss: 0.000e+00 | Val Loss: 4.044e-01 | Time: 4.99s
2025-08-15 02:58:04,481:INFO:New best model found at epoch 6500 with validation loss 4.044e-01. Saving...
2025-08-15 02:58:09,475:INFO:Epoch: 6550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.98s
2025-08-15 02:58:21,771:INFO:Epoch: 6600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 12.30s
2025-08-15 02:58:26,886:INFO:Epoch: 6650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.11s
2025-08-15 02:58:31,955:INFO:Epoch: 6700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.07s
2025-08-15 02:58:36,918:INFO:Epoch: 6750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.96s
2025-08-15 02:58:41,790:INFO:Epoch: 6800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.87s
2025-08-15 02:58:52,983:INFO:Epoch: 6850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 11.19s
2025-08-15 02:58:58,045:INFO:Epoch: 6900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.06s
2025-08-15 02:59:03,112:INFO:Epoch: 6950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.07s
2025-08-15 02:59:08,183:INFO:Epoch: 7000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.07s
2025-08-15 02:59:13,140:INFO:Epoch: 7050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.96s
2025-08-15 02:59:25,564:INFO:Epoch: 7100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 12.42s
2025-08-15 02:59:30,619:INFO:Epoch: 7150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.06s
2025-08-15 02:59:35,644:INFO:Epoch: 7200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.02s
2025-08-15 02:59:40,533:INFO:Epoch: 7250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.89s
2025-08-15 02:59:51,551:INFO:Epoch: 7300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 11.02s
2025-08-15 02:59:56,636:INFO:Epoch: 7350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.08s
2025-08-15 03:00:01,716:INFO:Epoch: 7400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.08s
2025-08-15 03:00:06,846:INFO:Epoch: 7450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.13s
2025-08-15 03:00:11,900:INFO:Epoch: 7500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.05s
2025-08-15 03:00:23,389:INFO:Epoch: 7550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 11.49s
2025-08-15 03:00:28,620:INFO:Epoch: 7600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.23s
2025-08-15 03:00:33,711:INFO:Epoch: 7650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.09s
2025-08-15 03:00:38,696:INFO:Epoch: 7700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.98s
2025-08-15 03:00:43,737:INFO:Epoch: 7750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.04s
2025-08-15 03:00:55,754:INFO:Epoch: 7800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 12.02s
2025-08-15 03:01:00,767:INFO:Epoch: 7850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.01s
2025-08-15 03:01:05,758:INFO:Epoch: 7900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.99s
2025-08-15 03:01:10,766:INFO:Epoch: 7950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.01s
2025-08-15 03:01:21,920:INFO:Epoch: 8000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 11.15s
2025-08-15 03:01:26,954:INFO:Epoch: 8050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.03s
2025-08-15 03:01:32,060:INFO:Epoch: 8100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.11s
2025-08-15 03:01:37,132:INFO:Epoch: 8150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.07s
2025-08-15 03:01:44,571:INFO:Epoch: 8200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 7.44s
2025-08-15 03:01:49,675:INFO:Epoch: 8250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.10s
2025-08-15 03:01:54,771:INFO:Epoch: 8300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.10s
2025-08-15 03:01:59,832:INFO:Epoch: 8350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.06s
2025-08-15 03:02:05,662:INFO:Epoch: 8400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.83s
2025-08-15 03:02:10,792:INFO:Epoch: 8450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.13s
2025-08-15 03:02:16,030:INFO:Epoch: 8500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.24s
2025-08-15 03:02:21,152:INFO:Epoch: 8550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.12s
2025-08-15 03:02:26,191:INFO:Epoch: 8600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.04s
2025-08-15 03:02:31,176:INFO:Epoch: 8650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.99s
2025-08-15 03:02:43,628:INFO:Epoch: 8700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 12.45s
2025-08-15 03:02:48,711:INFO:Epoch: 8750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.08s
2025-08-15 03:02:53,755:INFO:Epoch: 8800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.04s
2025-08-15 03:02:58,854:INFO:Epoch: 8850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.10s
2025-08-15 03:03:03,825:INFO:Epoch: 8900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.97s
2025-08-15 03:03:16,144:INFO:Epoch: 8950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 12.32s
2025-08-15 03:03:21,295:INFO:Epoch: 9000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.15s
2025-08-15 03:03:26,407:INFO:Epoch: 9050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.11s
2025-08-15 03:03:31,372:INFO:Epoch: 9100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.96s
2025-08-15 03:03:41,211:INFO:Epoch: 9150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 9.84s
2025-08-15 03:03:46,259:INFO:Epoch: 9200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.05s
2025-08-15 03:03:51,286:INFO:Epoch: 9250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.03s
2025-08-15 03:03:56,300:INFO:Epoch: 9300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.01s
2025-08-15 03:04:01,294:INFO:Epoch: 9350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.99s
2025-08-15 03:04:07,313:INFO:Epoch: 9400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 6.02s
2025-08-15 03:04:12,342:INFO:Epoch: 9450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.03s
2025-08-15 03:04:17,468:INFO:Epoch: 9500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.12s
2025-08-15 03:04:22,454:INFO:Epoch: 9550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.99s
2025-08-15 03:04:27,437:INFO:Epoch: 9600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.98s
2025-08-15 03:04:34,908:INFO:Epoch: 9650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 7.47s
2025-08-15 03:04:40,050:INFO:Epoch: 9700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.14s
2025-08-15 03:04:45,154:INFO:Epoch: 9750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.10s
2025-08-15 03:04:50,189:INFO:Epoch: 9800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.04s
2025-08-15 03:04:55,240:INFO:Epoch: 9850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.05s
2025-08-15 03:05:08,247:INFO:Epoch: 9900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 13.01s
2025-08-15 03:05:13,388:INFO:Epoch: 9950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.14s
2025-08-15 03:05:18,855:INFO:Epoch: 10000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.47s
