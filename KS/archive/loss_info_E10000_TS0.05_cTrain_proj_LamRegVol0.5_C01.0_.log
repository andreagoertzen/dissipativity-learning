2025-08-15 03:04:30,574:INFO:Created DataLoaders with 2994 training samples and 998 validation samples.
2025-08-15 03:04:31,210:INFO:model params: 479490
2025-08-15 03:04:31,958:INFO:Epoch: 0/10000 | Train Loss: 5.094e+00 | Dynamic Loss: 5.094e+00 | Regularization Loss: 3.098e-23 | Val Loss: 3.413e+00 | Time: 0.75s
2025-08-15 03:04:31,958:INFO:New best model found at epoch 0 with validation loss 3.413e+00. Saving...
2025-08-15 03:04:36,564:INFO:Epoch: 50/10000 | Train Loss: 9.023e-01 | Dynamic Loss: 9.023e-01 | Regularization Loss: 1.037e-19 | Val Loss: 9.511e-01 | Time: 4.53s
2025-08-15 03:04:36,564:INFO:New best model found at epoch 50 with validation loss 9.511e-01. Saving...
2025-08-15 03:04:41,043:INFO:Epoch: 100/10000 | Train Loss: 7.129e-01 | Dynamic Loss: 7.129e-01 | Regularization Loss: 9.458e-14 | Val Loss: 7.449e-01 | Time: 4.45s
2025-08-15 03:04:41,043:INFO:New best model found at epoch 100 with validation loss 7.449e-01. Saving...
2025-08-15 03:04:45,614:INFO:Epoch: 150/10000 | Train Loss: 6.419e-01 | Dynamic Loss: 6.419e-01 | Regularization Loss: 6.642e-07 | Val Loss: 6.647e-01 | Time: 4.56s
2025-08-15 03:04:45,614:INFO:New best model found at epoch 150 with validation loss 6.647e-01. Saving...
2025-08-15 03:04:50,126:INFO:Epoch: 200/10000 | Train Loss: 6.085e-01 | Dynamic Loss: 6.085e-01 | Regularization Loss: 6.308e-07 | Val Loss: 6.262e-01 | Time: 4.50s
2025-08-15 03:04:50,126:INFO:New best model found at epoch 200 with validation loss 6.262e-01. Saving...
2025-08-15 03:04:54,669:INFO:Epoch: 250/10000 | Train Loss: 5.900e-01 | Dynamic Loss: 5.900e-01 | Regularization Loss: 6.109e-07 | Val Loss: 6.007e-01 | Time: 4.53s
2025-08-15 03:04:54,669:INFO:New best model found at epoch 250 with validation loss 6.007e-01. Saving...
2025-08-15 03:05:04,512:INFO:Epoch: 300/10000 | Train Loss: 5.777e-01 | Dynamic Loss: 5.777e-01 | Regularization Loss: 5.902e-07 | Val Loss: 5.842e-01 | Time: 9.83s
2025-08-15 03:05:04,512:INFO:New best model found at epoch 300 with validation loss 5.842e-01. Saving...
2025-08-15 03:05:09,116:INFO:Epoch: 350/10000 | Train Loss: 5.711e-01 | Dynamic Loss: 5.711e-01 | Regularization Loss: 5.709e-07 | Val Loss: 5.749e-01 | Time: 4.59s
2025-08-15 03:05:09,116:INFO:New best model found at epoch 350 with validation loss 5.749e-01. Saving...
2025-08-15 03:05:13,703:INFO:Epoch: 400/10000 | Train Loss: 5.652e-01 | Dynamic Loss: 5.652e-01 | Regularization Loss: 5.542e-07 | Val Loss: 5.656e-01 | Time: 4.58s
2025-08-15 03:05:13,703:INFO:New best model found at epoch 400 with validation loss 5.656e-01. Saving...
2025-08-15 03:05:18,202:INFO:Epoch: 450/10000 | Train Loss: 5.582e-01 | Dynamic Loss: 5.582e-01 | Regularization Loss: 5.345e-07 | Val Loss: 5.572e-01 | Time: 4.49s
2025-08-15 03:05:18,202:INFO:New best model found at epoch 450 with validation loss 5.572e-01. Saving...
2025-08-15 03:05:28,423:INFO:Epoch: 500/10000 | Train Loss: 5.580e-01 | Dynamic Loss: 5.580e-01 | Regularization Loss: 5.196e-07 | Val Loss: 5.539e-01 | Time: 10.21s
2025-08-15 03:05:28,424:INFO:New best model found at epoch 500 with validation loss 5.539e-01. Saving...
2025-08-15 03:05:32,991:INFO:Epoch: 550/10000 | Train Loss: 5.535e-01 | Dynamic Loss: 5.535e-01 | Regularization Loss: 5.052e-07 | Val Loss: 5.487e-01 | Time: 4.56s
2025-08-15 03:05:32,991:INFO:New best model found at epoch 550 with validation loss 5.487e-01. Saving...
2025-08-15 03:05:37,589:INFO:Epoch: 600/10000 | Train Loss: 5.507e-01 | Dynamic Loss: 5.507e-01 | Regularization Loss: 4.889e-07 | Val Loss: 5.411e-01 | Time: 4.59s
2025-08-15 03:05:37,589:INFO:New best model found at epoch 600 with validation loss 5.411e-01. Saving...
2025-08-15 03:05:42,181:INFO:Epoch: 650/10000 | Train Loss: 5.443e-01 | Dynamic Loss: 5.443e-01 | Regularization Loss: 4.748e-07 | Val Loss: 5.372e-01 | Time: 4.58s
2025-08-15 03:05:42,181:INFO:New best model found at epoch 650 with validation loss 5.372e-01. Saving...
2025-08-15 03:05:46,930:INFO:Epoch: 700/10000 | Train Loss: 5.403e-01 | Dynamic Loss: 5.403e-01 | Regularization Loss: 4.591e-07 | Val Loss: 5.311e-01 | Time: 4.74s
2025-08-15 03:05:46,930:INFO:New best model found at epoch 700 with validation loss 5.311e-01. Saving...
2025-08-15 03:05:51,544:INFO:Epoch: 750/10000 | Train Loss: 5.340e-01 | Dynamic Loss: 5.340e-01 | Regularization Loss: 4.475e-07 | Val Loss: 5.264e-01 | Time: 4.60s
2025-08-15 03:05:51,544:INFO:New best model found at epoch 750 with validation loss 5.264e-01. Saving...
2025-08-15 03:05:56,164:INFO:Epoch: 800/10000 | Train Loss: 5.329e-01 | Dynamic Loss: 5.329e-01 | Regularization Loss: 4.356e-07 | Val Loss: 5.228e-01 | Time: 4.61s
2025-08-15 03:05:56,164:INFO:New best model found at epoch 800 with validation loss 5.228e-01. Saving...
2025-08-15 03:06:00,771:INFO:Epoch: 850/10000 | Train Loss: 5.295e-01 | Dynamic Loss: 5.295e-01 | Regularization Loss: 4.247e-07 | Val Loss: 5.218e-01 | Time: 4.60s
2025-08-15 03:06:00,771:INFO:New best model found at epoch 850 with validation loss 5.218e-01. Saving...
2025-08-15 03:06:06,137:INFO:Epoch: 900/10000 | Train Loss: 5.257e-01 | Dynamic Loss: 5.257e-01 | Regularization Loss: 4.141e-07 | Val Loss: 5.158e-01 | Time: 5.36s
2025-08-15 03:06:06,137:INFO:New best model found at epoch 900 with validation loss 5.158e-01. Saving...
2025-08-15 03:06:10,632:INFO:Epoch: 950/10000 | Train Loss: 5.226e-01 | Dynamic Loss: 5.226e-01 | Regularization Loss: 4.035e-07 | Val Loss: 5.128e-01 | Time: 4.49s
2025-08-15 03:06:10,632:INFO:New best model found at epoch 950 with validation loss 5.128e-01. Saving...
2025-08-15 03:06:15,366:INFO:Epoch: 1000/10000 | Train Loss: 5.210e-01 | Dynamic Loss: 5.210e-01 | Regularization Loss: 3.931e-07 | Val Loss: 5.096e-01 | Time: 4.72s
2025-08-15 03:06:15,366:INFO:New best model found at epoch 1000 with validation loss 5.096e-01. Saving...
2025-08-15 03:06:19,931:INFO:Epoch: 1050/10000 | Train Loss: 5.184e-01 | Dynamic Loss: 5.184e-01 | Regularization Loss: 3.835e-07 | Val Loss: 5.082e-01 | Time: 4.55s
2025-08-15 03:06:19,931:INFO:New best model found at epoch 1050 with validation loss 5.082e-01. Saving...
2025-08-15 03:06:24,516:INFO:Epoch: 1100/10000 | Train Loss: 5.163e-01 | Dynamic Loss: 5.163e-01 | Regularization Loss: 3.742e-07 | Val Loss: 5.042e-01 | Time: 4.58s
2025-08-15 03:06:24,516:INFO:New best model found at epoch 1100 with validation loss 5.042e-01. Saving...
2025-08-15 03:06:34,083:INFO:Epoch: 1150/10000 | Train Loss: 5.140e-01 | Dynamic Loss: 5.140e-01 | Regularization Loss: 3.662e-07 | Val Loss: 5.016e-01 | Time: 9.56s
2025-08-15 03:06:34,083:INFO:New best model found at epoch 1150 with validation loss 5.016e-01. Saving...
2025-08-15 03:06:38,637:INFO:Epoch: 1200/10000 | Train Loss: 5.119e-01 | Dynamic Loss: 5.119e-01 | Regularization Loss: 3.594e-07 | Val Loss: 5.009e-01 | Time: 4.54s
2025-08-15 03:06:38,637:INFO:New best model found at epoch 1200 with validation loss 5.009e-01. Saving...
2025-08-15 03:06:43,267:INFO:Epoch: 1250/10000 | Train Loss: 5.095e-01 | Dynamic Loss: 5.095e-01 | Regularization Loss: 3.531e-07 | Val Loss: 4.971e-01 | Time: 4.62s
2025-08-15 03:06:43,267:INFO:New best model found at epoch 1250 with validation loss 4.971e-01. Saving...
2025-08-15 03:06:47,817:INFO:Epoch: 1300/10000 | Train Loss: 5.072e-01 | Dynamic Loss: 5.072e-01 | Regularization Loss: 3.444e-07 | Val Loss: 4.947e-01 | Time: 4.54s
2025-08-15 03:06:47,817:INFO:New best model found at epoch 1300 with validation loss 4.947e-01. Saving...
2025-08-15 03:06:57,896:INFO:Epoch: 1350/10000 | Train Loss: 5.040e-01 | Dynamic Loss: 5.040e-01 | Regularization Loss: 3.386e-07 | Val Loss: 4.933e-01 | Time: 10.07s
2025-08-15 03:06:57,896:INFO:New best model found at epoch 1350 with validation loss 4.933e-01. Saving...
2025-08-15 03:07:02,565:INFO:Epoch: 1400/10000 | Train Loss: 5.019e-01 | Dynamic Loss: 5.019e-01 | Regularization Loss: 3.304e-07 | Val Loss: 4.909e-01 | Time: 4.66s
2025-08-15 03:07:02,565:INFO:New best model found at epoch 1400 with validation loss 4.909e-01. Saving...
2025-08-15 03:07:07,268:INFO:Epoch: 1450/10000 | Train Loss: 5.017e-01 | Dynamic Loss: 5.017e-01 | Regularization Loss: 3.256e-07 | Val Loss: 4.895e-01 | Time: 4.69s
2025-08-15 03:07:07,268:INFO:New best model found at epoch 1450 with validation loss 4.895e-01. Saving...
2025-08-15 03:07:11,931:INFO:Epoch: 1500/10000 | Train Loss: 4.983e-01 | Dynamic Loss: 4.983e-01 | Regularization Loss: 3.177e-07 | Val Loss: 4.871e-01 | Time: 4.65s
2025-08-15 03:07:11,931:INFO:New best model found at epoch 1500 with validation loss 4.871e-01. Saving...
2025-08-15 03:07:16,839:INFO:Epoch: 1550/10000 | Train Loss: 4.984e-01 | Dynamic Loss: 4.984e-01 | Regularization Loss: 3.165e-07 | Val Loss: 4.875e-01 | Time: 4.90s
2025-08-15 03:07:21,392:INFO:Epoch: 1600/10000 | Train Loss: 4.963e-01 | Dynamic Loss: 4.963e-01 | Regularization Loss: 3.088e-07 | Val Loss: 4.841e-01 | Time: 4.55s
2025-08-15 03:07:21,392:INFO:New best model found at epoch 1600 with validation loss 4.841e-01. Saving...
2025-08-15 03:07:26,051:INFO:Epoch: 1650/10000 | Train Loss: 4.930e-01 | Dynamic Loss: 4.930e-01 | Regularization Loss: 3.038e-07 | Val Loss: 4.836e-01 | Time: 4.65s
2025-08-15 03:07:26,051:INFO:New best model found at epoch 1650 with validation loss 4.836e-01. Saving...
2025-08-15 03:07:30,649:INFO:Epoch: 1700/10000 | Train Loss: 4.916e-01 | Dynamic Loss: 4.916e-01 | Regularization Loss: 2.977e-07 | Val Loss: 4.791e-01 | Time: 4.59s
2025-08-15 03:07:30,649:INFO:New best model found at epoch 1700 with validation loss 4.791e-01. Saving...
2025-08-15 03:07:38,191:INFO:Epoch: 1750/10000 | Train Loss: 4.903e-01 | Dynamic Loss: 4.903e-01 | Regularization Loss: 2.929e-07 | Val Loss: 4.781e-01 | Time: 7.53s
2025-08-15 03:07:38,191:INFO:New best model found at epoch 1750 with validation loss 4.781e-01. Saving...
2025-08-15 03:07:42,771:INFO:Epoch: 1800/10000 | Train Loss: 4.889e-01 | Dynamic Loss: 4.889e-01 | Regularization Loss: 2.891e-07 | Val Loss: 4.778e-01 | Time: 4.57s
2025-08-15 03:07:42,771:INFO:New best model found at epoch 1800 with validation loss 4.778e-01. Saving...
2025-08-15 03:07:47,358:INFO:Epoch: 1850/10000 | Train Loss: 4.882e-01 | Dynamic Loss: 4.882e-01 | Regularization Loss: 2.846e-07 | Val Loss: 4.770e-01 | Time: 4.58s
2025-08-15 03:07:47,358:INFO:New best model found at epoch 1850 with validation loss 4.770e-01. Saving...
2025-08-15 03:07:51,918:INFO:Epoch: 1900/10000 | Train Loss: 4.866e-01 | Dynamic Loss: 4.866e-01 | Regularization Loss: 2.800e-07 | Val Loss: 4.738e-01 | Time: 4.55s
2025-08-15 03:07:51,918:INFO:New best model found at epoch 1900 with validation loss 4.738e-01. Saving...
2025-08-15 03:07:56,429:INFO:Epoch: 1950/10000 | Train Loss: 4.829e-01 | Dynamic Loss: 4.829e-01 | Regularization Loss: 2.738e-07 | Val Loss: 4.721e-01 | Time: 4.50s
2025-08-15 03:07:56,429:INFO:New best model found at epoch 1950 with validation loss 4.721e-01. Saving...
2025-08-15 03:08:05,346:INFO:Epoch: 2000/10000 | Train Loss: 4.803e-01 | Dynamic Loss: 4.803e-01 | Regularization Loss: 2.702e-07 | Val Loss: 4.706e-01 | Time: 8.91s
2025-08-15 03:08:05,346:INFO:New best model found at epoch 2000 with validation loss 4.706e-01. Saving...
2025-08-15 03:08:09,933:INFO:Epoch: 2050/10000 | Train Loss: 4.808e-01 | Dynamic Loss: 4.808e-01 | Regularization Loss: 2.659e-07 | Val Loss: 4.714e-01 | Time: 4.58s
2025-08-15 03:08:14,500:INFO:Epoch: 2100/10000 | Train Loss: 4.759e-01 | Dynamic Loss: 4.759e-01 | Regularization Loss: 2.599e-07 | Val Loss: 4.686e-01 | Time: 4.57s
2025-08-15 03:08:14,500:INFO:New best model found at epoch 2100 with validation loss 4.686e-01. Saving...
2025-08-15 03:08:19,103:INFO:Epoch: 2150/10000 | Train Loss: 4.765e-01 | Dynamic Loss: 4.765e-01 | Regularization Loss: 2.546e-07 | Val Loss: 4.679e-01 | Time: 4.59s
2025-08-15 03:08:19,103:INFO:New best model found at epoch 2150 with validation loss 4.679e-01. Saving...
2025-08-15 03:08:27,434:INFO:Epoch: 2200/10000 | Train Loss: 4.726e-01 | Dynamic Loss: 4.726e-01 | Regularization Loss: 2.496e-07 | Val Loss: 4.668e-01 | Time: 8.32s
2025-08-15 03:08:27,434:INFO:New best model found at epoch 2200 with validation loss 4.668e-01. Saving...
2025-08-15 03:08:32,154:INFO:Epoch: 2250/10000 | Train Loss: 4.682e-01 | Dynamic Loss: 4.682e-01 | Regularization Loss: 2.437e-07 | Val Loss: 4.651e-01 | Time: 4.71s
2025-08-15 03:08:32,154:INFO:New best model found at epoch 2250 with validation loss 4.651e-01. Saving...
2025-08-15 03:08:36,804:INFO:Epoch: 2300/10000 | Train Loss: 4.676e-01 | Dynamic Loss: 4.676e-01 | Regularization Loss: 2.396e-07 | Val Loss: 4.618e-01 | Time: 4.64s
2025-08-15 03:08:36,804:INFO:New best model found at epoch 2300 with validation loss 4.618e-01. Saving...
2025-08-15 03:08:41,371:INFO:Epoch: 2350/10000 | Train Loss: 4.641e-01 | Dynamic Loss: 4.641e-01 | Regularization Loss: 2.346e-07 | Val Loss: 4.596e-01 | Time: 4.56s
2025-08-15 03:08:41,371:INFO:New best model found at epoch 2350 with validation loss 4.596e-01. Saving...
2025-08-15 03:08:46,003:INFO:Epoch: 2400/10000 | Train Loss: 4.645e-01 | Dynamic Loss: 4.645e-01 | Regularization Loss: 2.319e-07 | Val Loss: 4.603e-01 | Time: 4.62s
2025-08-15 03:08:50,580:INFO:Epoch: 2450/10000 | Train Loss: 4.637e-01 | Dynamic Loss: 4.637e-01 | Regularization Loss: 2.314e-07 | Val Loss: 4.608e-01 | Time: 4.58s
2025-08-15 03:08:55,323:INFO:Epoch: 2500/10000 | Train Loss: 4.607e-01 | Dynamic Loss: 4.607e-01 | Regularization Loss: 2.269e-07 | Val Loss: 4.568e-01 | Time: 4.74s
2025-08-15 03:08:55,323:INFO:New best model found at epoch 2500 with validation loss 4.568e-01. Saving...
2025-08-15 03:09:00,014:INFO:Epoch: 2550/10000 | Train Loss: 4.593e-01 | Dynamic Loss: 4.593e-01 | Regularization Loss: 2.245e-07 | Val Loss: 4.566e-01 | Time: 4.68s
2025-08-15 03:09:00,014:INFO:New best model found at epoch 2550 with validation loss 4.566e-01. Saving...
2025-08-15 03:09:04,542:INFO:Epoch: 2600/10000 | Train Loss: 4.589e-01 | Dynamic Loss: 4.589e-01 | Regularization Loss: 2.213e-07 | Val Loss: 4.548e-01 | Time: 4.52s
2025-08-15 03:09:04,542:INFO:New best model found at epoch 2600 with validation loss 4.548e-01. Saving...
2025-08-15 03:09:12,820:INFO:Epoch: 2650/10000 | Train Loss: 4.590e-01 | Dynamic Loss: 4.590e-01 | Regularization Loss: 2.197e-07 | Val Loss: 4.535e-01 | Time: 8.27s
2025-08-15 03:09:12,821:INFO:New best model found at epoch 2650 with validation loss 4.535e-01. Saving...
2025-08-15 03:09:17,480:INFO:Epoch: 2700/10000 | Train Loss: 4.579e-01 | Dynamic Loss: 4.579e-01 | Regularization Loss: 2.177e-07 | Val Loss: 4.544e-01 | Time: 4.65s
2025-08-15 03:09:22,155:INFO:Epoch: 2750/10000 | Train Loss: 4.557e-01 | Dynamic Loss: 4.557e-01 | Regularization Loss: 2.154e-07 | Val Loss: 4.523e-01 | Time: 4.67s
2025-08-15 03:09:22,155:INFO:New best model found at epoch 2750 with validation loss 4.523e-01. Saving...
2025-08-15 03:09:26,670:INFO:Epoch: 2800/10000 | Train Loss: 4.549e-01 | Dynamic Loss: 4.549e-01 | Regularization Loss: 2.146e-07 | Val Loss: 4.515e-01 | Time: 4.51s
2025-08-15 03:09:26,670:INFO:New best model found at epoch 2800 with validation loss 4.515e-01. Saving...
2025-08-15 03:09:31,401:INFO:Epoch: 2850/10000 | Train Loss: 4.543e-01 | Dynamic Loss: 4.543e-01 | Regularization Loss: 2.104e-07 | Val Loss: 4.508e-01 | Time: 4.72s
2025-08-15 03:09:31,401:INFO:New best model found at epoch 2850 with validation loss 4.508e-01. Saving...
2025-08-15 03:09:41,549:INFO:Epoch: 2900/10000 | Train Loss: 4.541e-01 | Dynamic Loss: 4.541e-01 | Regularization Loss: 2.096e-07 | Val Loss: 4.503e-01 | Time: 10.14s
2025-08-15 03:09:41,549:INFO:New best model found at epoch 2900 with validation loss 4.503e-01. Saving...
2025-08-15 03:09:46,211:INFO:Epoch: 2950/10000 | Train Loss: 4.536e-01 | Dynamic Loss: 4.536e-01 | Regularization Loss: 2.066e-07 | Val Loss: 4.491e-01 | Time: 4.65s
2025-08-15 03:09:46,211:INFO:New best model found at epoch 2950 with validation loss 4.491e-01. Saving...
2025-08-15 03:09:50,909:INFO:Epoch: 3000/10000 | Train Loss: 4.527e-01 | Dynamic Loss: 4.527e-01 | Regularization Loss: 2.033e-07 | Val Loss: 4.475e-01 | Time: 4.69s
2025-08-15 03:09:50,910:INFO:New best model found at epoch 3000 with validation loss 4.475e-01. Saving...
2025-08-15 03:09:55,501:INFO:Epoch: 3050/10000 | Train Loss: 4.500e-01 | Dynamic Loss: 4.500e-01 | Regularization Loss: 2.018e-07 | Val Loss: 4.466e-01 | Time: 4.58s
2025-08-15 03:09:55,501:INFO:New best model found at epoch 3050 with validation loss 4.466e-01. Saving...
2025-08-15 03:10:00,235:INFO:Epoch: 3100/10000 | Train Loss: 4.493e-01 | Dynamic Loss: 4.493e-01 | Regularization Loss: 1.994e-07 | Val Loss: 4.456e-01 | Time: 4.72s
2025-08-15 03:10:00,235:INFO:New best model found at epoch 3100 with validation loss 4.456e-01. Saving...
2025-08-15 03:10:04,954:INFO:Epoch: 3150/10000 | Train Loss: 4.490e-01 | Dynamic Loss: 4.490e-01 | Regularization Loss: 1.980e-07 | Val Loss: 4.450e-01 | Time: 4.71s
2025-08-15 03:10:04,954:INFO:New best model found at epoch 3150 with validation loss 4.450e-01. Saving...
2025-08-15 03:10:09,573:INFO:Epoch: 3200/10000 | Train Loss: 4.487e-01 | Dynamic Loss: 4.487e-01 | Regularization Loss: 1.964e-07 | Val Loss: 4.448e-01 | Time: 4.61s
2025-08-15 03:10:09,573:INFO:New best model found at epoch 3200 with validation loss 4.448e-01. Saving...
2025-08-15 03:10:14,144:INFO:Epoch: 3250/10000 | Train Loss: 4.463e-01 | Dynamic Loss: 4.463e-01 | Regularization Loss: 1.943e-07 | Val Loss: 4.436e-01 | Time: 4.56s
2025-08-15 03:10:14,144:INFO:New best model found at epoch 3250 with validation loss 4.436e-01. Saving...
2025-08-15 03:10:18,752:INFO:Epoch: 3300/10000 | Train Loss: 4.448e-01 | Dynamic Loss: 4.448e-01 | Regularization Loss: 1.924e-07 | Val Loss: 4.428e-01 | Time: 4.60s
2025-08-15 03:10:18,752:INFO:New best model found at epoch 3300 with validation loss 4.428e-01. Saving...
2025-08-15 03:10:28,928:INFO:Epoch: 3350/10000 | Train Loss: 4.441e-01 | Dynamic Loss: 4.441e-01 | Regularization Loss: 1.902e-07 | Val Loss: 4.422e-01 | Time: 10.17s
2025-08-15 03:10:28,928:INFO:New best model found at epoch 3350 with validation loss 4.422e-01. Saving...
2025-08-15 03:10:33,571:INFO:Epoch: 3400/10000 | Train Loss: 4.445e-01 | Dynamic Loss: 4.445e-01 | Regularization Loss: 1.894e-07 | Val Loss: 4.423e-01 | Time: 4.63s
2025-08-15 03:10:38,230:INFO:Epoch: 3450/10000 | Train Loss: 4.441e-01 | Dynamic Loss: 4.441e-01 | Regularization Loss: 1.872e-07 | Val Loss: 4.406e-01 | Time: 4.66s
2025-08-15 03:10:38,230:INFO:New best model found at epoch 3450 with validation loss 4.406e-01. Saving...
2025-08-15 03:10:42,833:INFO:Epoch: 3500/10000 | Train Loss: 4.437e-01 | Dynamic Loss: 4.437e-01 | Regularization Loss: 1.860e-07 | Val Loss: 4.404e-01 | Time: 4.59s
2025-08-15 03:10:42,833:INFO:New best model found at epoch 3500 with validation loss 4.404e-01. Saving...
2025-08-15 03:10:47,516:INFO:Epoch: 3550/10000 | Train Loss: 4.438e-01 | Dynamic Loss: 4.438e-01 | Regularization Loss: 1.859e-07 | Val Loss: 4.409e-01 | Time: 4.67s
2025-08-15 03:10:52,310:INFO:Epoch: 3600/10000 | Train Loss: 4.420e-01 | Dynamic Loss: 4.420e-01 | Regularization Loss: 1.841e-07 | Val Loss: 4.391e-01 | Time: 4.79s
2025-08-15 03:10:52,310:INFO:New best model found at epoch 3600 with validation loss 4.391e-01. Saving...
2025-08-15 03:10:57,162:INFO:Epoch: 3650/10000 | Train Loss: 4.410e-01 | Dynamic Loss: 4.410e-01 | Regularization Loss: 1.821e-07 | Val Loss: 4.389e-01 | Time: 4.84s
2025-08-15 03:10:57,162:INFO:New best model found at epoch 3650 with validation loss 4.389e-01. Saving...
2025-08-15 03:11:01,983:INFO:Epoch: 3700/10000 | Train Loss: 4.402e-01 | Dynamic Loss: 4.402e-01 | Regularization Loss: 1.812e-07 | Val Loss: 4.400e-01 | Time: 4.81s
2025-08-15 03:11:06,622:INFO:Epoch: 3750/10000 | Train Loss: 4.393e-01 | Dynamic Loss: 4.393e-01 | Regularization Loss: 1.797e-07 | Val Loss: 4.388e-01 | Time: 4.64s
2025-08-15 03:11:06,622:INFO:New best model found at epoch 3750 with validation loss 4.388e-01. Saving...
2025-08-15 03:11:15,377:INFO:Epoch: 3800/10000 | Train Loss: 4.390e-01 | Dynamic Loss: 4.390e-01 | Regularization Loss: 1.783e-07 | Val Loss: 4.379e-01 | Time: 8.75s
2025-08-15 03:11:15,377:INFO:New best model found at epoch 3800 with validation loss 4.379e-01. Saving...
2025-08-15 03:11:20,100:INFO:Epoch: 3850/10000 | Train Loss: 4.404e-01 | Dynamic Loss: 4.404e-01 | Regularization Loss: 1.772e-07 | Val Loss: 4.417e-01 | Time: 4.71s
2025-08-15 03:11:24,816:INFO:Epoch: 3900/10000 | Train Loss: 4.381e-01 | Dynamic Loss: 4.381e-01 | Regularization Loss: 1.754e-07 | Val Loss: 4.380e-01 | Time: 4.72s
2025-08-15 03:11:29,477:INFO:Epoch: 3950/10000 | Train Loss: 4.363e-01 | Dynamic Loss: 4.363e-01 | Regularization Loss: 1.738e-07 | Val Loss: 4.363e-01 | Time: 4.66s
2025-08-15 03:11:29,477:INFO:New best model found at epoch 3950 with validation loss 4.363e-01. Saving...
2025-08-15 03:11:34,056:INFO:Epoch: 4000/10000 | Train Loss: 4.360e-01 | Dynamic Loss: 4.360e-01 | Regularization Loss: 1.721e-07 | Val Loss: 4.362e-01 | Time: 4.57s
2025-08-15 03:11:34,056:INFO:New best model found at epoch 4000 with validation loss 4.362e-01. Saving...
2025-08-15 03:11:43,799:INFO:Epoch: 4050/10000 | Train Loss: 4.353e-01 | Dynamic Loss: 4.353e-01 | Regularization Loss: 1.713e-07 | Val Loss: 4.349e-01 | Time: 9.73s
2025-08-15 03:11:43,799:INFO:New best model found at epoch 4050 with validation loss 4.349e-01. Saving...
2025-08-15 03:11:48,453:INFO:Epoch: 4100/10000 | Train Loss: 4.342e-01 | Dynamic Loss: 4.342e-01 | Regularization Loss: 1.693e-07 | Val Loss: 4.338e-01 | Time: 4.65s
2025-08-15 03:11:48,453:INFO:New best model found at epoch 4100 with validation loss 4.338e-01. Saving...
2025-08-15 03:11:53,120:INFO:Epoch: 4150/10000 | Train Loss: 4.316e-01 | Dynamic Loss: 4.316e-01 | Regularization Loss: 1.675e-07 | Val Loss: 4.337e-01 | Time: 4.66s
2025-08-15 03:11:53,120:INFO:New best model found at epoch 4150 with validation loss 4.337e-01. Saving...
2025-08-15 03:11:57,756:INFO:Epoch: 4200/10000 | Train Loss: 4.330e-01 | Dynamic Loss: 4.330e-01 | Regularization Loss: 1.652e-07 | Val Loss: 4.316e-01 | Time: 4.63s
2025-08-15 03:11:57,756:INFO:New best model found at epoch 4200 with validation loss 4.316e-01. Saving...
2025-08-15 03:12:02,328:INFO:Epoch: 4250/10000 | Train Loss: 4.287e-01 | Dynamic Loss: 4.287e-01 | Regularization Loss: 1.632e-07 | Val Loss: 4.325e-01 | Time: 4.56s
2025-08-15 03:12:12,478:INFO:Epoch: 4300/10000 | Train Loss: 4.280e-01 | Dynamic Loss: 4.280e-01 | Regularization Loss: 1.610e-07 | Val Loss: 4.309e-01 | Time: 10.15s
2025-08-15 03:12:12,478:INFO:New best model found at epoch 4300 with validation loss 4.309e-01. Saving...
2025-08-15 03:12:17,255:INFO:Epoch: 4350/10000 | Train Loss: 4.269e-01 | Dynamic Loss: 4.269e-01 | Regularization Loss: 1.605e-07 | Val Loss: 4.320e-01 | Time: 4.77s
2025-08-15 03:12:22,006:INFO:Epoch: 4400/10000 | Train Loss: 4.278e-01 | Dynamic Loss: 4.278e-01 | Regularization Loss: 1.592e-07 | Val Loss: 4.308e-01 | Time: 4.75s
2025-08-15 03:12:22,006:INFO:New best model found at epoch 4400 with validation loss 4.308e-01. Saving...
2025-08-15 03:12:26,673:INFO:Epoch: 4450/10000 | Train Loss: 4.264e-01 | Dynamic Loss: 4.264e-01 | Regularization Loss: 1.577e-07 | Val Loss: 4.301e-01 | Time: 4.66s
2025-08-15 03:12:26,673:INFO:New best model found at epoch 4450 with validation loss 4.301e-01. Saving...
2025-08-15 03:12:31,382:INFO:Epoch: 4500/10000 | Train Loss: 4.223e-01 | Dynamic Loss: 4.223e-01 | Regularization Loss: 1.552e-07 | Val Loss: 4.255e-01 | Time: 4.70s
2025-08-15 03:12:31,382:INFO:New best model found at epoch 4500 with validation loss 4.255e-01. Saving...
2025-08-15 03:12:39,174:INFO:Epoch: 4550/10000 | Train Loss: 4.215e-01 | Dynamic Loss: 4.215e-01 | Regularization Loss: 1.532e-07 | Val Loss: 4.248e-01 | Time: 7.78s
2025-08-15 03:12:39,174:INFO:New best model found at epoch 4550 with validation loss 4.248e-01. Saving...
2025-08-15 03:12:43,875:INFO:Epoch: 4600/10000 | Train Loss: 4.191e-01 | Dynamic Loss: 4.191e-01 | Regularization Loss: 1.517e-07 | Val Loss: 4.247e-01 | Time: 4.69s
2025-08-15 03:12:43,875:INFO:New best model found at epoch 4600 with validation loss 4.247e-01. Saving...
2025-08-15 03:12:48,520:INFO:Epoch: 4650/10000 | Train Loss: 4.188e-01 | Dynamic Loss: 4.188e-01 | Regularization Loss: 1.508e-07 | Val Loss: 4.240e-01 | Time: 4.64s
2025-08-15 03:12:48,520:INFO:New best model found at epoch 4650 with validation loss 4.240e-01. Saving...
2025-08-15 03:12:53,140:INFO:Epoch: 4700/10000 | Train Loss: 4.176e-01 | Dynamic Loss: 4.176e-01 | Regularization Loss: 1.502e-07 | Val Loss: 4.241e-01 | Time: 4.61s
2025-08-15 03:12:57,772:INFO:Epoch: 4750/10000 | Train Loss: 4.173e-01 | Dynamic Loss: 4.173e-01 | Regularization Loss: 1.484e-07 | Val Loss: 4.231e-01 | Time: 4.63s
2025-08-15 03:12:57,772:INFO:New best model found at epoch 4750 with validation loss 4.231e-01. Saving...
2025-08-15 03:13:05,546:INFO:Epoch: 4800/10000 | Train Loss: 4.174e-01 | Dynamic Loss: 4.174e-01 | Regularization Loss: 1.473e-07 | Val Loss: 4.229e-01 | Time: 7.76s
2025-08-15 03:13:05,546:INFO:New best model found at epoch 4800 with validation loss 4.229e-01. Saving...
2025-08-15 03:13:10,236:INFO:Epoch: 4850/10000 | Train Loss: 4.139e-01 | Dynamic Loss: 4.139e-01 | Regularization Loss: 1.448e-07 | Val Loss: 4.223e-01 | Time: 4.68s
2025-08-15 03:13:10,236:INFO:New best model found at epoch 4850 with validation loss 4.223e-01. Saving...
2025-08-15 03:13:15,040:INFO:Epoch: 4900/10000 | Train Loss: 4.125e-01 | Dynamic Loss: 4.125e-01 | Regularization Loss: 1.434e-07 | Val Loss: 4.217e-01 | Time: 4.79s
2025-08-15 03:13:15,040:INFO:New best model found at epoch 4900 with validation loss 4.217e-01. Saving...
2025-08-15 03:13:19,721:INFO:Epoch: 4950/10000 | Train Loss: 4.134e-01 | Dynamic Loss: 4.134e-01 | Regularization Loss: 1.405e-07 | Val Loss: 4.219e-01 | Time: 4.67s
2025-08-15 03:13:24,418:INFO:Epoch: 5000/10000 | Train Loss: 4.132e-01 | Dynamic Loss: 4.132e-01 | Regularization Loss: 1.402e-07 | Val Loss: 4.205e-01 | Time: 4.70s
2025-08-15 03:13:24,418:INFO:New best model found at epoch 5000 with validation loss 4.205e-01. Saving...
2025-08-15 03:13:35,244:INFO:Epoch: 5050/10000 | Train Loss: 4.099e-01 | Dynamic Loss: 4.099e-01 | Regularization Loss: 1.388e-07 | Val Loss: 4.183e-01 | Time: 10.82s
2025-08-15 03:13:35,244:INFO:New best model found at epoch 5050 with validation loss 4.183e-01. Saving...
2025-08-15 03:13:39,928:INFO:Epoch: 5100/10000 | Train Loss: 4.074e-01 | Dynamic Loss: 4.074e-01 | Regularization Loss: 1.371e-07 | Val Loss: 4.172e-01 | Time: 4.67s
2025-08-15 03:13:39,928:INFO:New best model found at epoch 5100 with validation loss 4.172e-01. Saving...
2025-08-15 03:13:44,567:INFO:Epoch: 5150/10000 | Train Loss: 4.081e-01 | Dynamic Loss: 4.081e-01 | Regularization Loss: 1.344e-07 | Val Loss: 4.161e-01 | Time: 4.63s
2025-08-15 03:13:44,567:INFO:New best model found at epoch 5150 with validation loss 4.161e-01. Saving...
2025-08-15 03:13:49,243:INFO:Epoch: 5200/10000 | Train Loss: 4.045e-01 | Dynamic Loss: 4.045e-01 | Regularization Loss: 1.330e-07 | Val Loss: 4.149e-01 | Time: 4.67s
2025-08-15 03:13:49,243:INFO:New best model found at epoch 5200 with validation loss 4.149e-01. Saving...
2025-08-15 03:13:56,607:INFO:Epoch: 5250/10000 | Train Loss: 4.057e-01 | Dynamic Loss: 4.057e-01 | Regularization Loss: 1.313e-07 | Val Loss: 4.139e-01 | Time: 7.35s
2025-08-15 03:13:56,608:INFO:New best model found at epoch 5250 with validation loss 4.139e-01. Saving...
2025-08-15 03:14:01,317:INFO:Epoch: 5300/10000 | Train Loss: 4.045e-01 | Dynamic Loss: 4.045e-01 | Regularization Loss: 1.310e-07 | Val Loss: 4.132e-01 | Time: 4.70s
2025-08-15 03:14:01,317:INFO:New best model found at epoch 5300 with validation loss 4.132e-01. Saving...
2025-08-15 03:14:06,276:INFO:Epoch: 5350/10000 | Train Loss: 4.025e-01 | Dynamic Loss: 4.025e-01 | Regularization Loss: 1.291e-07 | Val Loss: 4.123e-01 | Time: 4.95s
2025-08-15 03:14:06,277:INFO:New best model found at epoch 5350 with validation loss 4.123e-01. Saving...
2025-08-15 03:14:10,965:INFO:Epoch: 5400/10000 | Train Loss: 4.023e-01 | Dynamic Loss: 4.023e-01 | Regularization Loss: 1.292e-07 | Val Loss: 4.127e-01 | Time: 4.68s
2025-08-15 03:14:15,635:INFO:Epoch: 5450/10000 | Train Loss: 4.015e-01 | Dynamic Loss: 4.015e-01 | Regularization Loss: 1.284e-07 | Val Loss: 4.109e-01 | Time: 4.67s
2025-08-15 03:14:15,636:INFO:New best model found at epoch 5450 with validation loss 4.109e-01. Saving...
2025-08-15 03:14:22,364:INFO:Epoch: 5500/10000 | Train Loss: 4.007e-01 | Dynamic Loss: 4.007e-01 | Regularization Loss: 1.275e-07 | Val Loss: 4.102e-01 | Time: 6.72s
2025-08-15 03:14:22,364:INFO:New best model found at epoch 5500 with validation loss 4.102e-01. Saving...
2025-08-15 03:14:27,127:INFO:Epoch: 5550/10000 | Train Loss: 3.998e-01 | Dynamic Loss: 3.998e-01 | Regularization Loss: 1.252e-07 | Val Loss: 4.094e-01 | Time: 4.75s
2025-08-15 03:14:27,127:INFO:New best model found at epoch 5550 with validation loss 4.094e-01. Saving...
2025-08-15 03:14:31,903:INFO:Epoch: 5600/10000 | Train Loss: 4.002e-01 | Dynamic Loss: 4.002e-01 | Regularization Loss: 1.247e-07 | Val Loss: 4.085e-01 | Time: 4.77s
2025-08-15 03:14:31,903:INFO:New best model found at epoch 5600 with validation loss 4.085e-01. Saving...
2025-08-15 03:14:36,586:INFO:Epoch: 5650/10000 | Train Loss: 3.976e-01 | Dynamic Loss: 3.976e-01 | Regularization Loss: 1.261e-07 | Val Loss: 4.080e-01 | Time: 4.67s
2025-08-15 03:14:36,586:INFO:New best model found at epoch 5650 with validation loss 4.080e-01. Saving...
2025-08-15 03:14:41,265:INFO:Epoch: 5700/10000 | Train Loss: 3.982e-01 | Dynamic Loss: 3.982e-01 | Regularization Loss: 1.242e-07 | Val Loss: 4.075e-01 | Time: 4.67s
2025-08-15 03:14:41,265:INFO:New best model found at epoch 5700 with validation loss 4.075e-01. Saving...
2025-08-15 03:14:51,614:INFO:Epoch: 5750/10000 | Train Loss: 3.969e-01 | Dynamic Loss: 3.969e-01 | Regularization Loss: 1.213e-07 | Val Loss: 4.070e-01 | Time: 10.34s
2025-08-15 03:14:51,614:INFO:New best model found at epoch 5750 with validation loss 4.070e-01. Saving...
2025-08-15 03:14:56,382:INFO:Epoch: 5800/10000 | Train Loss: 3.964e-01 | Dynamic Loss: 3.964e-01 | Regularization Loss: 1.222e-07 | Val Loss: 4.060e-01 | Time: 4.76s
2025-08-15 03:14:56,382:INFO:New best model found at epoch 5800 with validation loss 4.060e-01. Saving...
2025-08-15 03:15:01,063:INFO:Epoch: 5850/10000 | Train Loss: 3.956e-01 | Dynamic Loss: 3.956e-01 | Regularization Loss: 1.220e-07 | Val Loss: 4.056e-01 | Time: 4.67s
2025-08-15 03:15:01,063:INFO:New best model found at epoch 5850 with validation loss 4.056e-01. Saving...
2025-08-15 03:15:05,742:INFO:Epoch: 5900/10000 | Train Loss: 3.943e-01 | Dynamic Loss: 3.943e-01 | Regularization Loss: 1.193e-07 | Val Loss: 4.046e-01 | Time: 4.67s
2025-08-15 03:15:05,742:INFO:New best model found at epoch 5900 with validation loss 4.046e-01. Saving...
2025-08-15 03:15:10,418:INFO:Epoch: 5950/10000 | Train Loss: 3.956e-01 | Dynamic Loss: 3.956e-01 | Regularization Loss: 1.188e-07 | Val Loss: 4.062e-01 | Time: 4.67s
2025-08-15 03:15:21,328:INFO:Epoch: 6000/10000 | Train Loss: 3.935e-01 | Dynamic Loss: 3.935e-01 | Regularization Loss: 1.171e-07 | Val Loss: 4.039e-01 | Time: 10.91s
2025-08-15 03:15:21,328:INFO:New best model found at epoch 6000 with validation loss 4.039e-01. Saving...
2025-08-15 03:15:26,123:INFO:Epoch: 6050/10000 | Train Loss: 3.934e-01 | Dynamic Loss: 3.934e-01 | Regularization Loss: 1.171e-07 | Val Loss: 4.050e-01 | Time: 4.79s
2025-08-15 03:15:30,846:INFO:Epoch: 6100/10000 | Train Loss: 3.902e-01 | Dynamic Loss: 3.902e-01 | Regularization Loss: 1.161e-07 | Val Loss: 4.029e-01 | Time: 4.72s
2025-08-15 03:15:30,847:INFO:New best model found at epoch 6100 with validation loss 4.029e-01. Saving...
2025-08-15 03:15:35,604:INFO:Epoch: 6150/10000 | Train Loss: 3.910e-01 | Dynamic Loss: 3.910e-01 | Regularization Loss: 1.141e-07 | Val Loss: 4.029e-01 | Time: 4.75s
2025-08-15 03:15:35,604:INFO:New best model found at epoch 6150 with validation loss 4.029e-01. Saving...
2025-08-15 03:15:40,440:INFO:Epoch: 6200/10000 | Train Loss: 3.895e-01 | Dynamic Loss: 3.895e-01 | Regularization Loss: 1.122e-07 | Val Loss: 4.033e-01 | Time: 4.83s
2025-08-15 03:15:45,224:INFO:Epoch: 6250/10000 | Train Loss: 3.869e-01 | Dynamic Loss: 3.869e-01 | Regularization Loss: 1.102e-07 | Val Loss: 4.019e-01 | Time: 4.78s
2025-08-15 03:15:45,224:INFO:New best model found at epoch 6250 with validation loss 4.019e-01. Saving...
2025-08-15 03:15:49,994:INFO:Epoch: 6300/10000 | Train Loss: 3.870e-01 | Dynamic Loss: 3.870e-01 | Regularization Loss: 1.095e-07 | Val Loss: 4.017e-01 | Time: 4.76s
2025-08-15 03:15:49,994:INFO:New best model found at epoch 6300 with validation loss 4.017e-01. Saving...
2025-08-15 03:15:54,764:INFO:Epoch: 6350/10000 | Train Loss: 3.866e-01 | Dynamic Loss: 3.866e-01 | Regularization Loss: 1.090e-07 | Val Loss: 4.009e-01 | Time: 4.76s
2025-08-15 03:15:54,764:INFO:New best model found at epoch 6350 with validation loss 4.009e-01. Saving...
2025-08-15 03:15:59,495:INFO:Epoch: 6400/10000 | Train Loss: 3.830e-01 | Dynamic Loss: 3.830e-01 | Regularization Loss: 1.066e-07 | Val Loss: 3.992e-01 | Time: 4.72s
2025-08-15 03:15:59,495:INFO:New best model found at epoch 6400 with validation loss 3.992e-01. Saving...
2025-08-15 03:16:07,698:INFO:Epoch: 6450/10000 | Train Loss: 3.822e-01 | Dynamic Loss: 3.822e-01 | Regularization Loss: 1.058e-07 | Val Loss: 3.993e-01 | Time: 8.19s
2025-08-15 03:16:12,397:INFO:Epoch: 6500/10000 | Train Loss: 3.794e-01 | Dynamic Loss: 3.794e-01 | Regularization Loss: 1.032e-07 | Val Loss: 3.974e-01 | Time: 4.70s
2025-08-15 03:16:12,397:INFO:New best model found at epoch 6500 with validation loss 3.974e-01. Saving...
2025-08-15 03:16:17,151:INFO:Epoch: 6550/10000 | Train Loss: 3.768e-01 | Dynamic Loss: 3.768e-01 | Regularization Loss: 1.023e-07 | Val Loss: 3.961e-01 | Time: 4.74s
2025-08-15 03:16:17,151:INFO:New best model found at epoch 6550 with validation loss 3.961e-01. Saving...
2025-08-15 03:16:21,873:INFO:Epoch: 6600/10000 | Train Loss: 3.773e-01 | Dynamic Loss: 3.773e-01 | Regularization Loss: 9.918e-08 | Val Loss: 3.952e-01 | Time: 4.71s
2025-08-15 03:16:21,874:INFO:New best model found at epoch 6600 with validation loss 3.952e-01. Saving...
2025-08-15 03:16:26,592:INFO:Epoch: 6650/10000 | Train Loss: 3.745e-01 | Dynamic Loss: 3.745e-01 | Regularization Loss: 9.005e-08 | Val Loss: 3.939e-01 | Time: 4.71s
2025-08-15 03:16:26,592:INFO:New best model found at epoch 6650 with validation loss 3.939e-01. Saving...
2025-08-15 03:16:34,581:INFO:Epoch: 6700/10000 | Train Loss: 3.745e-01 | Dynamic Loss: 3.745e-01 | Regularization Loss: 1.003e-07 | Val Loss: 3.928e-01 | Time: 7.98s
2025-08-15 03:16:34,581:INFO:New best model found at epoch 6700 with validation loss 3.928e-01. Saving...
2025-08-15 03:16:39,255:INFO:Epoch: 6750/10000 | Train Loss: 3.743e-01 | Dynamic Loss: 3.743e-01 | Regularization Loss: 8.308e-08 | Val Loss: 3.930e-01 | Time: 4.66s
2025-08-15 03:16:43,948:INFO:Epoch: 6800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.69s
2025-08-15 03:16:48,740:INFO:Epoch: 6850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.79s
2025-08-15 03:16:53,506:INFO:Epoch: 6900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.77s
2025-08-15 03:17:04,861:INFO:Epoch: 6950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 11.36s
2025-08-15 03:17:09,623:INFO:Epoch: 7000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.76s
2025-08-15 03:17:14,470:INFO:Epoch: 7050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.85s
2025-08-15 03:17:19,129:INFO:Epoch: 7100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.66s
2025-08-15 03:17:27,199:INFO:Epoch: 7150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 8.07s
2025-08-15 03:17:31,955:INFO:Epoch: 7200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.76s
2025-08-15 03:17:36,655:INFO:Epoch: 7250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.70s
2025-08-15 03:17:41,542:INFO:Epoch: 7300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.89s
2025-08-15 03:17:46,293:INFO:Epoch: 7350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.75s
2025-08-15 03:17:55,863:INFO:Epoch: 7400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 9.57s
2025-08-15 03:18:00,625:INFO:Epoch: 7450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.76s
2025-08-15 03:18:05,350:INFO:Epoch: 7500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.72s
2025-08-15 03:18:10,036:INFO:Epoch: 7550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.69s
2025-08-15 03:18:14,723:INFO:Epoch: 7600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.69s
2025-08-15 03:18:21,538:INFO:Epoch: 7650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 6.81s
2025-08-15 03:18:26,280:INFO:Epoch: 7700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.74s
2025-08-15 03:18:31,043:INFO:Epoch: 7750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.76s
2025-08-15 03:18:35,742:INFO:Epoch: 7800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.70s
2025-08-15 03:18:40,435:INFO:Epoch: 7850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.69s
2025-08-15 03:18:47,637:INFO:Epoch: 7900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 7.20s
2025-08-15 03:18:52,376:INFO:Epoch: 7950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.74s
2025-08-15 03:18:57,134:INFO:Epoch: 8000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.76s
2025-08-15 03:19:01,842:INFO:Epoch: 8050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.71s
2025-08-15 03:19:06,537:INFO:Epoch: 8100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.69s
2025-08-15 03:19:16,607:INFO:Epoch: 8150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 10.07s
2025-08-15 03:19:21,360:INFO:Epoch: 8200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.75s
2025-08-15 03:19:26,143:INFO:Epoch: 8250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.78s
2025-08-15 03:19:30,816:INFO:Epoch: 8300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.67s
2025-08-15 03:19:35,524:INFO:Epoch: 8350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.71s
2025-08-15 03:19:42,395:INFO:Epoch: 8400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 6.87s
2025-08-15 03:19:47,133:INFO:Epoch: 8450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.74s
2025-08-15 03:19:51,862:INFO:Epoch: 8500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.73s
2025-08-15 03:19:56,589:INFO:Epoch: 8550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.73s
2025-08-15 03:20:01,308:INFO:Epoch: 8600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.72s
2025-08-15 03:20:08,800:INFO:Epoch: 8650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 7.49s
2025-08-15 03:20:13,566:INFO:Epoch: 8700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.77s
2025-08-15 03:20:18,312:INFO:Epoch: 8750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.75s
2025-08-15 03:20:23,101:INFO:Epoch: 8800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.79s
2025-08-15 03:20:27,857:INFO:Epoch: 8850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.76s
2025-08-15 03:20:34,650:INFO:Epoch: 8900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 6.79s
2025-08-15 03:20:39,531:INFO:Epoch: 8950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.88s
2025-08-15 03:20:44,202:INFO:Epoch: 9000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.67s
2025-08-15 03:20:49,020:INFO:Epoch: 9050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.82s
2025-08-15 03:20:53,962:INFO:Epoch: 9100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.94s
2025-08-15 03:21:02,055:INFO:Epoch: 9150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 8.09s
2025-08-15 03:21:06,776:INFO:Epoch: 9200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.72s
2025-08-15 03:21:11,452:INFO:Epoch: 9250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.68s
2025-08-15 03:21:16,179:INFO:Epoch: 9300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.73s
2025-08-15 03:21:21,048:INFO:Epoch: 9350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.87s
2025-08-15 03:21:28,981:INFO:Epoch: 9400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 7.93s
2025-08-15 03:21:33,731:INFO:Epoch: 9450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.75s
2025-08-15 03:21:38,527:INFO:Epoch: 9500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.80s
2025-08-15 03:21:43,327:INFO:Epoch: 9550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.80s
2025-08-15 03:21:48,054:INFO:Epoch: 9600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.73s
2025-08-15 03:21:58,800:INFO:Epoch: 9650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 10.75s
2025-08-15 03:22:03,625:INFO:Epoch: 9700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.82s
2025-08-15 03:22:08,428:INFO:Epoch: 9750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.80s
2025-08-15 03:22:13,170:INFO:Epoch: 9800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.74s
2025-08-15 03:22:17,886:INFO:Epoch: 9850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.72s
2025-08-15 03:22:28,204:INFO:Epoch: 9900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 10.32s
2025-08-15 03:22:32,923:INFO:Epoch: 9950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.72s
2025-08-15 03:22:38,006:INFO:Epoch: 10000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.08s
