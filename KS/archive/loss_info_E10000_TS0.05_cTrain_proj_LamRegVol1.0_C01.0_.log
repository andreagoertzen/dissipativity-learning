2025-08-15 03:04:30,494:INFO:Created DataLoaders with 2994 training samples and 998 validation samples.
2025-08-15 03:04:31,083:INFO:model params: 479490
2025-08-15 03:04:31,839:INFO:Epoch: 0/10000 | Train Loss: 5.094e+00 | Dynamic Loss: 5.094e+00 | Regularization Loss: 6.195e-23 | Val Loss: 3.413e+00 | Time: 0.76s
2025-08-15 03:04:31,839:INFO:New best model found at epoch 0 with validation loss 3.413e+00. Saving...
2025-08-15 03:04:36,565:INFO:Epoch: 50/10000 | Train Loss: 9.023e-01 | Dynamic Loss: 9.023e-01 | Regularization Loss: 2.074e-19 | Val Loss: 9.511e-01 | Time: 4.67s
2025-08-15 03:04:36,566:INFO:New best model found at epoch 50 with validation loss 9.511e-01. Saving...
2025-08-15 03:04:41,091:INFO:Epoch: 100/10000 | Train Loss: 7.129e-01 | Dynamic Loss: 7.129e-01 | Regularization Loss: 1.892e-13 | Val Loss: 7.449e-01 | Time: 4.51s
2025-08-15 03:04:41,091:INFO:New best model found at epoch 100 with validation loss 7.449e-01. Saving...
2025-08-15 03:04:45,736:INFO:Epoch: 150/10000 | Train Loss: 6.436e-01 | Dynamic Loss: 6.436e-01 | Regularization Loss: 8.614e-07 | Val Loss: 6.642e-01 | Time: 4.63s
2025-08-15 03:04:45,736:INFO:New best model found at epoch 150 with validation loss 6.642e-01. Saving...
2025-08-15 03:04:50,254:INFO:Epoch: 200/10000 | Train Loss: 6.073e-01 | Dynamic Loss: 6.073e-01 | Regularization Loss: 6.270e-07 | Val Loss: 6.274e-01 | Time: 4.51s
2025-08-15 03:04:50,255:INFO:New best model found at epoch 200 with validation loss 6.274e-01. Saving...
2025-08-15 03:04:54,822:INFO:Epoch: 250/10000 | Train Loss: 5.892e-01 | Dynamic Loss: 5.892e-01 | Regularization Loss: 6.087e-07 | Val Loss: 6.030e-01 | Time: 4.56s
2025-08-15 03:04:54,822:INFO:New best model found at epoch 250 with validation loss 6.030e-01. Saving...
2025-08-15 03:05:04,590:INFO:Epoch: 300/10000 | Train Loss: 5.770e-01 | Dynamic Loss: 5.770e-01 | Regularization Loss: 5.891e-07 | Val Loss: 5.845e-01 | Time: 9.76s
2025-08-15 03:05:04,590:INFO:New best model found at epoch 300 with validation loss 5.845e-01. Saving...
2025-08-15 03:05:09,224:INFO:Epoch: 350/10000 | Train Loss: 5.720e-01 | Dynamic Loss: 5.720e-01 | Regularization Loss: 5.699e-07 | Val Loss: 5.730e-01 | Time: 4.62s
2025-08-15 03:05:09,224:INFO:New best model found at epoch 350 with validation loss 5.730e-01. Saving...
2025-08-15 03:05:13,819:INFO:Epoch: 400/10000 | Train Loss: 5.659e-01 | Dynamic Loss: 5.659e-01 | Regularization Loss: 5.512e-07 | Val Loss: 5.649e-01 | Time: 4.59s
2025-08-15 03:05:13,819:INFO:New best model found at epoch 400 with validation loss 5.649e-01. Saving...
2025-08-15 03:05:18,382:INFO:Epoch: 450/10000 | Train Loss: 5.604e-01 | Dynamic Loss: 5.604e-01 | Regularization Loss: 5.347e-07 | Val Loss: 5.591e-01 | Time: 4.55s
2025-08-15 03:05:18,382:INFO:New best model found at epoch 450 with validation loss 5.591e-01. Saving...
2025-08-15 03:05:29,009:INFO:Epoch: 500/10000 | Train Loss: 5.577e-01 | Dynamic Loss: 5.577e-01 | Regularization Loss: 5.186e-07 | Val Loss: 5.531e-01 | Time: 10.62s
2025-08-15 03:05:29,009:INFO:New best model found at epoch 500 with validation loss 5.531e-01. Saving...
2025-08-15 03:05:33,695:INFO:Epoch: 550/10000 | Train Loss: 5.506e-01 | Dynamic Loss: 5.506e-01 | Regularization Loss: 5.018e-07 | Val Loss: 5.453e-01 | Time: 4.68s
2025-08-15 03:05:33,695:INFO:New best model found at epoch 550 with validation loss 5.453e-01. Saving...
2025-08-15 03:05:38,499:INFO:Epoch: 600/10000 | Train Loss: 5.486e-01 | Dynamic Loss: 5.486e-01 | Regularization Loss: 4.890e-07 | Val Loss: 5.422e-01 | Time: 4.80s
2025-08-15 03:05:38,499:INFO:New best model found at epoch 600 with validation loss 5.422e-01. Saving...
2025-08-15 03:05:43,191:INFO:Epoch: 650/10000 | Train Loss: 5.443e-01 | Dynamic Loss: 5.443e-01 | Regularization Loss: 4.729e-07 | Val Loss: 5.353e-01 | Time: 4.68s
2025-08-15 03:05:43,191:INFO:New best model found at epoch 650 with validation loss 5.353e-01. Saving...
2025-08-15 03:05:47,990:INFO:Epoch: 700/10000 | Train Loss: 5.432e-01 | Dynamic Loss: 5.432e-01 | Regularization Loss: 4.597e-07 | Val Loss: 5.306e-01 | Time: 4.79s
2025-08-15 03:05:47,990:INFO:New best model found at epoch 700 with validation loss 5.306e-01. Saving...
2025-08-15 03:05:52,710:INFO:Epoch: 750/10000 | Train Loss: 5.359e-01 | Dynamic Loss: 5.359e-01 | Regularization Loss: 4.448e-07 | Val Loss: 5.259e-01 | Time: 4.71s
2025-08-15 03:05:52,711:INFO:New best model found at epoch 750 with validation loss 5.259e-01. Saving...
2025-08-15 03:05:57,458:INFO:Epoch: 800/10000 | Train Loss: 5.339e-01 | Dynamic Loss: 5.339e-01 | Regularization Loss: 4.352e-07 | Val Loss: 5.237e-01 | Time: 4.74s
2025-08-15 03:05:57,459:INFO:New best model found at epoch 800 with validation loss 5.237e-01. Saving...
2025-08-15 03:06:02,134:INFO:Epoch: 850/10000 | Train Loss: 5.289e-01 | Dynamic Loss: 5.289e-01 | Regularization Loss: 4.226e-07 | Val Loss: 5.184e-01 | Time: 4.67s
2025-08-15 03:06:02,134:INFO:New best model found at epoch 850 with validation loss 5.184e-01. Saving...
2025-08-15 03:06:09,148:INFO:Epoch: 900/10000 | Train Loss: 5.283e-01 | Dynamic Loss: 5.283e-01 | Regularization Loss: 4.122e-07 | Val Loss: 5.160e-01 | Time: 7.01s
2025-08-15 03:06:09,148:INFO:New best model found at epoch 900 with validation loss 5.160e-01. Saving...
2025-08-15 03:06:13,880:INFO:Epoch: 950/10000 | Train Loss: 5.250e-01 | Dynamic Loss: 5.250e-01 | Regularization Loss: 4.023e-07 | Val Loss: 5.121e-01 | Time: 4.72s
2025-08-15 03:06:13,880:INFO:New best model found at epoch 950 with validation loss 5.121e-01. Saving...
2025-08-15 03:06:18,571:INFO:Epoch: 1000/10000 | Train Loss: 5.223e-01 | Dynamic Loss: 5.223e-01 | Regularization Loss: 3.927e-07 | Val Loss: 5.096e-01 | Time: 4.68s
2025-08-15 03:06:18,571:INFO:New best model found at epoch 1000 with validation loss 5.096e-01. Saving...
2025-08-15 03:06:23,234:INFO:Epoch: 1050/10000 | Train Loss: 5.173e-01 | Dynamic Loss: 5.173e-01 | Regularization Loss: 3.811e-07 | Val Loss: 5.069e-01 | Time: 4.65s
2025-08-15 03:06:23,234:INFO:New best model found at epoch 1050 with validation loss 5.069e-01. Saving...
2025-08-15 03:06:28,375:INFO:Epoch: 1100/10000 | Train Loss: 5.153e-01 | Dynamic Loss: 5.153e-01 | Regularization Loss: 3.725e-07 | Val Loss: 5.040e-01 | Time: 5.13s
2025-08-15 03:06:28,375:INFO:New best model found at epoch 1100 with validation loss 5.040e-01. Saving...
2025-08-15 03:06:33,045:INFO:Epoch: 1150/10000 | Train Loss: 5.118e-01 | Dynamic Loss: 5.118e-01 | Regularization Loss: 3.634e-07 | Val Loss: 5.010e-01 | Time: 4.66s
2025-08-15 03:06:33,045:INFO:New best model found at epoch 1150 with validation loss 5.010e-01. Saving...
2025-08-15 03:06:37,802:INFO:Epoch: 1200/10000 | Train Loss: 5.117e-01 | Dynamic Loss: 5.117e-01 | Regularization Loss: 3.573e-07 | Val Loss: 5.004e-01 | Time: 4.75s
2025-08-15 03:06:37,802:INFO:New best model found at epoch 1200 with validation loss 5.004e-01. Saving...
2025-08-15 03:06:42,509:INFO:Epoch: 1250/10000 | Train Loss: 5.089e-01 | Dynamic Loss: 5.089e-01 | Regularization Loss: 3.511e-07 | Val Loss: 4.962e-01 | Time: 4.70s
2025-08-15 03:06:42,509:INFO:New best model found at epoch 1250 with validation loss 4.962e-01. Saving...
2025-08-15 03:06:47,197:INFO:Epoch: 1300/10000 | Train Loss: 5.076e-01 | Dynamic Loss: 5.076e-01 | Regularization Loss: 3.419e-07 | Val Loss: 4.952e-01 | Time: 4.68s
2025-08-15 03:06:47,198:INFO:New best model found at epoch 1300 with validation loss 4.952e-01. Saving...
2025-08-15 03:06:57,887:INFO:Epoch: 1350/10000 | Train Loss: 5.056e-01 | Dynamic Loss: 5.056e-01 | Regularization Loss: 3.374e-07 | Val Loss: 4.942e-01 | Time: 10.68s
2025-08-15 03:06:57,887:INFO:New best model found at epoch 1350 with validation loss 4.942e-01. Saving...
2025-08-15 03:07:02,578:INFO:Epoch: 1400/10000 | Train Loss: 5.008e-01 | Dynamic Loss: 5.008e-01 | Regularization Loss: 3.290e-07 | Val Loss: 4.899e-01 | Time: 4.68s
2025-08-15 03:07:02,578:INFO:New best model found at epoch 1400 with validation loss 4.899e-01. Saving...
2025-08-15 03:07:07,268:INFO:Epoch: 1450/10000 | Train Loss: 5.001e-01 | Dynamic Loss: 5.001e-01 | Regularization Loss: 3.225e-07 | Val Loss: 4.884e-01 | Time: 4.68s
2025-08-15 03:07:07,268:INFO:New best model found at epoch 1450 with validation loss 4.884e-01. Saving...
2025-08-15 03:07:12,045:INFO:Epoch: 1500/10000 | Train Loss: 4.983e-01 | Dynamic Loss: 4.983e-01 | Regularization Loss: 3.159e-07 | Val Loss: 4.854e-01 | Time: 4.77s
2025-08-15 03:07:12,045:INFO:New best model found at epoch 1500 with validation loss 4.854e-01. Saving...
2025-08-15 03:07:17,406:INFO:Epoch: 1550/10000 | Train Loss: 4.977e-01 | Dynamic Loss: 4.977e-01 | Regularization Loss: 3.137e-07 | Val Loss: 4.877e-01 | Time: 5.35s
2025-08-15 03:07:22,096:INFO:Epoch: 1600/10000 | Train Loss: 4.934e-01 | Dynamic Loss: 4.934e-01 | Regularization Loss: 3.061e-07 | Val Loss: 4.819e-01 | Time: 4.69s
2025-08-15 03:07:22,096:INFO:New best model found at epoch 1600 with validation loss 4.819e-01. Saving...
2025-08-15 03:07:26,803:INFO:Epoch: 1650/10000 | Train Loss: 4.931e-01 | Dynamic Loss: 4.931e-01 | Regularization Loss: 3.004e-07 | Val Loss: 4.807e-01 | Time: 4.70s
2025-08-15 03:07:26,803:INFO:New best model found at epoch 1650 with validation loss 4.807e-01. Saving...
2025-08-15 03:07:31,544:INFO:Epoch: 1700/10000 | Train Loss: 4.897e-01 | Dynamic Loss: 4.897e-01 | Regularization Loss: 2.945e-07 | Val Loss: 4.792e-01 | Time: 4.73s
2025-08-15 03:07:31,544:INFO:New best model found at epoch 1700 with validation loss 4.792e-01. Saving...
2025-08-15 03:07:38,927:INFO:Epoch: 1750/10000 | Train Loss: 4.905e-01 | Dynamic Loss: 4.905e-01 | Regularization Loss: 2.905e-07 | Val Loss: 4.768e-01 | Time: 7.37s
2025-08-15 03:07:38,927:INFO:New best model found at epoch 1750 with validation loss 4.768e-01. Saving...
2025-08-15 03:07:43,622:INFO:Epoch: 1800/10000 | Train Loss: 4.869e-01 | Dynamic Loss: 4.869e-01 | Regularization Loss: 2.863e-07 | Val Loss: 4.775e-01 | Time: 4.69s
2025-08-15 03:07:48,311:INFO:Epoch: 1850/10000 | Train Loss: 4.845e-01 | Dynamic Loss: 4.845e-01 | Regularization Loss: 2.810e-07 | Val Loss: 4.758e-01 | Time: 4.69s
2025-08-15 03:07:48,311:INFO:New best model found at epoch 1850 with validation loss 4.758e-01. Saving...
2025-08-15 03:07:53,000:INFO:Epoch: 1900/10000 | Train Loss: 4.836e-01 | Dynamic Loss: 4.836e-01 | Regularization Loss: 2.762e-07 | Val Loss: 4.736e-01 | Time: 4.68s
2025-08-15 03:07:53,000:INFO:New best model found at epoch 1900 with validation loss 4.736e-01. Saving...
2025-08-15 03:07:57,780:INFO:Epoch: 1950/10000 | Train Loss: 4.812e-01 | Dynamic Loss: 4.812e-01 | Regularization Loss: 2.707e-07 | Val Loss: 4.731e-01 | Time: 4.77s
2025-08-15 03:07:57,780:INFO:New best model found at epoch 1950 with validation loss 4.731e-01. Saving...
2025-08-15 03:08:08,205:INFO:Epoch: 2000/10000 | Train Loss: 4.782e-01 | Dynamic Loss: 4.782e-01 | Regularization Loss: 2.658e-07 | Val Loss: 4.694e-01 | Time: 10.42s
2025-08-15 03:08:08,205:INFO:New best model found at epoch 2000 with validation loss 4.694e-01. Saving...
2025-08-15 03:08:12,934:INFO:Epoch: 2050/10000 | Train Loss: 4.765e-01 | Dynamic Loss: 4.765e-01 | Regularization Loss: 2.610e-07 | Val Loss: 4.668e-01 | Time: 4.72s
2025-08-15 03:08:12,934:INFO:New best model found at epoch 2050 with validation loss 4.668e-01. Saving...
2025-08-15 03:08:17,677:INFO:Epoch: 2100/10000 | Train Loss: 4.742e-01 | Dynamic Loss: 4.742e-01 | Regularization Loss: 2.564e-07 | Val Loss: 4.654e-01 | Time: 4.73s
2025-08-15 03:08:17,677:INFO:New best model found at epoch 2100 with validation loss 4.654e-01. Saving...
2025-08-15 03:08:22,414:INFO:Epoch: 2150/10000 | Train Loss: 4.721e-01 | Dynamic Loss: 4.721e-01 | Regularization Loss: 2.502e-07 | Val Loss: 4.647e-01 | Time: 4.73s
2025-08-15 03:08:22,414:INFO:New best model found at epoch 2150 with validation loss 4.647e-01. Saving...
2025-08-15 03:08:27,617:INFO:Epoch: 2200/10000 | Train Loss: 4.721e-01 | Dynamic Loss: 4.721e-01 | Regularization Loss: 2.462e-07 | Val Loss: 4.637e-01 | Time: 5.19s
2025-08-15 03:08:27,617:INFO:New best model found at epoch 2200 with validation loss 4.637e-01. Saving...
2025-08-15 03:08:32,313:INFO:Epoch: 2250/10000 | Train Loss: 4.673e-01 | Dynamic Loss: 4.673e-01 | Regularization Loss: 2.400e-07 | Val Loss: 4.604e-01 | Time: 4.69s
2025-08-15 03:08:32,313:INFO:New best model found at epoch 2250 with validation loss 4.604e-01. Saving...
2025-08-15 03:08:37,038:INFO:Epoch: 2300/10000 | Train Loss: 4.661e-01 | Dynamic Loss: 4.661e-01 | Regularization Loss: 2.363e-07 | Val Loss: 4.590e-01 | Time: 4.72s
2025-08-15 03:08:37,039:INFO:New best model found at epoch 2300 with validation loss 4.590e-01. Saving...
2025-08-15 03:08:41,716:INFO:Epoch: 2350/10000 | Train Loss: 4.652e-01 | Dynamic Loss: 4.652e-01 | Regularization Loss: 2.320e-07 | Val Loss: 4.606e-01 | Time: 4.67s
2025-08-15 03:08:46,375:INFO:Epoch: 2400/10000 | Train Loss: 4.628e-01 | Dynamic Loss: 4.628e-01 | Regularization Loss: 2.288e-07 | Val Loss: 4.570e-01 | Time: 4.66s
2025-08-15 03:08:46,375:INFO:New best model found at epoch 2400 with validation loss 4.570e-01. Saving...
2025-08-15 03:08:55,273:INFO:Epoch: 2450/10000 | Train Loss: 4.613e-01 | Dynamic Loss: 4.613e-01 | Regularization Loss: 2.274e-07 | Val Loss: 4.567e-01 | Time: 8.89s
2025-08-15 03:08:55,273:INFO:New best model found at epoch 2450 with validation loss 4.567e-01. Saving...
2025-08-15 03:08:59,930:INFO:Epoch: 2500/10000 | Train Loss: 4.589e-01 | Dynamic Loss: 4.589e-01 | Regularization Loss: 2.237e-07 | Val Loss: 4.550e-01 | Time: 4.65s
2025-08-15 03:08:59,931:INFO:New best model found at epoch 2500 with validation loss 4.550e-01. Saving...
2025-08-15 03:09:04,729:INFO:Epoch: 2550/10000 | Train Loss: 4.580e-01 | Dynamic Loss: 4.580e-01 | Regularization Loss: 2.212e-07 | Val Loss: 4.537e-01 | Time: 4.79s
2025-08-15 03:09:04,729:INFO:New best model found at epoch 2550 with validation loss 4.537e-01. Saving...
2025-08-15 03:09:09,373:INFO:Epoch: 2600/10000 | Train Loss: 4.574e-01 | Dynamic Loss: 4.574e-01 | Regularization Loss: 2.182e-07 | Val Loss: 4.538e-01 | Time: 4.63s
2025-08-15 03:09:14,090:INFO:Epoch: 2650/10000 | Train Loss: 4.569e-01 | Dynamic Loss: 4.569e-01 | Regularization Loss: 2.167e-07 | Val Loss: 4.534e-01 | Time: 4.72s
2025-08-15 03:09:14,090:INFO:New best model found at epoch 2650 with validation loss 4.534e-01. Saving...
2025-08-15 03:09:23,707:INFO:Epoch: 2700/10000 | Train Loss: 4.556e-01 | Dynamic Loss: 4.556e-01 | Regularization Loss: 2.149e-07 | Val Loss: 4.509e-01 | Time: 9.61s
2025-08-15 03:09:23,707:INFO:New best model found at epoch 2700 with validation loss 4.509e-01. Saving...
2025-08-15 03:09:28,497:INFO:Epoch: 2750/10000 | Train Loss: 4.539e-01 | Dynamic Loss: 4.539e-01 | Regularization Loss: 2.122e-07 | Val Loss: 4.505e-01 | Time: 4.78s
2025-08-15 03:09:28,497:INFO:New best model found at epoch 2750 with validation loss 4.505e-01. Saving...
2025-08-15 03:09:33,278:INFO:Epoch: 2800/10000 | Train Loss: 4.532e-01 | Dynamic Loss: 4.532e-01 | Regularization Loss: 2.110e-07 | Val Loss: 4.495e-01 | Time: 4.77s
2025-08-15 03:09:33,278:INFO:New best model found at epoch 2800 with validation loss 4.495e-01. Saving...
2025-08-15 03:09:38,067:INFO:Epoch: 2850/10000 | Train Loss: 4.519e-01 | Dynamic Loss: 4.519e-01 | Regularization Loss: 2.067e-07 | Val Loss: 4.490e-01 | Time: 4.78s
2025-08-15 03:09:38,067:INFO:New best model found at epoch 2850 with validation loss 4.490e-01. Saving...
2025-08-15 03:09:42,845:INFO:Epoch: 2900/10000 | Train Loss: 4.523e-01 | Dynamic Loss: 4.523e-01 | Regularization Loss: 2.055e-07 | Val Loss: 4.478e-01 | Time: 4.77s
2025-08-15 03:09:42,845:INFO:New best model found at epoch 2900 with validation loss 4.478e-01. Saving...
2025-08-15 03:09:51,646:INFO:Epoch: 2950/10000 | Train Loss: 4.512e-01 | Dynamic Loss: 4.512e-01 | Regularization Loss: 2.026e-07 | Val Loss: 4.459e-01 | Time: 8.79s
2025-08-15 03:09:51,646:INFO:New best model found at epoch 2950 with validation loss 4.459e-01. Saving...
2025-08-15 03:09:56,392:INFO:Epoch: 3000/10000 | Train Loss: 4.504e-01 | Dynamic Loss: 4.504e-01 | Regularization Loss: 1.994e-07 | Val Loss: 4.452e-01 | Time: 4.74s
2025-08-15 03:09:56,392:INFO:New best model found at epoch 3000 with validation loss 4.452e-01. Saving...
2025-08-15 03:10:01,157:INFO:Epoch: 3050/10000 | Train Loss: 4.473e-01 | Dynamic Loss: 4.473e-01 | Regularization Loss: 1.974e-07 | Val Loss: 4.460e-01 | Time: 4.76s
2025-08-15 03:10:05,812:INFO:Epoch: 3100/10000 | Train Loss: 4.471e-01 | Dynamic Loss: 4.471e-01 | Regularization Loss: 1.954e-07 | Val Loss: 4.441e-01 | Time: 4.65s
2025-08-15 03:10:05,812:INFO:New best model found at epoch 3100 with validation loss 4.441e-01. Saving...
2025-08-15 03:10:10,502:INFO:Epoch: 3150/10000 | Train Loss: 4.474e-01 | Dynamic Loss: 4.474e-01 | Regularization Loss: 1.943e-07 | Val Loss: 4.423e-01 | Time: 4.68s
2025-08-15 03:10:10,502:INFO:New best model found at epoch 3150 with validation loss 4.423e-01. Saving...
2025-08-15 03:10:21,025:INFO:Epoch: 3200/10000 | Train Loss: 4.460e-01 | Dynamic Loss: 4.460e-01 | Regularization Loss: 1.918e-07 | Val Loss: 4.416e-01 | Time: 10.51s
2025-08-15 03:10:21,025:INFO:New best model found at epoch 3200 with validation loss 4.416e-01. Saving...
2025-08-15 03:10:25,707:INFO:Epoch: 3250/10000 | Train Loss: 4.444e-01 | Dynamic Loss: 4.444e-01 | Regularization Loss: 1.906e-07 | Val Loss: 4.411e-01 | Time: 4.67s
2025-08-15 03:10:25,708:INFO:New best model found at epoch 3250 with validation loss 4.411e-01. Saving...
2025-08-15 03:10:30,410:INFO:Epoch: 3300/10000 | Train Loss: 4.428e-01 | Dynamic Loss: 4.428e-01 | Regularization Loss: 1.884e-07 | Val Loss: 4.400e-01 | Time: 4.69s
2025-08-15 03:10:30,410:INFO:New best model found at epoch 3300 with validation loss 4.400e-01. Saving...
2025-08-15 03:10:35,207:INFO:Epoch: 3350/10000 | Train Loss: 4.424e-01 | Dynamic Loss: 4.424e-01 | Regularization Loss: 1.861e-07 | Val Loss: 4.393e-01 | Time: 4.79s
2025-08-15 03:10:35,207:INFO:New best model found at epoch 3350 with validation loss 4.393e-01. Saving...
2025-08-15 03:10:40,227:INFO:Epoch: 3400/10000 | Train Loss: 4.429e-01 | Dynamic Loss: 4.429e-01 | Regularization Loss: 1.853e-07 | Val Loss: 4.400e-01 | Time: 5.01s
2025-08-15 03:10:45,003:INFO:Epoch: 3450/10000 | Train Loss: 4.417e-01 | Dynamic Loss: 4.417e-01 | Regularization Loss: 1.832e-07 | Val Loss: 4.388e-01 | Time: 4.78s
2025-08-15 03:10:45,003:INFO:New best model found at epoch 3450 with validation loss 4.388e-01. Saving...
2025-08-15 03:10:49,753:INFO:Epoch: 3500/10000 | Train Loss: 4.416e-01 | Dynamic Loss: 4.416e-01 | Regularization Loss: 1.823e-07 | Val Loss: 4.388e-01 | Time: 4.74s
2025-08-15 03:10:49,753:INFO:New best model found at epoch 3500 with validation loss 4.388e-01. Saving...
2025-08-15 03:10:54,467:INFO:Epoch: 3550/10000 | Train Loss: 4.412e-01 | Dynamic Loss: 4.412e-01 | Regularization Loss: 1.817e-07 | Val Loss: 4.385e-01 | Time: 4.71s
2025-08-15 03:10:54,467:INFO:New best model found at epoch 3550 with validation loss 4.385e-01. Saving...
2025-08-15 03:10:59,199:INFO:Epoch: 3600/10000 | Train Loss: 4.401e-01 | Dynamic Loss: 4.401e-01 | Regularization Loss: 1.803e-07 | Val Loss: 4.380e-01 | Time: 4.72s
2025-08-15 03:10:59,199:INFO:New best model found at epoch 3600 with validation loss 4.380e-01. Saving...
2025-08-15 03:11:10,006:INFO:Epoch: 3650/10000 | Train Loss: 4.394e-01 | Dynamic Loss: 4.394e-01 | Regularization Loss: 1.789e-07 | Val Loss: 4.383e-01 | Time: 10.80s
2025-08-15 03:11:14,733:INFO:Epoch: 3700/10000 | Train Loss: 4.384e-01 | Dynamic Loss: 4.384e-01 | Regularization Loss: 1.780e-07 | Val Loss: 4.374e-01 | Time: 4.73s
2025-08-15 03:11:14,734:INFO:New best model found at epoch 3700 with validation loss 4.374e-01. Saving...
2025-08-15 03:11:19,542:INFO:Epoch: 3750/10000 | Train Loss: 4.385e-01 | Dynamic Loss: 4.385e-01 | Regularization Loss: 1.763e-07 | Val Loss: 4.381e-01 | Time: 4.80s
2025-08-15 03:11:24,211:INFO:Epoch: 3800/10000 | Train Loss: 4.370e-01 | Dynamic Loss: 4.370e-01 | Regularization Loss: 1.749e-07 | Val Loss: 4.364e-01 | Time: 4.67s
2025-08-15 03:11:24,212:INFO:New best model found at epoch 3800 with validation loss 4.364e-01. Saving...
2025-08-15 03:11:29,675:INFO:Epoch: 3850/10000 | Train Loss: 4.367e-01 | Dynamic Loss: 4.367e-01 | Regularization Loss: 1.735e-07 | Val Loss: 4.363e-01 | Time: 5.45s
2025-08-15 03:11:29,675:INFO:New best model found at epoch 3850 with validation loss 4.363e-01. Saving...
2025-08-15 03:11:34,536:INFO:Epoch: 3900/10000 | Train Loss: 4.360e-01 | Dynamic Loss: 4.360e-01 | Regularization Loss: 1.722e-07 | Val Loss: 4.372e-01 | Time: 4.85s
2025-08-15 03:11:39,402:INFO:Epoch: 3950/10000 | Train Loss: 4.352e-01 | Dynamic Loss: 4.352e-01 | Regularization Loss: 1.703e-07 | Val Loss: 4.355e-01 | Time: 4.87s
2025-08-15 03:11:39,403:INFO:New best model found at epoch 3950 with validation loss 4.355e-01. Saving...
2025-08-15 03:11:44,245:INFO:Epoch: 4000/10000 | Train Loss: 4.350e-01 | Dynamic Loss: 4.350e-01 | Regularization Loss: 1.687e-07 | Val Loss: 4.347e-01 | Time: 4.83s
2025-08-15 03:11:44,245:INFO:New best model found at epoch 4000 with validation loss 4.347e-01. Saving...
2025-08-15 03:11:49,022:INFO:Epoch: 4050/10000 | Train Loss: 4.334e-01 | Dynamic Loss: 4.334e-01 | Regularization Loss: 1.678e-07 | Val Loss: 4.341e-01 | Time: 4.77s
2025-08-15 03:11:49,022:INFO:New best model found at epoch 4050 with validation loss 4.341e-01. Saving...
2025-08-15 03:11:53,751:INFO:Epoch: 4100/10000 | Train Loss: 4.313e-01 | Dynamic Loss: 4.313e-01 | Regularization Loss: 1.652e-07 | Val Loss: 4.323e-01 | Time: 4.72s
2025-08-15 03:11:53,751:INFO:New best model found at epoch 4100 with validation loss 4.323e-01. Saving...
2025-08-15 03:11:58,492:INFO:Epoch: 4150/10000 | Train Loss: 4.291e-01 | Dynamic Loss: 4.291e-01 | Regularization Loss: 1.637e-07 | Val Loss: 4.319e-01 | Time: 4.73s
2025-08-15 03:11:58,492:INFO:New best model found at epoch 4150 with validation loss 4.319e-01. Saving...
2025-08-15 03:12:03,258:INFO:Epoch: 4200/10000 | Train Loss: 4.302e-01 | Dynamic Loss: 4.302e-01 | Regularization Loss: 1.606e-07 | Val Loss: 4.317e-01 | Time: 4.76s
2025-08-15 03:12:03,258:INFO:New best model found at epoch 4200 with validation loss 4.317e-01. Saving...
2025-08-15 03:12:08,022:INFO:Epoch: 4250/10000 | Train Loss: 4.267e-01 | Dynamic Loss: 4.267e-01 | Regularization Loss: 1.590e-07 | Val Loss: 4.305e-01 | Time: 4.75s
2025-08-15 03:12:08,022:INFO:New best model found at epoch 4250 with validation loss 4.305e-01. Saving...
2025-08-15 03:12:16,997:INFO:Epoch: 4300/10000 | Train Loss: 4.251e-01 | Dynamic Loss: 4.251e-01 | Regularization Loss: 1.568e-07 | Val Loss: 4.281e-01 | Time: 8.97s
2025-08-15 03:12:16,997:INFO:New best model found at epoch 4300 with validation loss 4.281e-01. Saving...
2025-08-15 03:12:21,796:INFO:Epoch: 4350/10000 | Train Loss: 4.246e-01 | Dynamic Loss: 4.246e-01 | Regularization Loss: 1.555e-07 | Val Loss: 4.283e-01 | Time: 4.79s
2025-08-15 03:12:26,565:INFO:Epoch: 4400/10000 | Train Loss: 4.235e-01 | Dynamic Loss: 4.235e-01 | Regularization Loss: 1.545e-07 | Val Loss: 4.272e-01 | Time: 4.77s
2025-08-15 03:12:26,565:INFO:New best model found at epoch 4400 with validation loss 4.272e-01. Saving...
2025-08-15 03:12:31,389:INFO:Epoch: 4450/10000 | Train Loss: 4.234e-01 | Dynamic Loss: 4.234e-01 | Regularization Loss: 1.535e-07 | Val Loss: 4.276e-01 | Time: 4.81s
2025-08-15 03:12:36,140:INFO:Epoch: 4500/10000 | Train Loss: 4.230e-01 | Dynamic Loss: 4.230e-01 | Regularization Loss: 1.523e-07 | Val Loss: 4.259e-01 | Time: 4.75s
2025-08-15 03:12:36,140:INFO:New best model found at epoch 4500 with validation loss 4.259e-01. Saving...
2025-08-15 03:12:46,731:INFO:Epoch: 4550/10000 | Train Loss: 4.214e-01 | Dynamic Loss: 4.214e-01 | Regularization Loss: 1.501e-07 | Val Loss: 4.257e-01 | Time: 10.58s
2025-08-15 03:12:46,731:INFO:New best model found at epoch 4550 with validation loss 4.257e-01. Saving...
2025-08-15 03:12:51,562:INFO:Epoch: 4600/10000 | Train Loss: 4.197e-01 | Dynamic Loss: 4.197e-01 | Regularization Loss: 1.493e-07 | Val Loss: 4.250e-01 | Time: 4.82s
2025-08-15 03:12:51,562:INFO:New best model found at epoch 4600 with validation loss 4.250e-01. Saving...
2025-08-15 03:12:56,369:INFO:Epoch: 4650/10000 | Train Loss: 4.191e-01 | Dynamic Loss: 4.191e-01 | Regularization Loss: 1.483e-07 | Val Loss: 4.243e-01 | Time: 4.80s
2025-08-15 03:12:56,369:INFO:New best model found at epoch 4650 with validation loss 4.243e-01. Saving...
2025-08-15 03:13:01,006:INFO:Epoch: 4700/10000 | Train Loss: 4.179e-01 | Dynamic Loss: 4.179e-01 | Regularization Loss: 1.476e-07 | Val Loss: 4.243e-01 | Time: 4.63s
2025-08-15 03:13:01,007:INFO:New best model found at epoch 4700 with validation loss 4.243e-01. Saving...
2025-08-15 03:13:05,741:INFO:Epoch: 4750/10000 | Train Loss: 4.184e-01 | Dynamic Loss: 4.184e-01 | Regularization Loss: 1.455e-07 | Val Loss: 4.246e-01 | Time: 4.72s
2025-08-15 03:13:13,387:INFO:Epoch: 4800/10000 | Train Loss: 4.183e-01 | Dynamic Loss: 4.183e-01 | Regularization Loss: 1.453e-07 | Val Loss: 4.239e-01 | Time: 7.65s
2025-08-15 03:13:13,387:INFO:New best model found at epoch 4800 with validation loss 4.239e-01. Saving...
2025-08-15 03:13:18,122:INFO:Epoch: 4850/10000 | Train Loss: 4.138e-01 | Dynamic Loss: 4.138e-01 | Regularization Loss: 1.427e-07 | Val Loss: 4.211e-01 | Time: 4.73s
2025-08-15 03:13:18,123:INFO:New best model found at epoch 4850 with validation loss 4.211e-01. Saving...
2025-08-15 03:13:22,929:INFO:Epoch: 4900/10000 | Train Loss: 4.122e-01 | Dynamic Loss: 4.122e-01 | Regularization Loss: 1.417e-07 | Val Loss: 4.203e-01 | Time: 4.80s
2025-08-15 03:13:22,930:INFO:New best model found at epoch 4900 with validation loss 4.203e-01. Saving...
2025-08-15 03:13:27,733:INFO:Epoch: 4950/10000 | Train Loss: 4.124e-01 | Dynamic Loss: 4.124e-01 | Regularization Loss: 1.393e-07 | Val Loss: 4.199e-01 | Time: 4.80s
2025-08-15 03:13:27,733:INFO:New best model found at epoch 4950 with validation loss 4.199e-01. Saving...
2025-08-15 03:13:32,489:INFO:Epoch: 5000/10000 | Train Loss: 4.110e-01 | Dynamic Loss: 4.110e-01 | Regularization Loss: 1.393e-07 | Val Loss: 4.188e-01 | Time: 4.75s
2025-08-15 03:13:32,489:INFO:New best model found at epoch 5000 with validation loss 4.188e-01. Saving...
2025-08-15 03:13:39,846:INFO:Epoch: 5050/10000 | Train Loss: 4.099e-01 | Dynamic Loss: 4.099e-01 | Regularization Loss: 1.385e-07 | Val Loss: 4.183e-01 | Time: 7.35s
2025-08-15 03:13:39,846:INFO:New best model found at epoch 5050 with validation loss 4.183e-01. Saving...
2025-08-15 03:13:44,653:INFO:Epoch: 5100/10000 | Train Loss: 4.087e-01 | Dynamic Loss: 4.087e-01 | Regularization Loss: 1.371e-07 | Val Loss: 4.176e-01 | Time: 4.80s
2025-08-15 03:13:44,653:INFO:New best model found at epoch 5100 with validation loss 4.176e-01. Saving...
2025-08-15 03:13:49,395:INFO:Epoch: 5150/10000 | Train Loss: 4.094e-01 | Dynamic Loss: 4.094e-01 | Regularization Loss: 1.352e-07 | Val Loss: 4.170e-01 | Time: 4.73s
2025-08-15 03:13:49,395:INFO:New best model found at epoch 5150 with validation loss 4.170e-01. Saving...
2025-08-15 03:13:54,230:INFO:Epoch: 5200/10000 | Train Loss: 4.065e-01 | Dynamic Loss: 4.065e-01 | Regularization Loss: 1.337e-07 | Val Loss: 4.164e-01 | Time: 4.82s
2025-08-15 03:13:54,230:INFO:New best model found at epoch 5200 with validation loss 4.164e-01. Saving...
2025-08-15 03:13:59,022:INFO:Epoch: 5250/10000 | Train Loss: 4.077e-01 | Dynamic Loss: 4.077e-01 | Regularization Loss: 1.324e-07 | Val Loss: 4.153e-01 | Time: 4.78s
2025-08-15 03:13:59,022:INFO:New best model found at epoch 5250 with validation loss 4.153e-01. Saving...
2025-08-15 03:14:06,586:INFO:Epoch: 5300/10000 | Train Loss: 4.064e-01 | Dynamic Loss: 4.064e-01 | Regularization Loss: 1.323e-07 | Val Loss: 4.147e-01 | Time: 7.55s
2025-08-15 03:14:06,586:INFO:New best model found at epoch 5300 with validation loss 4.147e-01. Saving...
2025-08-15 03:14:11,402:INFO:Epoch: 5350/10000 | Train Loss: 4.046e-01 | Dynamic Loss: 4.046e-01 | Regularization Loss: 1.302e-07 | Val Loss: 4.140e-01 | Time: 4.81s
2025-08-15 03:14:11,402:INFO:New best model found at epoch 5350 with validation loss 4.140e-01. Saving...
2025-08-15 03:14:16,158:INFO:Epoch: 5400/10000 | Train Loss: 4.034e-01 | Dynamic Loss: 4.034e-01 | Regularization Loss: 1.306e-07 | Val Loss: 4.134e-01 | Time: 4.75s
2025-08-15 03:14:16,158:INFO:New best model found at epoch 5400 with validation loss 4.134e-01. Saving...
2025-08-15 03:14:20,921:INFO:Epoch: 5450/10000 | Train Loss: 4.033e-01 | Dynamic Loss: 4.033e-01 | Regularization Loss: 1.298e-07 | Val Loss: 4.128e-01 | Time: 4.75s
2025-08-15 03:14:20,921:INFO:New best model found at epoch 5450 with validation loss 4.128e-01. Saving...
2025-08-15 03:14:25,643:INFO:Epoch: 5500/10000 | Train Loss: 4.027e-01 | Dynamic Loss: 4.027e-01 | Regularization Loss: 1.287e-07 | Val Loss: 4.118e-01 | Time: 4.71s
2025-08-15 03:14:25,643:INFO:New best model found at epoch 5500 with validation loss 4.118e-01. Saving...
2025-08-15 03:14:35,861:INFO:Epoch: 5550/10000 | Train Loss: 4.015e-01 | Dynamic Loss: 4.015e-01 | Regularization Loss: 1.261e-07 | Val Loss: 4.114e-01 | Time: 10.21s
2025-08-15 03:14:35,861:INFO:New best model found at epoch 5550 with validation loss 4.114e-01. Saving...
2025-08-15 03:14:40,621:INFO:Epoch: 5600/10000 | Train Loss: 4.020e-01 | Dynamic Loss: 4.020e-01 | Regularization Loss: 1.254e-07 | Val Loss: 4.110e-01 | Time: 4.75s
2025-08-15 03:14:40,621:INFO:New best model found at epoch 5600 with validation loss 4.110e-01. Saving...
2025-08-15 03:14:45,335:INFO:Epoch: 5650/10000 | Train Loss: 3.988e-01 | Dynamic Loss: 3.988e-01 | Regularization Loss: 1.266e-07 | Val Loss: 4.101e-01 | Time: 4.70s
2025-08-15 03:14:45,335:INFO:New best model found at epoch 5650 with validation loss 4.101e-01. Saving...
2025-08-15 03:14:50,309:INFO:Epoch: 5700/10000 | Train Loss: 4.000e-01 | Dynamic Loss: 4.000e-01 | Regularization Loss: 1.247e-07 | Val Loss: 4.136e-01 | Time: 4.96s
2025-08-15 03:14:55,010:INFO:Epoch: 5750/10000 | Train Loss: 3.969e-01 | Dynamic Loss: 3.969e-01 | Regularization Loss: 1.210e-07 | Val Loss: 4.083e-01 | Time: 4.70s
2025-08-15 03:14:55,010:INFO:New best model found at epoch 5750 with validation loss 4.083e-01. Saving...
2025-08-15 03:15:06,082:INFO:Epoch: 5800/10000 | Train Loss: 3.949e-01 | Dynamic Loss: 3.949e-01 | Regularization Loss: 1.209e-07 | Val Loss: 4.073e-01 | Time: 11.06s
2025-08-15 03:15:06,082:INFO:New best model found at epoch 5800 with validation loss 4.073e-01. Saving...
2025-08-15 03:15:10,892:INFO:Epoch: 5850/10000 | Train Loss: 3.932e-01 | Dynamic Loss: 3.932e-01 | Regularization Loss: 1.197e-07 | Val Loss: 4.067e-01 | Time: 4.80s
2025-08-15 03:15:10,892:INFO:New best model found at epoch 5850 with validation loss 4.067e-01. Saving...
2025-08-15 03:15:15,754:INFO:Epoch: 5900/10000 | Train Loss: 3.910e-01 | Dynamic Loss: 3.910e-01 | Regularization Loss: 1.162e-07 | Val Loss: 4.051e-01 | Time: 4.85s
2025-08-15 03:15:15,754:INFO:New best model found at epoch 5900 with validation loss 4.051e-01. Saving...
2025-08-15 03:15:20,519:INFO:Epoch: 5950/10000 | Train Loss: 3.907e-01 | Dynamic Loss: 3.907e-01 | Regularization Loss: 1.147e-07 | Val Loss: 4.046e-01 | Time: 4.75s
2025-08-15 03:15:20,519:INFO:New best model found at epoch 5950 with validation loss 4.046e-01. Saving...
2025-08-15 03:15:26,660:INFO:Epoch: 6000/10000 | Train Loss: 3.890e-01 | Dynamic Loss: 3.890e-01 | Regularization Loss: 1.127e-07 | Val Loss: 4.039e-01 | Time: 6.13s
2025-08-15 03:15:26,660:INFO:New best model found at epoch 6000 with validation loss 4.039e-01. Saving...
2025-08-15 03:15:31,460:INFO:Epoch: 6050/10000 | Train Loss: 3.876e-01 | Dynamic Loss: 3.876e-01 | Regularization Loss: 1.124e-07 | Val Loss: 4.020e-01 | Time: 4.79s
2025-08-15 03:15:31,460:INFO:New best model found at epoch 6050 with validation loss 4.020e-01. Saving...
2025-08-15 03:15:36,182:INFO:Epoch: 6100/10000 | Train Loss: 3.847e-01 | Dynamic Loss: 3.847e-01 | Regularization Loss: 1.111e-07 | Val Loss: 4.008e-01 | Time: 4.71s
2025-08-15 03:15:36,182:INFO:New best model found at epoch 6100 with validation loss 4.008e-01. Saving...
2025-08-15 03:15:40,961:INFO:Epoch: 6150/10000 | Train Loss: 3.849e-01 | Dynamic Loss: 3.849e-01 | Regularization Loss: 1.097e-07 | Val Loss: 4.001e-01 | Time: 4.77s
2025-08-15 03:15:40,961:INFO:New best model found at epoch 6150 with validation loss 4.001e-01. Saving...
2025-08-15 03:15:45,792:INFO:Epoch: 6200/10000 | Train Loss: 3.841e-01 | Dynamic Loss: 3.841e-01 | Regularization Loss: 1.075e-07 | Val Loss: 4.002e-01 | Time: 4.82s
2025-08-15 03:15:55,216:INFO:Epoch: 6250/10000 | Train Loss: 3.843e-01 | Dynamic Loss: 3.843e-01 | Regularization Loss: 1.063e-07 | Val Loss: 4.002e-01 | Time: 9.42s
2025-08-15 03:15:59,985:INFO:Epoch: 6300/10000 | Train Loss: 3.833e-01 | Dynamic Loss: 3.833e-01 | Regularization Loss: 1.059e-07 | Val Loss: 4.021e-01 | Time: 4.77s
2025-08-15 03:16:04,724:INFO:Epoch: 6350/10000 | Train Loss: 3.814e-01 | Dynamic Loss: 3.814e-01 | Regularization Loss: 1.063e-07 | Val Loss: 3.980e-01 | Time: 4.74s
2025-08-15 03:16:04,724:INFO:New best model found at epoch 6350 with validation loss 3.980e-01. Saving...
2025-08-15 03:16:09,534:INFO:Epoch: 6400/10000 | Train Loss: 3.825e-01 | Dynamic Loss: 3.825e-01 | Regularization Loss: 1.036e-07 | Val Loss: 3.977e-01 | Time: 4.80s
2025-08-15 03:16:09,534:INFO:New best model found at epoch 6400 with validation loss 3.977e-01. Saving...
2025-08-15 03:16:14,289:INFO:Epoch: 6450/10000 | Train Loss: 3.802e-01 | Dynamic Loss: 3.802e-01 | Regularization Loss: 1.047e-07 | Val Loss: 3.970e-01 | Time: 4.75s
2025-08-15 03:16:14,289:INFO:New best model found at epoch 6450 with validation loss 3.970e-01. Saving...
2025-08-15 03:16:24,924:INFO:Epoch: 6500/10000 | Train Loss: 3.791e-01 | Dynamic Loss: 3.791e-01 | Regularization Loss: 1.053e-07 | Val Loss: 3.958e-01 | Time: 10.63s
2025-08-15 03:16:24,924:INFO:New best model found at epoch 6500 with validation loss 3.958e-01. Saving...
2025-08-15 03:16:29,747:INFO:Epoch: 6550/10000 | Train Loss: 3.767e-01 | Dynamic Loss: 3.767e-01 | Regularization Loss: 9.910e-08 | Val Loss: 3.959e-01 | Time: 4.81s
2025-08-15 03:16:34,500:INFO:Epoch: 6600/10000 | Train Loss: 3.765e-01 | Dynamic Loss: 3.765e-01 | Regularization Loss: 9.647e-08 | Val Loss: 3.946e-01 | Time: 4.75s
2025-08-15 03:16:34,500:INFO:New best model found at epoch 6600 with validation loss 3.946e-01. Saving...
2025-08-15 03:16:39,267:INFO:Epoch: 6650/10000 | Train Loss: 3.756e-01 | Dynamic Loss: 3.756e-01 | Regularization Loss: 1.099e-07 | Val Loss: 3.949e-01 | Time: 4.76s
2025-08-15 03:16:44,116:INFO:Epoch: 6700/10000 | Train Loss: 3.759e-01 | Dynamic Loss: 3.759e-01 | Regularization Loss: 1.241e-07 | Val Loss: 3.937e-01 | Time: 4.85s
2025-08-15 03:16:44,116:INFO:New best model found at epoch 6700 with validation loss 3.937e-01. Saving...
2025-08-15 03:16:55,328:INFO:Epoch: 6750/10000 | Train Loss: 3.756e-01 | Dynamic Loss: 3.756e-01 | Regularization Loss: 0.000e+00 | Val Loss: 3.928e-01 | Time: 11.20s
2025-08-15 03:16:55,328:INFO:New best model found at epoch 6750 with validation loss 3.928e-01. Saving...
2025-08-15 03:17:00,171:INFO:Epoch: 6800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.83s
2025-08-15 03:17:05,068:INFO:Epoch: 6850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.90s
2025-08-15 03:17:09,855:INFO:Epoch: 6900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.79s
2025-08-15 03:17:15,224:INFO:Epoch: 6950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.37s
2025-08-15 03:17:20,001:INFO:Epoch: 7000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.78s
2025-08-15 03:17:24,808:INFO:Epoch: 7050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.81s
2025-08-15 03:17:29,614:INFO:Epoch: 7100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.81s
2025-08-15 03:17:34,392:INFO:Epoch: 7150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.78s
2025-08-15 03:17:42,971:INFO:Epoch: 7200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 8.58s
2025-08-15 03:17:47,736:INFO:Epoch: 7250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.77s
2025-08-15 03:17:52,482:INFO:Epoch: 7300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.75s
2025-08-15 03:17:57,274:INFO:Epoch: 7350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.79s
2025-08-15 03:18:02,860:INFO:Epoch: 7400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.59s
2025-08-15 03:18:07,721:INFO:Epoch: 7450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.86s
2025-08-15 03:18:12,601:INFO:Epoch: 7500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.88s
2025-08-15 03:18:17,340:INFO:Epoch: 7550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.74s
2025-08-15 03:18:22,049:INFO:Epoch: 7600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.71s
2025-08-15 03:18:28,547:INFO:Epoch: 7650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 6.50s
2025-08-15 03:18:33,338:INFO:Epoch: 7700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.79s
2025-08-15 03:18:38,243:INFO:Epoch: 7750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.90s
2025-08-15 03:18:42,983:INFO:Epoch: 7800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.74s
2025-08-15 03:18:47,813:INFO:Epoch: 7850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.83s
2025-08-15 03:18:55,061:INFO:Epoch: 7900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 7.25s
2025-08-15 03:18:59,896:INFO:Epoch: 7950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.83s
2025-08-15 03:19:04,765:INFO:Epoch: 8000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.87s
2025-08-15 03:19:09,534:INFO:Epoch: 8050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.77s
2025-08-15 03:19:14,365:INFO:Epoch: 8100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.83s
2025-08-15 03:19:24,825:INFO:Epoch: 8150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 10.46s
2025-08-15 03:19:29,672:INFO:Epoch: 8200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.85s
2025-08-15 03:19:34,530:INFO:Epoch: 8250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.86s
2025-08-15 03:19:39,312:INFO:Epoch: 8300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.78s
2025-08-15 03:19:44,122:INFO:Epoch: 8350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.81s
2025-08-15 03:19:50,900:INFO:Epoch: 8400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 6.78s
2025-08-15 03:19:55,749:INFO:Epoch: 8450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.85s
2025-08-15 03:20:00,585:INFO:Epoch: 8500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.84s
2025-08-15 03:20:05,455:INFO:Epoch: 8550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.87s
2025-08-15 03:20:10,304:INFO:Epoch: 8600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.85s
2025-08-15 03:20:17,767:INFO:Epoch: 8650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 7.46s
2025-08-15 03:20:22,591:INFO:Epoch: 8700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.82s
2025-08-15 03:20:27,432:INFO:Epoch: 8750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.84s
2025-08-15 03:20:32,272:INFO:Epoch: 8800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.84s
2025-08-15 03:20:37,106:INFO:Epoch: 8850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.83s
2025-08-15 03:20:44,029:INFO:Epoch: 8900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 6.92s
2025-08-15 03:20:48,909:INFO:Epoch: 8950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.88s
2025-08-15 03:20:53,765:INFO:Epoch: 9000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.86s
2025-08-15 03:20:58,662:INFO:Epoch: 9050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.90s
2025-08-15 03:21:03,527:INFO:Epoch: 9100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.86s
2025-08-15 03:21:11,776:INFO:Epoch: 9150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 8.25s
2025-08-15 03:21:16,549:INFO:Epoch: 9200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.77s
2025-08-15 03:21:21,404:INFO:Epoch: 9250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.85s
2025-08-15 03:21:26,290:INFO:Epoch: 9300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.89s
2025-08-15 03:21:31,146:INFO:Epoch: 9350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.86s
2025-08-15 03:21:39,221:INFO:Epoch: 9400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 8.07s
2025-08-15 03:21:44,002:INFO:Epoch: 9450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.78s
2025-08-15 03:21:48,858:INFO:Epoch: 9500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.86s
2025-08-15 03:21:53,718:INFO:Epoch: 9550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.86s
2025-08-15 03:21:58,501:INFO:Epoch: 9600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.78s
2025-08-15 03:22:09,348:INFO:Epoch: 9650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 10.85s
2025-08-15 03:22:14,154:INFO:Epoch: 9700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.81s
2025-08-15 03:22:18,929:INFO:Epoch: 9750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.77s
2025-08-15 03:22:23,730:INFO:Epoch: 9800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.80s
2025-08-15 03:22:28,510:INFO:Epoch: 9850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.78s
2025-08-15 03:22:38,821:INFO:Epoch: 9900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 10.31s
2025-08-15 03:22:43,619:INFO:Epoch: 9950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.80s
2025-08-15 03:22:48,427:INFO:Epoch: 10000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.81s
