2025-08-15 11:34:42,708:INFO:Created DataLoaders with 2994 training samples and 998 validation samples.
2025-08-15 11:35:01,041:INFO:model params: 479490
2025-08-15 11:35:41,930:INFO:Created DataLoaders with 2994 training samples and 998 validation samples.
2025-08-15 11:35:42,503:INFO:model params: 479490
2025-08-15 11:35:56,571:INFO:Epoch: 0/10000 | Train Loss: 5.094e+00 | Dynamic Loss: 5.094e+00 | Regularization Loss: 6.195e-24 | Val Loss: 3.413e+00 | Time: 14.07s
2025-08-15 11:35:56,571:INFO:New best model found at epoch 0 with validation loss 3.413e+00. Saving...
2025-08-15 11:36:01,832:INFO:Epoch: 50/10000 | Train Loss: 9.023e-01 | Dynamic Loss: 9.023e-01 | Regularization Loss: 2.074e-20 | Val Loss: 9.511e-01 | Time: 4.48s
2025-08-15 11:36:01,832:INFO:New best model found at epoch 50 with validation loss 9.511e-01. Saving...
2025-08-15 11:36:06,218:INFO:Epoch: 100/10000 | Train Loss: 7.129e-01 | Dynamic Loss: 7.129e-01 | Regularization Loss: 1.892e-14 | Val Loss: 7.449e-01 | Time: 4.38s
2025-08-15 11:36:06,218:INFO:New best model found at epoch 100 with validation loss 7.449e-01. Saving...
2025-08-15 11:36:10,799:INFO:Epoch: 150/10000 | Train Loss: 6.419e-01 | Dynamic Loss: 6.419e-01 | Regularization Loss: 2.082e-07 | Val Loss: 6.647e-01 | Time: 4.57s
2025-08-15 11:36:10,801:INFO:New best model found at epoch 150 with validation loss 6.647e-01. Saving...
2025-08-15 11:36:15,238:INFO:Epoch: 200/10000 | Train Loss: 6.087e-01 | Dynamic Loss: 6.086e-01 | Regularization Loss: 6.321e-07 | Val Loss: 6.246e-01 | Time: 4.43s
2025-08-15 11:36:15,238:INFO:New best model found at epoch 200 with validation loss 6.246e-01. Saving...
2025-08-15 11:36:19,625:INFO:Epoch: 250/10000 | Train Loss: 5.900e-01 | Dynamic Loss: 5.900e-01 | Regularization Loss: 6.162e-07 | Val Loss: 6.009e-01 | Time: 4.38s
2025-08-15 11:36:19,625:INFO:New best model found at epoch 250 with validation loss 6.009e-01. Saving...
2025-08-15 11:36:29,183:INFO:Epoch: 300/10000 | Train Loss: 5.803e-01 | Dynamic Loss: 5.803e-01 | Regularization Loss: 5.963e-07 | Val Loss: 5.864e-01 | Time: 9.55s
2025-08-15 11:36:29,183:INFO:New best model found at epoch 300 with validation loss 5.864e-01. Saving...
2025-08-15 11:36:33,648:INFO:Epoch: 350/10000 | Train Loss: 5.717e-01 | Dynamic Loss: 5.717e-01 | Regularization Loss: 5.766e-07 | Val Loss: 5.749e-01 | Time: 4.46s
2025-08-15 11:36:33,648:INFO:New best model found at epoch 350 with validation loss 5.749e-01. Saving...
2025-08-15 11:36:38,059:INFO:Epoch: 400/10000 | Train Loss: 5.636e-01 | Dynamic Loss: 5.636e-01 | Regularization Loss: 5.566e-07 | Val Loss: 5.642e-01 | Time: 4.40s
2025-08-15 11:36:38,059:INFO:New best model found at epoch 400 with validation loss 5.642e-01. Saving...
2025-08-15 11:36:42,418:INFO:Epoch: 450/10000 | Train Loss: 5.583e-01 | Dynamic Loss: 5.583e-01 | Regularization Loss: 5.376e-07 | Val Loss: 5.581e-01 | Time: 4.35s
2025-08-15 11:36:42,418:INFO:New best model found at epoch 450 with validation loss 5.581e-01. Saving...
2025-08-15 11:36:52,322:INFO:Epoch: 500/10000 | Train Loss: 5.562e-01 | Dynamic Loss: 5.562e-01 | Regularization Loss: 5.229e-07 | Val Loss: 5.513e-01 | Time: 9.90s
2025-08-15 11:36:52,322:INFO:New best model found at epoch 500 with validation loss 5.513e-01. Saving...
2025-08-15 11:36:56,756:INFO:Epoch: 550/10000 | Train Loss: 5.532e-01 | Dynamic Loss: 5.532e-01 | Regularization Loss: 5.086e-07 | Val Loss: 5.472e-01 | Time: 4.42s
2025-08-15 11:36:56,756:INFO:New best model found at epoch 550 with validation loss 5.472e-01. Saving...
2025-08-15 11:37:01,219:INFO:Epoch: 600/10000 | Train Loss: 5.500e-01 | Dynamic Loss: 5.500e-01 | Regularization Loss: 4.920e-07 | Val Loss: 5.401e-01 | Time: 4.45s
2025-08-15 11:37:01,220:INFO:New best model found at epoch 600 with validation loss 5.401e-01. Saving...
2025-08-15 11:37:05,670:INFO:Epoch: 650/10000 | Train Loss: 5.428e-01 | Dynamic Loss: 5.428e-01 | Regularization Loss: 4.776e-07 | Val Loss: 5.353e-01 | Time: 4.44s
2025-08-15 11:37:05,671:INFO:New best model found at epoch 650 with validation loss 5.353e-01. Saving...
2025-08-15 11:37:10,303:INFO:Epoch: 700/10000 | Train Loss: 5.407e-01 | Dynamic Loss: 5.407e-01 | Regularization Loss: 4.639e-07 | Val Loss: 5.311e-01 | Time: 4.62s
2025-08-15 11:37:10,303:INFO:New best model found at epoch 700 with validation loss 5.311e-01. Saving...
2025-08-15 11:37:14,801:INFO:Epoch: 750/10000 | Train Loss: 5.354e-01 | Dynamic Loss: 5.354e-01 | Regularization Loss: 4.494e-07 | Val Loss: 5.260e-01 | Time: 4.49s
2025-08-15 11:37:14,801:INFO:New best model found at epoch 750 with validation loss 5.260e-01. Saving...
2025-08-15 11:37:19,345:INFO:Epoch: 800/10000 | Train Loss: 5.333e-01 | Dynamic Loss: 5.333e-01 | Regularization Loss: 4.386e-07 | Val Loss: 5.233e-01 | Time: 4.53s
2025-08-15 11:37:19,345:INFO:New best model found at epoch 800 with validation loss 5.233e-01. Saving...
2025-08-15 11:37:23,792:INFO:Epoch: 850/10000 | Train Loss: 5.307e-01 | Dynamic Loss: 5.307e-01 | Regularization Loss: 4.276e-07 | Val Loss: 5.193e-01 | Time: 4.44s
2025-08-15 11:37:23,792:INFO:New best model found at epoch 850 with validation loss 5.193e-01. Saving...
2025-08-15 11:37:28,226:INFO:Epoch: 900/10000 | Train Loss: 5.255e-01 | Dynamic Loss: 5.255e-01 | Regularization Loss: 4.167e-07 | Val Loss: 5.165e-01 | Time: 4.42s
2025-08-15 11:37:28,226:INFO:New best model found at epoch 900 with validation loss 5.165e-01. Saving...
2025-08-15 11:37:38,331:INFO:Epoch: 950/10000 | Train Loss: 5.230e-01 | Dynamic Loss: 5.230e-01 | Regularization Loss: 4.055e-07 | Val Loss: 5.135e-01 | Time: 10.10s
2025-08-15 11:37:38,331:INFO:New best model found at epoch 950 with validation loss 5.135e-01. Saving...
2025-08-15 11:37:42,839:INFO:Epoch: 1000/10000 | Train Loss: 5.215e-01 | Dynamic Loss: 5.215e-01 | Regularization Loss: 3.958e-07 | Val Loss: 5.096e-01 | Time: 4.50s
2025-08-15 11:37:42,840:INFO:New best model found at epoch 1000 with validation loss 5.096e-01. Saving...
2025-08-15 11:37:47,703:INFO:Epoch: 1050/10000 | Train Loss: 5.192e-01 | Dynamic Loss: 5.192e-01 | Regularization Loss: 3.842e-07 | Val Loss: 5.068e-01 | Time: 4.85s
2025-08-15 11:37:47,703:INFO:New best model found at epoch 1050 with validation loss 5.068e-01. Saving...
2025-08-15 11:37:52,138:INFO:Epoch: 1100/10000 | Train Loss: 5.151e-01 | Dynamic Loss: 5.151e-01 | Regularization Loss: 3.767e-07 | Val Loss: 5.045e-01 | Time: 4.43s
2025-08-15 11:37:52,138:INFO:New best model found at epoch 1100 with validation loss 5.045e-01. Saving...
2025-08-15 11:37:58,056:INFO:Epoch: 1150/10000 | Train Loss: 5.117e-01 | Dynamic Loss: 5.117e-01 | Regularization Loss: 3.671e-07 | Val Loss: 5.026e-01 | Time: 5.91s
2025-08-15 11:37:58,056:INFO:New best model found at epoch 1150 with validation loss 5.026e-01. Saving...
2025-08-15 11:38:02,554:INFO:Epoch: 1200/10000 | Train Loss: 5.103e-01 | Dynamic Loss: 5.103e-01 | Regularization Loss: 3.605e-07 | Val Loss: 4.985e-01 | Time: 4.49s
2025-08-15 11:38:02,554:INFO:New best model found at epoch 1200 with validation loss 4.985e-01. Saving...
2025-08-15 11:38:07,574:INFO:Epoch: 1250/10000 | Train Loss: 5.079e-01 | Dynamic Loss: 5.079e-01 | Regularization Loss: 3.540e-07 | Val Loss: 4.968e-01 | Time: 5.01s
2025-08-15 11:38:07,574:INFO:New best model found at epoch 1250 with validation loss 4.968e-01. Saving...
2025-08-15 11:38:12,139:INFO:Epoch: 1300/10000 | Train Loss: 5.066e-01 | Dynamic Loss: 5.066e-01 | Regularization Loss: 3.453e-07 | Val Loss: 4.957e-01 | Time: 4.56s
2025-08-15 11:38:12,139:INFO:New best model found at epoch 1300 with validation loss 4.957e-01. Saving...
2025-08-15 11:38:17,002:INFO:Epoch: 1350/10000 | Train Loss: 5.041e-01 | Dynamic Loss: 5.041e-01 | Regularization Loss: 3.397e-07 | Val Loss: 4.933e-01 | Time: 4.85s
2025-08-15 11:38:17,002:INFO:New best model found at epoch 1350 with validation loss 4.933e-01. Saving...
2025-08-15 11:38:21,454:INFO:Epoch: 1400/10000 | Train Loss: 4.997e-01 | Dynamic Loss: 4.997e-01 | Regularization Loss: 3.314e-07 | Val Loss: 4.896e-01 | Time: 4.44s
2025-08-15 11:38:21,454:INFO:New best model found at epoch 1400 with validation loss 4.896e-01. Saving...
2025-08-15 11:38:26,403:INFO:Epoch: 1450/10000 | Train Loss: 4.996e-01 | Dynamic Loss: 4.996e-01 | Regularization Loss: 3.255e-07 | Val Loss: 4.873e-01 | Time: 4.94s
2025-08-15 11:38:26,403:INFO:New best model found at epoch 1450 with validation loss 4.873e-01. Saving...
2025-08-15 11:38:30,945:INFO:Epoch: 1500/10000 | Train Loss: 4.975e-01 | Dynamic Loss: 4.975e-01 | Regularization Loss: 3.184e-07 | Val Loss: 4.860e-01 | Time: 4.53s
2025-08-15 11:38:30,945:INFO:New best model found at epoch 1500 with validation loss 4.860e-01. Saving...
2025-08-15 11:38:36,319:INFO:Epoch: 1550/10000 | Train Loss: 4.945e-01 | Dynamic Loss: 4.945e-01 | Regularization Loss: 3.146e-07 | Val Loss: 4.832e-01 | Time: 5.36s
2025-08-15 11:38:36,319:INFO:New best model found at epoch 1550 with validation loss 4.832e-01. Saving...
2025-08-15 11:38:40,900:INFO:Epoch: 1600/10000 | Train Loss: 4.932e-01 | Dynamic Loss: 4.932e-01 | Regularization Loss: 3.085e-07 | Val Loss: 4.812e-01 | Time: 4.57s
2025-08-15 11:38:40,901:INFO:New best model found at epoch 1600 with validation loss 4.812e-01. Saving...
2025-08-15 11:38:45,432:INFO:Epoch: 1650/10000 | Train Loss: 4.913e-01 | Dynamic Loss: 4.913e-01 | Regularization Loss: 3.036e-07 | Val Loss: 4.799e-01 | Time: 4.52s
2025-08-15 11:38:45,433:INFO:New best model found at epoch 1650 with validation loss 4.799e-01. Saving...
2025-08-15 11:38:49,961:INFO:Epoch: 1700/10000 | Train Loss: 4.917e-01 | Dynamic Loss: 4.917e-01 | Regularization Loss: 2.980e-07 | Val Loss: 4.792e-01 | Time: 4.52s
2025-08-15 11:38:49,961:INFO:New best model found at epoch 1700 with validation loss 4.792e-01. Saving...
2025-08-15 11:38:54,464:INFO:Epoch: 1750/10000 | Train Loss: 4.906e-01 | Dynamic Loss: 4.906e-01 | Regularization Loss: 2.928e-07 | Val Loss: 4.782e-01 | Time: 4.49s
2025-08-15 11:38:54,464:INFO:New best model found at epoch 1750 with validation loss 4.782e-01. Saving...
2025-08-15 11:39:03,371:INFO:Epoch: 1800/10000 | Train Loss: 4.866e-01 | Dynamic Loss: 4.866e-01 | Regularization Loss: 2.890e-07 | Val Loss: 4.755e-01 | Time: 8.90s
2025-08-15 11:39:03,371:INFO:New best model found at epoch 1800 with validation loss 4.755e-01. Saving...
2025-08-15 11:39:07,916:INFO:Epoch: 1850/10000 | Train Loss: 4.845e-01 | Dynamic Loss: 4.845e-01 | Regularization Loss: 2.838e-07 | Val Loss: 4.744e-01 | Time: 4.54s
2025-08-15 11:39:07,916:INFO:New best model found at epoch 1850 with validation loss 4.744e-01. Saving...
2025-08-15 11:39:12,430:INFO:Epoch: 1900/10000 | Train Loss: 4.826e-01 | Dynamic Loss: 4.826e-01 | Regularization Loss: 2.791e-07 | Val Loss: 4.728e-01 | Time: 4.51s
2025-08-15 11:39:12,430:INFO:New best model found at epoch 1900 with validation loss 4.728e-01. Saving...
2025-08-15 11:39:16,958:INFO:Epoch: 1950/10000 | Train Loss: 4.810e-01 | Dynamic Loss: 4.810e-01 | Regularization Loss: 2.724e-07 | Val Loss: 4.703e-01 | Time: 4.52s
2025-08-15 11:39:16,958:INFO:New best model found at epoch 1950 with validation loss 4.703e-01. Saving...
2025-08-15 11:39:25,502:INFO:Epoch: 2000/10000 | Train Loss: 4.788e-01 | Dynamic Loss: 4.788e-01 | Regularization Loss: 2.686e-07 | Val Loss: 4.698e-01 | Time: 8.54s
2025-08-15 11:39:25,502:INFO:New best model found at epoch 2000 with validation loss 4.698e-01. Saving...
2025-08-15 11:39:30,038:INFO:Epoch: 2050/10000 | Train Loss: 4.777e-01 | Dynamic Loss: 4.777e-01 | Regularization Loss: 2.649e-07 | Val Loss: 4.699e-01 | Time: 4.53s
2025-08-15 11:39:34,550:INFO:Epoch: 2100/10000 | Train Loss: 4.758e-01 | Dynamic Loss: 4.758e-01 | Regularization Loss: 2.599e-07 | Val Loss: 4.687e-01 | Time: 4.51s
2025-08-15 11:39:34,550:INFO:New best model found at epoch 2100 with validation loss 4.687e-01. Saving...
2025-08-15 11:39:39,071:INFO:Epoch: 2150/10000 | Train Loss: 4.730e-01 | Dynamic Loss: 4.730e-01 | Regularization Loss: 2.535e-07 | Val Loss: 4.645e-01 | Time: 4.51s
2025-08-15 11:39:39,071:INFO:New best model found at epoch 2150 with validation loss 4.645e-01. Saving...
2025-08-15 11:39:43,541:INFO:Epoch: 2200/10000 | Train Loss: 4.708e-01 | Dynamic Loss: 4.708e-01 | Regularization Loss: 2.492e-07 | Val Loss: 4.650e-01 | Time: 4.46s
2025-08-15 11:39:53,865:INFO:Epoch: 2250/10000 | Train Loss: 4.671e-01 | Dynamic Loss: 4.671e-01 | Regularization Loss: 2.432e-07 | Val Loss: 4.627e-01 | Time: 10.32s
2025-08-15 11:39:53,866:INFO:New best model found at epoch 2250 with validation loss 4.627e-01. Saving...
2025-08-15 11:39:58,386:INFO:Epoch: 2300/10000 | Train Loss: 4.668e-01 | Dynamic Loss: 4.668e-01 | Regularization Loss: 2.394e-07 | Val Loss: 4.617e-01 | Time: 4.51s
2025-08-15 11:39:58,386:INFO:New best model found at epoch 2300 with validation loss 4.617e-01. Saving...
2025-08-15 11:40:02,903:INFO:Epoch: 2350/10000 | Train Loss: 4.641e-01 | Dynamic Loss: 4.641e-01 | Regularization Loss: 2.347e-07 | Val Loss: 4.603e-01 | Time: 4.51s
2025-08-15 11:40:02,903:INFO:New best model found at epoch 2350 with validation loss 4.603e-01. Saving...
2025-08-15 11:40:07,919:INFO:Epoch: 2400/10000 | Train Loss: 4.633e-01 | Dynamic Loss: 4.633e-01 | Regularization Loss: 2.316e-07 | Val Loss: 4.569e-01 | Time: 5.01s
2025-08-15 11:40:07,919:INFO:New best model found at epoch 2400 with validation loss 4.569e-01. Saving...
2025-08-15 11:40:13,039:INFO:Epoch: 2450/10000 | Train Loss: 4.619e-01 | Dynamic Loss: 4.619e-01 | Regularization Loss: 2.303e-07 | Val Loss: 4.561e-01 | Time: 5.11s
2025-08-15 11:40:13,039:INFO:New best model found at epoch 2450 with validation loss 4.561e-01. Saving...
2025-08-15 11:40:17,569:INFO:Epoch: 2500/10000 | Train Loss: 4.606e-01 | Dynamic Loss: 4.606e-01 | Regularization Loss: 2.265e-07 | Val Loss: 4.547e-01 | Time: 4.52s
2025-08-15 11:40:17,570:INFO:New best model found at epoch 2500 with validation loss 4.547e-01. Saving...
2025-08-15 11:40:22,129:INFO:Epoch: 2550/10000 | Train Loss: 4.585e-01 | Dynamic Loss: 4.585e-01 | Regularization Loss: 2.242e-07 | Val Loss: 4.547e-01 | Time: 4.55s
2025-08-15 11:40:22,129:INFO:New best model found at epoch 2550 with validation loss 4.547e-01. Saving...
2025-08-15 11:40:26,682:INFO:Epoch: 2600/10000 | Train Loss: 4.585e-01 | Dynamic Loss: 4.585e-01 | Regularization Loss: 2.213e-07 | Val Loss: 4.535e-01 | Time: 4.54s
2025-08-15 11:40:26,682:INFO:New best model found at epoch 2600 with validation loss 4.535e-01. Saving...
2025-08-15 11:40:31,223:INFO:Epoch: 2650/10000 | Train Loss: 4.581e-01 | Dynamic Loss: 4.581e-01 | Regularization Loss: 2.198e-07 | Val Loss: 4.534e-01 | Time: 4.53s
2025-08-15 11:40:31,223:INFO:New best model found at epoch 2650 with validation loss 4.534e-01. Saving...
2025-08-15 11:40:38,555:INFO:Epoch: 2700/10000 | Train Loss: 4.577e-01 | Dynamic Loss: 4.577e-01 | Regularization Loss: 2.182e-07 | Val Loss: 4.514e-01 | Time: 7.32s
2025-08-15 11:40:38,555:INFO:New best model found at epoch 2700 with validation loss 4.514e-01. Saving...
2025-08-15 11:40:43,060:INFO:Epoch: 2750/10000 | Train Loss: 4.543e-01 | Dynamic Loss: 4.543e-01 | Regularization Loss: 2.149e-07 | Val Loss: 4.511e-01 | Time: 4.50s
2025-08-15 11:40:43,060:INFO:New best model found at epoch 2750 with validation loss 4.511e-01. Saving...
2025-08-15 11:40:47,599:INFO:Epoch: 2800/10000 | Train Loss: 4.536e-01 | Dynamic Loss: 4.536e-01 | Regularization Loss: 2.135e-07 | Val Loss: 4.495e-01 | Time: 4.53s
2025-08-15 11:40:47,600:INFO:New best model found at epoch 2800 with validation loss 4.495e-01. Saving...
2025-08-15 11:40:52,089:INFO:Epoch: 2850/10000 | Train Loss: 4.527e-01 | Dynamic Loss: 4.527e-01 | Regularization Loss: 2.097e-07 | Val Loss: 4.501e-01 | Time: 4.48s
2025-08-15 11:40:56,613:INFO:Epoch: 2900/10000 | Train Loss: 4.519e-01 | Dynamic Loss: 4.519e-01 | Regularization Loss: 2.082e-07 | Val Loss: 4.491e-01 | Time: 4.52s
2025-08-15 11:40:56,613:INFO:New best model found at epoch 2900 with validation loss 4.491e-01. Saving...
2025-08-15 11:41:05,494:INFO:Epoch: 2950/10000 | Train Loss: 4.521e-01 | Dynamic Loss: 4.521e-01 | Regularization Loss: 2.054e-07 | Val Loss: 4.477e-01 | Time: 8.87s
2025-08-15 11:41:05,494:INFO:New best model found at epoch 2950 with validation loss 4.477e-01. Saving...
2025-08-15 11:41:10,025:INFO:Epoch: 3000/10000 | Train Loss: 4.503e-01 | Dynamic Loss: 4.503e-01 | Regularization Loss: 2.022e-07 | Val Loss: 4.464e-01 | Time: 4.52s
2025-08-15 11:41:10,026:INFO:New best model found at epoch 3000 with validation loss 4.464e-01. Saving...
2025-08-15 11:41:14,588:INFO:Epoch: 3050/10000 | Train Loss: 4.487e-01 | Dynamic Loss: 4.487e-01 | Regularization Loss: 2.007e-07 | Val Loss: 4.461e-01 | Time: 4.55s
2025-08-15 11:41:14,588:INFO:New best model found at epoch 3050 with validation loss 4.461e-01. Saving...
2025-08-15 11:41:19,059:INFO:Epoch: 3100/10000 | Train Loss: 4.474e-01 | Dynamic Loss: 4.474e-01 | Regularization Loss: 1.980e-07 | Val Loss: 4.449e-01 | Time: 4.46s
2025-08-15 11:41:19,059:INFO:New best model found at epoch 3100 with validation loss 4.449e-01. Saving...
2025-08-15 11:41:23,624:INFO:Epoch: 3150/10000 | Train Loss: 4.479e-01 | Dynamic Loss: 4.479e-01 | Regularization Loss: 1.968e-07 | Val Loss: 4.436e-01 | Time: 4.55s
2025-08-15 11:41:23,624:INFO:New best model found at epoch 3150 with validation loss 4.436e-01. Saving...
2025-08-15 11:41:34,038:INFO:Epoch: 3200/10000 | Train Loss: 4.460e-01 | Dynamic Loss: 4.460e-01 | Regularization Loss: 1.940e-07 | Val Loss: 4.422e-01 | Time: 10.40s
2025-08-15 11:41:34,038:INFO:New best model found at epoch 3200 with validation loss 4.422e-01. Saving...
2025-08-15 11:41:38,621:INFO:Epoch: 3250/10000 | Train Loss: 4.444e-01 | Dynamic Loss: 4.444e-01 | Regularization Loss: 1.927e-07 | Val Loss: 4.427e-01 | Time: 4.57s
2025-08-15 11:41:43,245:INFO:Epoch: 3300/10000 | Train Loss: 4.429e-01 | Dynamic Loss: 4.429e-01 | Regularization Loss: 1.909e-07 | Val Loss: 4.414e-01 | Time: 4.62s
2025-08-15 11:41:43,245:INFO:New best model found at epoch 3300 with validation loss 4.414e-01. Saving...
2025-08-15 11:41:47,838:INFO:Epoch: 3350/10000 | Train Loss: 4.421e-01 | Dynamic Loss: 4.421e-01 | Regularization Loss: 1.882e-07 | Val Loss: 4.402e-01 | Time: 4.57s
2025-08-15 11:41:47,838:INFO:New best model found at epoch 3350 with validation loss 4.402e-01. Saving...
2025-08-15 11:41:56,067:INFO:Epoch: 3400/10000 | Train Loss: 4.419e-01 | Dynamic Loss: 4.419e-01 | Regularization Loss: 1.871e-07 | Val Loss: 4.395e-01 | Time: 8.22s
2025-08-15 11:41:56,068:INFO:New best model found at epoch 3400 with validation loss 4.395e-01. Saving...
2025-08-15 11:42:00,660:INFO:Epoch: 3450/10000 | Train Loss: 4.418e-01 | Dynamic Loss: 4.418e-01 | Regularization Loss: 1.851e-07 | Val Loss: 4.403e-01 | Time: 4.58s
2025-08-15 11:42:05,211:INFO:Epoch: 3500/10000 | Train Loss: 4.411e-01 | Dynamic Loss: 4.411e-01 | Regularization Loss: 1.847e-07 | Val Loss: 4.384e-01 | Time: 4.55s
2025-08-15 11:42:05,211:INFO:New best model found at epoch 3500 with validation loss 4.384e-01. Saving...
2025-08-15 11:42:10,149:INFO:Epoch: 3550/10000 | Train Loss: 4.406e-01 | Dynamic Loss: 4.406e-01 | Regularization Loss: 1.836e-07 | Val Loss: 4.381e-01 | Time: 4.93s
2025-08-15 11:42:10,150:INFO:New best model found at epoch 3550 with validation loss 4.381e-01. Saving...
2025-08-15 11:42:14,662:INFO:Epoch: 3600/10000 | Train Loss: 4.396e-01 | Dynamic Loss: 4.396e-01 | Regularization Loss: 1.820e-07 | Val Loss: 4.384e-01 | Time: 4.50s
2025-08-15 11:42:24,199:INFO:Epoch: 3650/10000 | Train Loss: 4.389e-01 | Dynamic Loss: 4.389e-01 | Regularization Loss: 1.805e-07 | Val Loss: 4.381e-01 | Time: 9.54s
2025-08-15 11:42:28,754:INFO:Epoch: 3700/10000 | Train Loss: 4.380e-01 | Dynamic Loss: 4.380e-01 | Regularization Loss: 1.795e-07 | Val Loss: 4.372e-01 | Time: 4.56s
2025-08-15 11:42:28,754:INFO:New best model found at epoch 3700 with validation loss 4.372e-01. Saving...
2025-08-15 11:42:33,497:INFO:Epoch: 3750/10000 | Train Loss: 4.374e-01 | Dynamic Loss: 4.374e-01 | Regularization Loss: 1.776e-07 | Val Loss: 4.371e-01 | Time: 4.73s
2025-08-15 11:42:33,497:INFO:New best model found at epoch 3750 with validation loss 4.371e-01. Saving...
2025-08-15 11:42:38,021:INFO:Epoch: 3800/10000 | Train Loss: 4.382e-01 | Dynamic Loss: 4.382e-01 | Regularization Loss: 1.768e-07 | Val Loss: 4.364e-01 | Time: 4.52s
2025-08-15 11:42:38,021:INFO:New best model found at epoch 3800 with validation loss 4.364e-01. Saving...
2025-08-15 11:42:42,687:INFO:Epoch: 3850/10000 | Train Loss: 4.366e-01 | Dynamic Loss: 4.366e-01 | Regularization Loss: 1.749e-07 | Val Loss: 4.351e-01 | Time: 4.66s
2025-08-15 11:42:42,687:INFO:New best model found at epoch 3850 with validation loss 4.351e-01. Saving...
2025-08-15 11:42:47,363:INFO:Epoch: 3900/10000 | Train Loss: 4.350e-01 | Dynamic Loss: 4.350e-01 | Regularization Loss: 1.730e-07 | Val Loss: 4.361e-01 | Time: 4.67s
2025-08-15 11:42:52,018:INFO:Epoch: 3950/10000 | Train Loss: 4.342e-01 | Dynamic Loss: 4.342e-01 | Regularization Loss: 1.715e-07 | Val Loss: 4.332e-01 | Time: 4.65s
2025-08-15 11:42:52,018:INFO:New best model found at epoch 3950 with validation loss 4.332e-01. Saving...
2025-08-15 11:42:56,668:INFO:Epoch: 4000/10000 | Train Loss: 4.320e-01 | Dynamic Loss: 4.320e-01 | Regularization Loss: 1.696e-07 | Val Loss: 4.326e-01 | Time: 4.64s
2025-08-15 11:42:56,668:INFO:New best model found at epoch 4000 with validation loss 4.326e-01. Saving...
2025-08-15 11:43:01,261:INFO:Epoch: 4050/10000 | Train Loss: 4.313e-01 | Dynamic Loss: 4.313e-01 | Regularization Loss: 1.675e-07 | Val Loss: 4.306e-01 | Time: 4.58s
2025-08-15 11:43:01,262:INFO:New best model found at epoch 4050 with validation loss 4.306e-01. Saving...
2025-08-15 11:43:10,229:INFO:Epoch: 4100/10000 | Train Loss: 4.281e-01 | Dynamic Loss: 4.281e-01 | Regularization Loss: 1.650e-07 | Val Loss: 4.296e-01 | Time: 8.96s
2025-08-15 11:43:10,229:INFO:New best model found at epoch 4100 with validation loss 4.296e-01. Saving...
2025-08-15 11:43:14,808:INFO:Epoch: 4150/10000 | Train Loss: 4.273e-01 | Dynamic Loss: 4.273e-01 | Regularization Loss: 1.638e-07 | Val Loss: 4.282e-01 | Time: 4.57s
2025-08-15 11:43:14,808:INFO:New best model found at epoch 4150 with validation loss 4.282e-01. Saving...
2025-08-15 11:43:19,435:INFO:Epoch: 4200/10000 | Train Loss: 4.281e-01 | Dynamic Loss: 4.281e-01 | Regularization Loss: 1.608e-07 | Val Loss: 4.282e-01 | Time: 4.62s
2025-08-15 11:43:19,436:INFO:New best model found at epoch 4200 with validation loss 4.282e-01. Saving...
2025-08-15 11:43:24,012:INFO:Epoch: 4250/10000 | Train Loss: 4.251e-01 | Dynamic Loss: 4.251e-01 | Regularization Loss: 1.594e-07 | Val Loss: 4.267e-01 | Time: 4.57s
2025-08-15 11:43:24,012:INFO:New best model found at epoch 4250 with validation loss 4.267e-01. Saving...
2025-08-15 11:43:28,566:INFO:Epoch: 4300/10000 | Train Loss: 4.243e-01 | Dynamic Loss: 4.243e-01 | Regularization Loss: 1.572e-07 | Val Loss: 4.265e-01 | Time: 4.54s
2025-08-15 11:43:28,566:INFO:New best model found at epoch 4300 with validation loss 4.265e-01. Saving...
2025-08-15 11:43:37,342:INFO:Epoch: 4350/10000 | Train Loss: 4.227e-01 | Dynamic Loss: 4.227e-01 | Regularization Loss: 1.563e-07 | Val Loss: 4.259e-01 | Time: 8.77s
2025-08-15 11:43:37,342:INFO:New best model found at epoch 4350 with validation loss 4.259e-01. Saving...
2025-08-15 11:43:42,022:INFO:Epoch: 4400/10000 | Train Loss: 4.225e-01 | Dynamic Loss: 4.225e-01 | Regularization Loss: 1.558e-07 | Val Loss: 4.249e-01 | Time: 4.67s
2025-08-15 11:43:42,023:INFO:New best model found at epoch 4400 with validation loss 4.249e-01. Saving...
2025-08-15 11:43:46,685:INFO:Epoch: 4450/10000 | Train Loss: 4.222e-01 | Dynamic Loss: 4.222e-01 | Regularization Loss: 1.547e-07 | Val Loss: 4.253e-01 | Time: 4.65s
2025-08-15 11:43:51,199:INFO:Epoch: 4500/10000 | Train Loss: 4.217e-01 | Dynamic Loss: 4.217e-01 | Regularization Loss: 1.530e-07 | Val Loss: 4.264e-01 | Time: 4.51s
2025-08-15 11:43:55,741:INFO:Epoch: 4550/10000 | Train Loss: 4.217e-01 | Dynamic Loss: 4.217e-01 | Regularization Loss: 1.516e-07 | Val Loss: 4.241e-01 | Time: 4.54s
2025-08-15 11:43:55,741:INFO:New best model found at epoch 4550 with validation loss 4.241e-01. Saving...
2025-08-15 11:44:03,304:INFO:Epoch: 4600/10000 | Train Loss: 4.188e-01 | Dynamic Loss: 4.188e-01 | Regularization Loss: 1.504e-07 | Val Loss: 4.233e-01 | Time: 7.55s
2025-08-15 11:44:03,304:INFO:New best model found at epoch 4600 with validation loss 4.233e-01. Saving...
2025-08-15 11:44:07,910:INFO:Epoch: 4650/10000 | Train Loss: 4.190e-01 | Dynamic Loss: 4.190e-01 | Regularization Loss: 1.498e-07 | Val Loss: 4.230e-01 | Time: 4.60s
2025-08-15 11:44:07,910:INFO:New best model found at epoch 4650 with validation loss 4.230e-01. Saving...
2025-08-15 11:44:12,547:INFO:Epoch: 4700/10000 | Train Loss: 4.189e-01 | Dynamic Loss: 4.189e-01 | Regularization Loss: 1.497e-07 | Val Loss: 4.225e-01 | Time: 4.63s
2025-08-15 11:44:12,547:INFO:New best model found at epoch 4700 with validation loss 4.225e-01. Saving...
2025-08-15 11:44:17,091:INFO:Epoch: 4750/10000 | Train Loss: 4.199e-01 | Dynamic Loss: 4.199e-01 | Regularization Loss: 1.483e-07 | Val Loss: 4.224e-01 | Time: 4.53s
2025-08-15 11:44:17,091:INFO:New best model found at epoch 4750 with validation loss 4.224e-01. Saving...
2025-08-15 11:44:21,681:INFO:Epoch: 4800/10000 | Train Loss: 4.189e-01 | Dynamic Loss: 4.189e-01 | Regularization Loss: 1.475e-07 | Val Loss: 4.229e-01 | Time: 4.58s
2025-08-15 11:44:29,719:INFO:Epoch: 4850/10000 | Train Loss: 4.173e-01 | Dynamic Loss: 4.173e-01 | Regularization Loss: 1.458e-07 | Val Loss: 4.215e-01 | Time: 8.04s
2025-08-15 11:44:29,719:INFO:New best model found at epoch 4850 with validation loss 4.215e-01. Saving...
2025-08-15 11:44:34,354:INFO:Epoch: 4900/10000 | Train Loss: 4.156e-01 | Dynamic Loss: 4.156e-01 | Regularization Loss: 1.449e-07 | Val Loss: 4.222e-01 | Time: 4.63s
2025-08-15 11:44:39,003:INFO:Epoch: 4950/10000 | Train Loss: 4.160e-01 | Dynamic Loss: 4.160e-01 | Regularization Loss: 1.429e-07 | Val Loss: 4.208e-01 | Time: 4.65s
2025-08-15 11:44:39,005:INFO:New best model found at epoch 4950 with validation loss 4.208e-01. Saving...
2025-08-15 11:44:43,591:INFO:Epoch: 5000/10000 | Train Loss: 4.147e-01 | Dynamic Loss: 4.147e-01 | Regularization Loss: 1.429e-07 | Val Loss: 4.207e-01 | Time: 4.58s
2025-08-15 11:44:43,591:INFO:New best model found at epoch 5000 with validation loss 4.207e-01. Saving...
2025-08-15 11:44:48,196:INFO:Epoch: 5050/10000 | Train Loss: 4.144e-01 | Dynamic Loss: 4.144e-01 | Regularization Loss: 1.420e-07 | Val Loss: 4.198e-01 | Time: 4.59s
2025-08-15 11:44:48,196:INFO:New best model found at epoch 5050 with validation loss 4.198e-01. Saving...
2025-08-15 11:44:56,464:INFO:Epoch: 5100/10000 | Train Loss: 4.131e-01 | Dynamic Loss: 4.131e-01 | Regularization Loss: 1.412e-07 | Val Loss: 4.186e-01 | Time: 8.26s
2025-08-15 11:44:56,464:INFO:New best model found at epoch 5100 with validation loss 4.186e-01. Saving...
2025-08-15 11:45:01,065:INFO:Epoch: 5150/10000 | Train Loss: 4.119e-01 | Dynamic Loss: 4.119e-01 | Regularization Loss: 1.385e-07 | Val Loss: 4.162e-01 | Time: 4.59s
2025-08-15 11:45:01,065:INFO:New best model found at epoch 5150 with validation loss 4.162e-01. Saving...
2025-08-15 11:45:05,697:INFO:Epoch: 5200/10000 | Train Loss: 4.086e-01 | Dynamic Loss: 4.086e-01 | Regularization Loss: 1.370e-07 | Val Loss: 4.156e-01 | Time: 4.62s
2025-08-15 11:45:05,697:INFO:New best model found at epoch 5200 with validation loss 4.156e-01. Saving...
2025-08-15 11:45:10,319:INFO:Epoch: 5250/10000 | Train Loss: 4.101e-01 | Dynamic Loss: 4.101e-01 | Regularization Loss: 1.355e-07 | Val Loss: 4.142e-01 | Time: 4.61s
2025-08-15 11:45:10,319:INFO:New best model found at epoch 5250 with validation loss 4.142e-01. Saving...
2025-08-15 11:45:14,941:INFO:Epoch: 5300/10000 | Train Loss: 4.092e-01 | Dynamic Loss: 4.092e-01 | Regularization Loss: 1.351e-07 | Val Loss: 4.142e-01 | Time: 4.61s
2025-08-15 11:45:25,009:INFO:Epoch: 5350/10000 | Train Loss: 4.070e-01 | Dynamic Loss: 4.070e-01 | Regularization Loss: 1.331e-07 | Val Loss: 4.133e-01 | Time: 10.07s
2025-08-15 11:45:25,009:INFO:New best model found at epoch 5350 with validation loss 4.133e-01. Saving...
2025-08-15 11:45:29,629:INFO:Epoch: 5400/10000 | Train Loss: 4.054e-01 | Dynamic Loss: 4.054e-01 | Regularization Loss: 1.333e-07 | Val Loss: 4.120e-01 | Time: 4.61s
2025-08-15 11:45:29,629:INFO:New best model found at epoch 5400 with validation loss 4.120e-01. Saving...
2025-08-15 11:45:34,227:INFO:Epoch: 5450/10000 | Train Loss: 4.055e-01 | Dynamic Loss: 4.055e-01 | Regularization Loss: 1.324e-07 | Val Loss: 4.116e-01 | Time: 4.59s
2025-08-15 11:45:34,227:INFO:New best model found at epoch 5450 with validation loss 4.116e-01. Saving...
2025-08-15 11:45:38,890:INFO:Epoch: 5500/10000 | Train Loss: 4.065e-01 | Dynamic Loss: 4.065e-01 | Regularization Loss: 1.316e-07 | Val Loss: 4.116e-01 | Time: 4.65s
2025-08-15 11:45:43,836:INFO:Epoch: 5550/10000 | Train Loss: 4.037e-01 | Dynamic Loss: 4.037e-01 | Regularization Loss: 1.289e-07 | Val Loss: 4.103e-01 | Time: 4.95s
2025-08-15 11:45:43,836:INFO:New best model found at epoch 5550 with validation loss 4.103e-01. Saving...
2025-08-15 11:45:48,470:INFO:Epoch: 5600/10000 | Train Loss: 4.046e-01 | Dynamic Loss: 4.046e-01 | Regularization Loss: 1.285e-07 | Val Loss: 4.097e-01 | Time: 4.62s
2025-08-15 11:45:48,470:INFO:New best model found at epoch 5600 with validation loss 4.097e-01. Saving...
2025-08-15 11:45:53,103:INFO:Epoch: 5650/10000 | Train Loss: 4.017e-01 | Dynamic Loss: 4.017e-01 | Regularization Loss: 1.297e-07 | Val Loss: 4.095e-01 | Time: 4.62s
2025-08-15 11:45:53,103:INFO:New best model found at epoch 5650 with validation loss 4.095e-01. Saving...
2025-08-15 11:45:57,653:INFO:Epoch: 5700/10000 | Train Loss: 4.027e-01 | Dynamic Loss: 4.027e-01 | Regularization Loss: 1.279e-07 | Val Loss: 4.092e-01 | Time: 4.54s
2025-08-15 11:45:57,653:INFO:New best model found at epoch 5700 with validation loss 4.092e-01. Saving...
2025-08-15 11:46:02,202:INFO:Epoch: 5750/10000 | Train Loss: 4.011e-01 | Dynamic Loss: 4.011e-01 | Regularization Loss: 1.246e-07 | Val Loss: 4.087e-01 | Time: 4.54s
2025-08-15 11:46:02,203:INFO:New best model found at epoch 5750 with validation loss 4.087e-01. Saving...
2025-08-15 11:46:12,404:INFO:Epoch: 5800/10000 | Train Loss: 4.007e-01 | Dynamic Loss: 4.007e-01 | Regularization Loss: 1.258e-07 | Val Loss: 4.086e-01 | Time: 10.19s
2025-08-15 11:46:12,406:INFO:New best model found at epoch 5800 with validation loss 4.086e-01. Saving...
2025-08-15 11:46:16,997:INFO:Epoch: 5850/10000 | Train Loss: 4.003e-01 | Dynamic Loss: 4.003e-01 | Regularization Loss: 1.250e-07 | Val Loss: 4.098e-01 | Time: 4.58s
2025-08-15 11:46:21,691:INFO:Epoch: 5900/10000 | Train Loss: 3.978e-01 | Dynamic Loss: 3.978e-01 | Regularization Loss: 1.224e-07 | Val Loss: 4.073e-01 | Time: 4.69s
2025-08-15 11:46:21,691:INFO:New best model found at epoch 5900 with validation loss 4.073e-01. Saving...
2025-08-15 11:46:26,414:INFO:Epoch: 5950/10000 | Train Loss: 3.980e-01 | Dynamic Loss: 3.980e-01 | Regularization Loss: 1.213e-07 | Val Loss: 4.070e-01 | Time: 4.71s
2025-08-15 11:46:26,414:INFO:New best model found at epoch 5950 with validation loss 4.070e-01. Saving...
2025-08-15 11:46:31,051:INFO:Epoch: 6000/10000 | Train Loss: 3.963e-01 | Dynamic Loss: 3.963e-01 | Regularization Loss: 1.197e-07 | Val Loss: 4.066e-01 | Time: 4.63s
2025-08-15 11:46:31,051:INFO:New best model found at epoch 6000 with validation loss 4.066e-01. Saving...
2025-08-15 11:46:41,622:INFO:Epoch: 6050/10000 | Train Loss: 3.969e-01 | Dynamic Loss: 3.969e-01 | Regularization Loss: 1.197e-07 | Val Loss: 4.073e-01 | Time: 10.56s
2025-08-15 11:46:46,306:INFO:Epoch: 6100/10000 | Train Loss: 3.952e-01 | Dynamic Loss: 3.952e-01 | Regularization Loss: 1.189e-07 | Val Loss: 4.073e-01 | Time: 4.68s
2025-08-15 11:46:50,930:INFO:Epoch: 6150/10000 | Train Loss: 3.939e-01 | Dynamic Loss: 3.939e-01 | Regularization Loss: 1.171e-07 | Val Loss: 4.057e-01 | Time: 4.62s
2025-08-15 11:46:50,930:INFO:New best model found at epoch 6150 with validation loss 4.057e-01. Saving...
2025-08-15 11:46:55,445:INFO:Epoch: 6200/10000 | Train Loss: 3.914e-01 | Dynamic Loss: 3.914e-01 | Regularization Loss: 1.151e-07 | Val Loss: 4.045e-01 | Time: 4.50s
2025-08-15 11:46:55,445:INFO:New best model found at epoch 6200 with validation loss 4.045e-01. Saving...
2025-08-15 11:47:00,043:INFO:Epoch: 6250/10000 | Train Loss: 3.917e-01 | Dynamic Loss: 3.917e-01 | Regularization Loss: 1.137e-07 | Val Loss: 4.041e-01 | Time: 4.59s
2025-08-15 11:47:00,044:INFO:New best model found at epoch 6250 with validation loss 4.041e-01. Saving...
2025-08-15 11:47:11,324:INFO:Epoch: 6300/10000 | Train Loss: 3.913e-01 | Dynamic Loss: 3.913e-01 | Regularization Loss: 1.133e-07 | Val Loss: 4.040e-01 | Time: 11.27s
2025-08-15 11:47:11,325:INFO:New best model found at epoch 6300 with validation loss 4.040e-01. Saving...
2025-08-15 11:47:16,074:INFO:Epoch: 6350/10000 | Train Loss: 3.892e-01 | Dynamic Loss: 3.892e-01 | Regularization Loss: 1.131e-07 | Val Loss: 4.028e-01 | Time: 4.74s
2025-08-15 11:47:16,076:INFO:New best model found at epoch 6350 with validation loss 4.028e-01. Saving...
2025-08-15 11:47:20,778:INFO:Epoch: 6400/10000 | Train Loss: 3.908e-01 | Dynamic Loss: 3.908e-01 | Regularization Loss: 1.120e-07 | Val Loss: 4.027e-01 | Time: 4.69s
2025-08-15 11:47:20,780:INFO:New best model found at epoch 6400 with validation loss 4.027e-01. Saving...
2025-08-15 11:47:25,328:INFO:Epoch: 6450/10000 | Train Loss: 3.907e-01 | Dynamic Loss: 3.907e-01 | Regularization Loss: 1.113e-07 | Val Loss: 4.051e-01 | Time: 4.54s
2025-08-15 11:47:29,872:INFO:Epoch: 6500/10000 | Train Loss: 3.900e-01 | Dynamic Loss: 3.900e-01 | Regularization Loss: 1.095e-07 | Val Loss: 4.027e-01 | Time: 4.54s
2025-08-15 11:47:41,254:INFO:Epoch: 6550/10000 | Train Loss: 3.841e-01 | Dynamic Loss: 3.840e-01 | Regularization Loss: 1.096e-07 | Val Loss: 3.998e-01 | Time: 11.38s
2025-08-15 11:47:41,255:INFO:New best model found at epoch 6550 with validation loss 3.998e-01. Saving...
2025-08-15 11:47:45,880:INFO:Epoch: 6600/10000 | Train Loss: 3.837e-01 | Dynamic Loss: 3.837e-01 | Regularization Loss: 1.056e-07 | Val Loss: 3.995e-01 | Time: 4.62s
2025-08-15 11:47:45,880:INFO:New best model found at epoch 6600 with validation loss 3.995e-01. Saving...
2025-08-15 11:47:50,452:INFO:Epoch: 6650/10000 | Train Loss: 3.815e-01 | Dynamic Loss: 3.815e-01 | Regularization Loss: 1.062e-07 | Val Loss: 3.987e-01 | Time: 4.56s
2025-08-15 11:47:50,454:INFO:New best model found at epoch 6650 with validation loss 3.987e-01. Saving...
2025-08-15 11:47:55,076:INFO:Epoch: 6700/10000 | Train Loss: 3.814e-01 | Dynamic Loss: 3.814e-01 | Regularization Loss: 1.051e-07 | Val Loss: 3.961e-01 | Time: 4.61s
2025-08-15 11:47:55,076:INFO:New best model found at epoch 6700 with validation loss 3.961e-01. Saving...
2025-08-15 11:48:02,490:INFO:Epoch: 6750/10000 | Train Loss: 3.798e-01 | Dynamic Loss: 3.798e-01 | Regularization Loss: 1.061e-07 | Val Loss: 3.949e-01 | Time: 7.41s
2025-08-15 11:48:02,490:INFO:New best model found at epoch 6750 with validation loss 3.949e-01. Saving...
2025-08-15 11:48:07,109:INFO:Epoch: 6800/10000 | Train Loss: 3.790e-01 | Dynamic Loss: 3.790e-01 | Regularization Loss: 1.081e-07 | Val Loss: 3.942e-01 | Time: 4.61s
2025-08-15 11:48:07,109:INFO:New best model found at epoch 6800 with validation loss 3.942e-01. Saving...
2025-08-15 11:48:11,781:INFO:Epoch: 6850/10000 | Train Loss: 3.797e-01 | Dynamic Loss: 3.797e-01 | Regularization Loss: 1.160e-07 | Val Loss: 3.958e-01 | Time: 4.66s
2025-08-15 11:48:16,382:INFO:Epoch: 6900/10000 | Train Loss: 3.767e-01 | Dynamic Loss: 3.767e-01 | Regularization Loss: 9.085e-08 | Val Loss: 3.940e-01 | Time: 4.60s
2025-08-15 11:48:16,382:INFO:New best model found at epoch 6900 with validation loss 3.940e-01. Saving...
2025-08-15 11:48:20,982:INFO:Epoch: 6950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.59s
2025-08-15 11:48:28,616:INFO:Epoch: 7000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 7.63s
2025-08-15 11:48:33,259:INFO:Epoch: 7050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.64s
2025-08-15 11:48:37,931:INFO:Epoch: 7100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.67s
2025-08-15 11:48:42,553:INFO:Epoch: 7150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.62s
2025-08-15 11:48:47,156:INFO:Epoch: 7200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.60s
2025-08-15 11:48:54,474:INFO:Epoch: 7250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 7.32s
2025-08-15 11:48:59,132:INFO:Epoch: 7300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.66s
2025-08-15 11:49:03,821:INFO:Epoch: 7350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.69s
2025-08-15 11:49:08,354:INFO:Epoch: 7400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.53s
2025-08-15 11:49:12,954:INFO:Epoch: 7450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.60s
2025-08-15 11:49:20,067:INFO:Epoch: 7500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 7.11s
2025-08-15 11:49:24,696:INFO:Epoch: 7550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.63s
2025-08-15 11:49:29,298:INFO:Epoch: 7600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.60s
2025-08-15 11:49:34,024:INFO:Epoch: 7650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.73s
2025-08-15 11:49:38,651:INFO:Epoch: 7700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.63s
2025-08-15 11:49:47,504:INFO:Epoch: 7750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 8.85s
2025-08-15 11:49:52,185:INFO:Epoch: 7800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.68s
2025-08-15 11:49:56,917:INFO:Epoch: 7850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.73s
2025-08-15 11:50:01,601:INFO:Epoch: 7900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.68s
2025-08-15 11:50:06,225:INFO:Epoch: 7950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.62s
2025-08-15 11:50:14,909:INFO:Epoch: 8000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 8.68s
2025-08-15 11:50:19,565:INFO:Epoch: 8050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.66s
2025-08-15 11:50:24,245:INFO:Epoch: 8100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.68s
2025-08-15 11:50:29,023:INFO:Epoch: 8150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.78s
2025-08-15 11:50:33,740:INFO:Epoch: 8200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.72s
2025-08-15 11:50:40,961:INFO:Epoch: 8250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 7.22s
2025-08-15 11:50:45,597:INFO:Epoch: 8300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.64s
2025-08-15 11:50:50,221:INFO:Epoch: 8350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.62s
2025-08-15 11:50:54,909:INFO:Epoch: 8400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.69s
2025-08-15 11:50:59,557:INFO:Epoch: 8450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.65s
2025-08-15 11:51:09,885:INFO:Epoch: 8500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 10.33s
2025-08-15 11:51:14,681:INFO:Epoch: 8550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.79s
2025-08-15 11:51:19,398:INFO:Epoch: 8600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.72s
2025-08-15 11:51:24,066:INFO:Epoch: 8650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.67s
2025-08-15 11:51:28,673:INFO:Epoch: 8700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.61s
2025-08-15 11:51:39,706:INFO:Epoch: 8750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 11.03s
2025-08-15 11:51:44,414:INFO:Epoch: 8800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.71s
2025-08-15 11:51:49,069:INFO:Epoch: 8850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.65s
2025-08-15 11:51:53,715:INFO:Epoch: 8900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.65s
2025-08-15 11:51:58,382:INFO:Epoch: 8950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.67s
2025-08-15 11:52:09,908:INFO:Epoch: 9000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 11.53s
2025-08-15 11:52:14,594:INFO:Epoch: 9050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.69s
2025-08-15 11:52:19,320:INFO:Epoch: 9100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.73s
2025-08-15 11:52:23,994:INFO:Epoch: 9150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.67s
2025-08-15 11:52:28,595:INFO:Epoch: 9200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.60s
2025-08-15 11:52:36,818:INFO:Epoch: 9250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 8.22s
2025-08-15 11:52:41,532:INFO:Epoch: 9300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.71s
2025-08-15 11:52:46,249:INFO:Epoch: 9350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.72s
2025-08-15 11:52:50,909:INFO:Epoch: 9400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.66s
2025-08-15 11:52:55,544:INFO:Epoch: 9450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.63s
2025-08-15 11:53:03,134:INFO:Epoch: 9500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 7.59s
2025-08-15 11:53:07,869:INFO:Epoch: 9550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.73s
2025-08-15 11:53:12,603:INFO:Epoch: 9600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.73s
2025-08-15 11:53:17,316:INFO:Epoch: 9650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.71s
2025-08-15 11:53:21,961:INFO:Epoch: 9700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.64s
2025-08-15 11:53:28,654:INFO:Epoch: 9750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 6.69s
2025-08-15 11:53:33,366:INFO:Epoch: 9800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.71s
2025-08-15 11:53:37,948:INFO:Epoch: 9850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.58s
2025-08-15 11:53:42,583:INFO:Epoch: 9900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.63s
2025-08-15 11:53:47,238:INFO:Epoch: 9950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.66s
2025-08-15 11:53:54,114:INFO:Epoch: 10000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 6.88s
2025-08-15 11:57:06,906:INFO:Using device: cuda
2025-08-15 11:58:08,043:INFO:Using device: cuda
2025-08-15 11:59:09,198:INFO:Using device: cuda
