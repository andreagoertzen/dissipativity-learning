2025-08-15 11:34:42,710:INFO:Created DataLoaders with 2994 training samples and 998 validation samples.
2025-08-15 11:35:01,044:INFO:model params: 479490
2025-08-15 11:35:42,127:INFO:Created DataLoaders with 2994 training samples and 998 validation samples.
2025-08-15 11:35:42,743:INFO:model params: 479490
2025-08-15 11:35:56,968:INFO:Epoch: 0/10000 | Train Loss: 5.094e+00 | Dynamic Loss: 5.094e+00 | Regularization Loss: 6.195e-23 | Val Loss: 3.413e+00 | Time: 14.22s
2025-08-15 11:35:56,968:INFO:New best model found at epoch 0 with validation loss 3.413e+00. Saving...
2025-08-15 11:36:01,664:INFO:Epoch: 50/10000 | Train Loss: 9.023e-01 | Dynamic Loss: 9.023e-01 | Regularization Loss: 2.074e-19 | Val Loss: 9.511e-01 | Time: 4.56s
2025-08-15 11:36:01,664:INFO:New best model found at epoch 50 with validation loss 9.511e-01. Saving...
2025-08-15 11:36:06,156:INFO:Epoch: 100/10000 | Train Loss: 7.129e-01 | Dynamic Loss: 7.129e-01 | Regularization Loss: 1.892e-13 | Val Loss: 7.449e-01 | Time: 4.48s
2025-08-15 11:36:06,156:INFO:New best model found at epoch 100 with validation loss 7.449e-01. Saving...
2025-08-15 11:36:10,705:INFO:Epoch: 150/10000 | Train Loss: 6.436e-01 | Dynamic Loss: 6.436e-01 | Regularization Loss: 8.614e-07 | Val Loss: 6.642e-01 | Time: 4.54s
2025-08-15 11:36:10,705:INFO:New best model found at epoch 150 with validation loss 6.642e-01. Saving...
2025-08-15 11:36:15,261:INFO:Epoch: 200/10000 | Train Loss: 6.073e-01 | Dynamic Loss: 6.073e-01 | Regularization Loss: 6.270e-07 | Val Loss: 6.274e-01 | Time: 4.55s
2025-08-15 11:36:15,261:INFO:New best model found at epoch 200 with validation loss 6.274e-01. Saving...
2025-08-15 11:36:19,837:INFO:Epoch: 250/10000 | Train Loss: 5.892e-01 | Dynamic Loss: 5.892e-01 | Regularization Loss: 6.087e-07 | Val Loss: 6.030e-01 | Time: 4.56s
2025-08-15 11:36:19,837:INFO:New best model found at epoch 250 with validation loss 6.030e-01. Saving...
2025-08-15 11:36:29,564:INFO:Epoch: 300/10000 | Train Loss: 5.770e-01 | Dynamic Loss: 5.770e-01 | Regularization Loss: 5.891e-07 | Val Loss: 5.845e-01 | Time: 9.72s
2025-08-15 11:36:29,564:INFO:New best model found at epoch 300 with validation loss 5.845e-01. Saving...
2025-08-15 11:36:34,211:INFO:Epoch: 350/10000 | Train Loss: 5.720e-01 | Dynamic Loss: 5.720e-01 | Regularization Loss: 5.699e-07 | Val Loss: 5.730e-01 | Time: 4.64s
2025-08-15 11:36:34,211:INFO:New best model found at epoch 350 with validation loss 5.730e-01. Saving...
2025-08-15 11:36:38,808:INFO:Epoch: 400/10000 | Train Loss: 5.659e-01 | Dynamic Loss: 5.659e-01 | Regularization Loss: 5.512e-07 | Val Loss: 5.649e-01 | Time: 4.59s
2025-08-15 11:36:38,808:INFO:New best model found at epoch 400 with validation loss 5.649e-01. Saving...
2025-08-15 11:36:43,320:INFO:Epoch: 450/10000 | Train Loss: 5.604e-01 | Dynamic Loss: 5.604e-01 | Regularization Loss: 5.347e-07 | Val Loss: 5.591e-01 | Time: 4.50s
2025-08-15 11:36:43,320:INFO:New best model found at epoch 450 with validation loss 5.591e-01. Saving...
2025-08-15 11:36:53,567:INFO:Epoch: 500/10000 | Train Loss: 5.577e-01 | Dynamic Loss: 5.577e-01 | Regularization Loss: 5.186e-07 | Val Loss: 5.531e-01 | Time: 10.24s
2025-08-15 11:36:53,567:INFO:New best model found at epoch 500 with validation loss 5.531e-01. Saving...
2025-08-15 11:36:58,232:INFO:Epoch: 550/10000 | Train Loss: 5.506e-01 | Dynamic Loss: 5.506e-01 | Regularization Loss: 5.018e-07 | Val Loss: 5.453e-01 | Time: 4.66s
2025-08-15 11:36:58,232:INFO:New best model found at epoch 550 with validation loss 5.453e-01. Saving...
2025-08-15 11:37:02,885:INFO:Epoch: 600/10000 | Train Loss: 5.486e-01 | Dynamic Loss: 5.486e-01 | Regularization Loss: 4.890e-07 | Val Loss: 5.422e-01 | Time: 4.64s
2025-08-15 11:37:02,885:INFO:New best model found at epoch 600 with validation loss 5.422e-01. Saving...
2025-08-15 11:37:07,474:INFO:Epoch: 650/10000 | Train Loss: 5.443e-01 | Dynamic Loss: 5.443e-01 | Regularization Loss: 4.729e-07 | Val Loss: 5.353e-01 | Time: 4.58s
2025-08-15 11:37:07,474:INFO:New best model found at epoch 650 with validation loss 5.353e-01. Saving...
2025-08-15 11:37:12,230:INFO:Epoch: 700/10000 | Train Loss: 5.432e-01 | Dynamic Loss: 5.432e-01 | Regularization Loss: 4.597e-07 | Val Loss: 5.306e-01 | Time: 4.72s
2025-08-15 11:37:12,230:INFO:New best model found at epoch 700 with validation loss 5.306e-01. Saving...
2025-08-15 11:37:16,920:INFO:Epoch: 750/10000 | Train Loss: 5.359e-01 | Dynamic Loss: 5.359e-01 | Regularization Loss: 4.448e-07 | Val Loss: 5.259e-01 | Time: 4.68s
2025-08-15 11:37:16,921:INFO:New best model found at epoch 750 with validation loss 5.259e-01. Saving...
2025-08-15 11:37:21,642:INFO:Epoch: 800/10000 | Train Loss: 5.339e-01 | Dynamic Loss: 5.339e-01 | Regularization Loss: 4.352e-07 | Val Loss: 5.237e-01 | Time: 4.71s
2025-08-15 11:37:21,642:INFO:New best model found at epoch 800 with validation loss 5.237e-01. Saving...
2025-08-15 11:37:26,307:INFO:Epoch: 850/10000 | Train Loss: 5.289e-01 | Dynamic Loss: 5.289e-01 | Regularization Loss: 4.226e-07 | Val Loss: 5.184e-01 | Time: 4.66s
2025-08-15 11:37:26,308:INFO:New best model found at epoch 850 with validation loss 5.184e-01. Saving...
2025-08-15 11:37:31,819:INFO:Epoch: 900/10000 | Train Loss: 5.283e-01 | Dynamic Loss: 5.283e-01 | Regularization Loss: 4.122e-07 | Val Loss: 5.160e-01 | Time: 5.50s
2025-08-15 11:37:31,819:INFO:New best model found at epoch 900 with validation loss 5.160e-01. Saving...
2025-08-15 11:37:36,461:INFO:Epoch: 950/10000 | Train Loss: 5.250e-01 | Dynamic Loss: 5.250e-01 | Regularization Loss: 4.023e-07 | Val Loss: 5.121e-01 | Time: 4.63s
2025-08-15 11:37:36,461:INFO:New best model found at epoch 950 with validation loss 5.121e-01. Saving...
2025-08-15 11:37:41,119:INFO:Epoch: 1000/10000 | Train Loss: 5.223e-01 | Dynamic Loss: 5.223e-01 | Regularization Loss: 3.927e-07 | Val Loss: 5.096e-01 | Time: 4.65s
2025-08-15 11:37:41,119:INFO:New best model found at epoch 1000 with validation loss 5.096e-01. Saving...
2025-08-15 11:37:45,808:INFO:Epoch: 1050/10000 | Train Loss: 5.173e-01 | Dynamic Loss: 5.173e-01 | Regularization Loss: 3.811e-07 | Val Loss: 5.069e-01 | Time: 4.68s
2025-08-15 11:37:45,808:INFO:New best model found at epoch 1050 with validation loss 5.069e-01. Saving...
2025-08-15 11:37:50,375:INFO:Epoch: 1100/10000 | Train Loss: 5.153e-01 | Dynamic Loss: 5.153e-01 | Regularization Loss: 3.725e-07 | Val Loss: 5.040e-01 | Time: 4.56s
2025-08-15 11:37:50,376:INFO:New best model found at epoch 1100 with validation loss 5.040e-01. Saving...
2025-08-15 11:37:59,855:INFO:Epoch: 1150/10000 | Train Loss: 5.118e-01 | Dynamic Loss: 5.118e-01 | Regularization Loss: 3.634e-07 | Val Loss: 5.010e-01 | Time: 9.47s
2025-08-15 11:37:59,855:INFO:New best model found at epoch 1150 with validation loss 5.010e-01. Saving...
2025-08-15 11:38:04,490:INFO:Epoch: 1200/10000 | Train Loss: 5.117e-01 | Dynamic Loss: 5.117e-01 | Regularization Loss: 3.573e-07 | Val Loss: 5.004e-01 | Time: 4.63s
2025-08-15 11:38:04,490:INFO:New best model found at epoch 1200 with validation loss 5.004e-01. Saving...
2025-08-15 11:38:09,138:INFO:Epoch: 1250/10000 | Train Loss: 5.089e-01 | Dynamic Loss: 5.089e-01 | Regularization Loss: 3.511e-07 | Val Loss: 4.962e-01 | Time: 4.64s
2025-08-15 11:38:09,139:INFO:New best model found at epoch 1250 with validation loss 4.962e-01. Saving...
2025-08-15 11:38:13,741:INFO:Epoch: 1300/10000 | Train Loss: 5.076e-01 | Dynamic Loss: 5.076e-01 | Regularization Loss: 3.419e-07 | Val Loss: 4.952e-01 | Time: 4.59s
2025-08-15 11:38:13,741:INFO:New best model found at epoch 1300 with validation loss 4.952e-01. Saving...
2025-08-15 11:38:24,173:INFO:Epoch: 1350/10000 | Train Loss: 5.056e-01 | Dynamic Loss: 5.056e-01 | Regularization Loss: 3.374e-07 | Val Loss: 4.942e-01 | Time: 10.42s
2025-08-15 11:38:24,173:INFO:New best model found at epoch 1350 with validation loss 4.942e-01. Saving...
2025-08-15 11:38:28,798:INFO:Epoch: 1400/10000 | Train Loss: 5.008e-01 | Dynamic Loss: 5.008e-01 | Regularization Loss: 3.290e-07 | Val Loss: 4.899e-01 | Time: 4.61s
2025-08-15 11:38:28,798:INFO:New best model found at epoch 1400 with validation loss 4.899e-01. Saving...
2025-08-15 11:38:33,535:INFO:Epoch: 1450/10000 | Train Loss: 5.001e-01 | Dynamic Loss: 5.001e-01 | Regularization Loss: 3.225e-07 | Val Loss: 4.884e-01 | Time: 4.73s
2025-08-15 11:38:33,535:INFO:New best model found at epoch 1450 with validation loss 4.884e-01. Saving...
2025-08-15 11:38:38,184:INFO:Epoch: 1500/10000 | Train Loss: 4.983e-01 | Dynamic Loss: 4.983e-01 | Regularization Loss: 3.159e-07 | Val Loss: 4.854e-01 | Time: 4.64s
2025-08-15 11:38:38,184:INFO:New best model found at epoch 1500 with validation loss 4.854e-01. Saving...
2025-08-15 11:38:43,148:INFO:Epoch: 1550/10000 | Train Loss: 4.977e-01 | Dynamic Loss: 4.977e-01 | Regularization Loss: 3.137e-07 | Val Loss: 4.877e-01 | Time: 4.95s
2025-08-15 11:38:47,739:INFO:Epoch: 1600/10000 | Train Loss: 4.934e-01 | Dynamic Loss: 4.934e-01 | Regularization Loss: 3.061e-07 | Val Loss: 4.819e-01 | Time: 4.59s
2025-08-15 11:38:47,739:INFO:New best model found at epoch 1600 with validation loss 4.819e-01. Saving...
2025-08-15 11:38:52,330:INFO:Epoch: 1650/10000 | Train Loss: 4.931e-01 | Dynamic Loss: 4.931e-01 | Regularization Loss: 3.004e-07 | Val Loss: 4.807e-01 | Time: 4.58s
2025-08-15 11:38:52,330:INFO:New best model found at epoch 1650 with validation loss 4.807e-01. Saving...
2025-08-15 11:38:56,946:INFO:Epoch: 1700/10000 | Train Loss: 4.897e-01 | Dynamic Loss: 4.897e-01 | Regularization Loss: 2.945e-07 | Val Loss: 4.792e-01 | Time: 4.61s
2025-08-15 11:38:56,947:INFO:New best model found at epoch 1700 with validation loss 4.792e-01. Saving...
2025-08-15 11:39:04,657:INFO:Epoch: 1750/10000 | Train Loss: 4.905e-01 | Dynamic Loss: 4.905e-01 | Regularization Loss: 2.905e-07 | Val Loss: 4.768e-01 | Time: 7.70s
2025-08-15 11:39:04,657:INFO:New best model found at epoch 1750 with validation loss 4.768e-01. Saving...
2025-08-15 11:39:09,290:INFO:Epoch: 1800/10000 | Train Loss: 4.869e-01 | Dynamic Loss: 4.869e-01 | Regularization Loss: 2.863e-07 | Val Loss: 4.775e-01 | Time: 4.62s
2025-08-15 11:39:13,893:INFO:Epoch: 1850/10000 | Train Loss: 4.845e-01 | Dynamic Loss: 4.845e-01 | Regularization Loss: 2.810e-07 | Val Loss: 4.758e-01 | Time: 4.60s
2025-08-15 11:39:13,893:INFO:New best model found at epoch 1850 with validation loss 4.758e-01. Saving...
2025-08-15 11:39:18,405:INFO:Epoch: 1900/10000 | Train Loss: 4.836e-01 | Dynamic Loss: 4.836e-01 | Regularization Loss: 2.762e-07 | Val Loss: 4.736e-01 | Time: 4.50s
2025-08-15 11:39:18,405:INFO:New best model found at epoch 1900 with validation loss 4.736e-01. Saving...
2025-08-15 11:39:23,051:INFO:Epoch: 1950/10000 | Train Loss: 4.812e-01 | Dynamic Loss: 4.812e-01 | Regularization Loss: 2.707e-07 | Val Loss: 4.731e-01 | Time: 4.63s
2025-08-15 11:39:23,051:INFO:New best model found at epoch 1950 with validation loss 4.731e-01. Saving...
2025-08-15 11:39:31,959:INFO:Epoch: 2000/10000 | Train Loss: 4.782e-01 | Dynamic Loss: 4.782e-01 | Regularization Loss: 2.658e-07 | Val Loss: 4.694e-01 | Time: 8.90s
2025-08-15 11:39:31,959:INFO:New best model found at epoch 2000 with validation loss 4.694e-01. Saving...
2025-08-15 11:39:36,579:INFO:Epoch: 2050/10000 | Train Loss: 4.765e-01 | Dynamic Loss: 4.765e-01 | Regularization Loss: 2.610e-07 | Val Loss: 4.668e-01 | Time: 4.61s
2025-08-15 11:39:36,579:INFO:New best model found at epoch 2050 with validation loss 4.668e-01. Saving...
2025-08-15 11:39:41,272:INFO:Epoch: 2100/10000 | Train Loss: 4.742e-01 | Dynamic Loss: 4.742e-01 | Regularization Loss: 2.564e-07 | Val Loss: 4.654e-01 | Time: 4.68s
2025-08-15 11:39:41,272:INFO:New best model found at epoch 2100 with validation loss 4.654e-01. Saving...
2025-08-15 11:39:45,828:INFO:Epoch: 2150/10000 | Train Loss: 4.721e-01 | Dynamic Loss: 4.721e-01 | Regularization Loss: 2.502e-07 | Val Loss: 4.647e-01 | Time: 4.55s
2025-08-15 11:39:45,828:INFO:New best model found at epoch 2150 with validation loss 4.647e-01. Saving...
2025-08-15 11:39:54,027:INFO:Epoch: 2200/10000 | Train Loss: 4.721e-01 | Dynamic Loss: 4.721e-01 | Regularization Loss: 2.462e-07 | Val Loss: 4.637e-01 | Time: 8.19s
2025-08-15 11:39:54,027:INFO:New best model found at epoch 2200 with validation loss 4.637e-01. Saving...
2025-08-15 11:39:58,703:INFO:Epoch: 2250/10000 | Train Loss: 4.673e-01 | Dynamic Loss: 4.673e-01 | Regularization Loss: 2.400e-07 | Val Loss: 4.604e-01 | Time: 4.67s
2025-08-15 11:39:58,703:INFO:New best model found at epoch 2250 with validation loss 4.604e-01. Saving...
2025-08-15 11:40:03,427:INFO:Epoch: 2300/10000 | Train Loss: 4.661e-01 | Dynamic Loss: 4.661e-01 | Regularization Loss: 2.363e-07 | Val Loss: 4.590e-01 | Time: 4.71s
2025-08-15 11:40:03,427:INFO:New best model found at epoch 2300 with validation loss 4.590e-01. Saving...
2025-08-15 11:40:08,030:INFO:Epoch: 2350/10000 | Train Loss: 4.652e-01 | Dynamic Loss: 4.652e-01 | Regularization Loss: 2.320e-07 | Val Loss: 4.606e-01 | Time: 4.59s
2025-08-15 11:40:12,723:INFO:Epoch: 2400/10000 | Train Loss: 4.628e-01 | Dynamic Loss: 4.628e-01 | Regularization Loss: 2.288e-07 | Val Loss: 4.570e-01 | Time: 4.69s
2025-08-15 11:40:12,723:INFO:New best model found at epoch 2400 with validation loss 4.570e-01. Saving...
2025-08-15 11:40:17,388:INFO:Epoch: 2450/10000 | Train Loss: 4.613e-01 | Dynamic Loss: 4.613e-01 | Regularization Loss: 2.274e-07 | Val Loss: 4.567e-01 | Time: 4.66s
2025-08-15 11:40:17,388:INFO:New best model found at epoch 2450 with validation loss 4.567e-01. Saving...
2025-08-15 11:40:22,071:INFO:Epoch: 2500/10000 | Train Loss: 4.589e-01 | Dynamic Loss: 4.589e-01 | Regularization Loss: 2.237e-07 | Val Loss: 4.550e-01 | Time: 4.67s
2025-08-15 11:40:22,072:INFO:New best model found at epoch 2500 with validation loss 4.550e-01. Saving...
2025-08-15 11:40:26,726:INFO:Epoch: 2550/10000 | Train Loss: 4.580e-01 | Dynamic Loss: 4.580e-01 | Regularization Loss: 2.212e-07 | Val Loss: 4.537e-01 | Time: 4.65s
2025-08-15 11:40:26,726:INFO:New best model found at epoch 2550 with validation loss 4.537e-01. Saving...
2025-08-15 11:40:31,364:INFO:Epoch: 2600/10000 | Train Loss: 4.574e-01 | Dynamic Loss: 4.574e-01 | Regularization Loss: 2.182e-07 | Val Loss: 4.538e-01 | Time: 4.63s
2025-08-15 11:40:39,648:INFO:Epoch: 2650/10000 | Train Loss: 4.569e-01 | Dynamic Loss: 4.569e-01 | Regularization Loss: 2.167e-07 | Val Loss: 4.534e-01 | Time: 8.28s
2025-08-15 11:40:39,648:INFO:New best model found at epoch 2650 with validation loss 4.534e-01. Saving...
2025-08-15 11:40:44,323:INFO:Epoch: 2700/10000 | Train Loss: 4.556e-01 | Dynamic Loss: 4.556e-01 | Regularization Loss: 2.149e-07 | Val Loss: 4.509e-01 | Time: 4.67s
2025-08-15 11:40:44,323:INFO:New best model found at epoch 2700 with validation loss 4.509e-01. Saving...
2025-08-15 11:40:49,023:INFO:Epoch: 2750/10000 | Train Loss: 4.539e-01 | Dynamic Loss: 4.539e-01 | Regularization Loss: 2.122e-07 | Val Loss: 4.505e-01 | Time: 4.69s
2025-08-15 11:40:49,023:INFO:New best model found at epoch 2750 with validation loss 4.505e-01. Saving...
2025-08-15 11:40:53,655:INFO:Epoch: 2800/10000 | Train Loss: 4.532e-01 | Dynamic Loss: 4.532e-01 | Regularization Loss: 2.110e-07 | Val Loss: 4.495e-01 | Time: 4.62s
2025-08-15 11:40:53,655:INFO:New best model found at epoch 2800 with validation loss 4.495e-01. Saving...
2025-08-15 11:40:58,244:INFO:Epoch: 2850/10000 | Train Loss: 4.519e-01 | Dynamic Loss: 4.519e-01 | Regularization Loss: 2.067e-07 | Val Loss: 4.490e-01 | Time: 4.58s
2025-08-15 11:40:58,244:INFO:New best model found at epoch 2850 with validation loss 4.490e-01. Saving...
2025-08-15 11:41:08,775:INFO:Epoch: 2900/10000 | Train Loss: 4.523e-01 | Dynamic Loss: 4.523e-01 | Regularization Loss: 2.055e-07 | Val Loss: 4.478e-01 | Time: 10.52s
2025-08-15 11:41:08,775:INFO:New best model found at epoch 2900 with validation loss 4.478e-01. Saving...
2025-08-15 11:41:13,464:INFO:Epoch: 2950/10000 | Train Loss: 4.512e-01 | Dynamic Loss: 4.512e-01 | Regularization Loss: 2.026e-07 | Val Loss: 4.459e-01 | Time: 4.68s
2025-08-15 11:41:13,465:INFO:New best model found at epoch 2950 with validation loss 4.459e-01. Saving...
2025-08-15 11:41:18,127:INFO:Epoch: 3000/10000 | Train Loss: 4.504e-01 | Dynamic Loss: 4.504e-01 | Regularization Loss: 1.994e-07 | Val Loss: 4.452e-01 | Time: 4.65s
2025-08-15 11:41:18,127:INFO:New best model found at epoch 3000 with validation loss 4.452e-01. Saving...
2025-08-15 11:41:22,712:INFO:Epoch: 3050/10000 | Train Loss: 4.473e-01 | Dynamic Loss: 4.473e-01 | Regularization Loss: 1.974e-07 | Val Loss: 4.460e-01 | Time: 4.58s
2025-08-15 11:41:28,419:INFO:Epoch: 3100/10000 | Train Loss: 4.471e-01 | Dynamic Loss: 4.471e-01 | Regularization Loss: 1.954e-07 | Val Loss: 4.441e-01 | Time: 5.71s
2025-08-15 11:41:28,419:INFO:New best model found at epoch 3100 with validation loss 4.441e-01. Saving...
2025-08-15 11:41:33,149:INFO:Epoch: 3150/10000 | Train Loss: 4.474e-01 | Dynamic Loss: 4.474e-01 | Regularization Loss: 1.943e-07 | Val Loss: 4.423e-01 | Time: 4.72s
2025-08-15 11:41:33,149:INFO:New best model found at epoch 3150 with validation loss 4.423e-01. Saving...
2025-08-15 11:41:37,892:INFO:Epoch: 3200/10000 | Train Loss: 4.460e-01 | Dynamic Loss: 4.460e-01 | Regularization Loss: 1.918e-07 | Val Loss: 4.416e-01 | Time: 4.73s
2025-08-15 11:41:37,892:INFO:New best model found at epoch 3200 with validation loss 4.416e-01. Saving...
2025-08-15 11:41:42,514:INFO:Epoch: 3250/10000 | Train Loss: 4.444e-01 | Dynamic Loss: 4.444e-01 | Regularization Loss: 1.906e-07 | Val Loss: 4.411e-01 | Time: 4.61s
2025-08-15 11:41:42,515:INFO:New best model found at epoch 3250 with validation loss 4.411e-01. Saving...
2025-08-15 11:41:47,136:INFO:Epoch: 3300/10000 | Train Loss: 4.428e-01 | Dynamic Loss: 4.428e-01 | Regularization Loss: 1.884e-07 | Val Loss: 4.400e-01 | Time: 4.61s
2025-08-15 11:41:47,136:INFO:New best model found at epoch 3300 with validation loss 4.400e-01. Saving...
2025-08-15 11:41:55,423:INFO:Epoch: 3350/10000 | Train Loss: 4.424e-01 | Dynamic Loss: 4.424e-01 | Regularization Loss: 1.861e-07 | Val Loss: 4.393e-01 | Time: 8.28s
2025-08-15 11:41:55,423:INFO:New best model found at epoch 3350 with validation loss 4.393e-01. Saving...
2025-08-15 11:42:00,132:INFO:Epoch: 3400/10000 | Train Loss: 4.429e-01 | Dynamic Loss: 4.429e-01 | Regularization Loss: 1.853e-07 | Val Loss: 4.400e-01 | Time: 4.70s
2025-08-15 11:42:04,803:INFO:Epoch: 3450/10000 | Train Loss: 4.417e-01 | Dynamic Loss: 4.417e-01 | Regularization Loss: 1.832e-07 | Val Loss: 4.388e-01 | Time: 4.67s
2025-08-15 11:42:04,804:INFO:New best model found at epoch 3450 with validation loss 4.388e-01. Saving...
2025-08-15 11:42:09,429:INFO:Epoch: 3500/10000 | Train Loss: 4.416e-01 | Dynamic Loss: 4.416e-01 | Regularization Loss: 1.823e-07 | Val Loss: 4.388e-01 | Time: 4.62s
2025-08-15 11:42:09,429:INFO:New best model found at epoch 3500 with validation loss 4.388e-01. Saving...
2025-08-15 11:42:14,021:INFO:Epoch: 3550/10000 | Train Loss: 4.412e-01 | Dynamic Loss: 4.412e-01 | Regularization Loss: 1.817e-07 | Val Loss: 4.385e-01 | Time: 4.58s
2025-08-15 11:42:14,021:INFO:New best model found at epoch 3550 with validation loss 4.385e-01. Saving...
2025-08-15 11:42:24,151:INFO:Epoch: 3600/10000 | Train Loss: 4.401e-01 | Dynamic Loss: 4.401e-01 | Regularization Loss: 1.803e-07 | Val Loss: 4.380e-01 | Time: 10.12s
2025-08-15 11:42:24,151:INFO:New best model found at epoch 3600 with validation loss 4.380e-01. Saving...
2025-08-15 11:42:28,981:INFO:Epoch: 3650/10000 | Train Loss: 4.394e-01 | Dynamic Loss: 4.394e-01 | Regularization Loss: 1.789e-07 | Val Loss: 4.383e-01 | Time: 4.82s
2025-08-15 11:42:33,767:INFO:Epoch: 3700/10000 | Train Loss: 4.384e-01 | Dynamic Loss: 4.384e-01 | Regularization Loss: 1.780e-07 | Val Loss: 4.374e-01 | Time: 4.79s
2025-08-15 11:42:33,767:INFO:New best model found at epoch 3700 with validation loss 4.374e-01. Saving...
2025-08-15 11:42:38,491:INFO:Epoch: 3750/10000 | Train Loss: 4.385e-01 | Dynamic Loss: 4.385e-01 | Regularization Loss: 1.763e-07 | Val Loss: 4.381e-01 | Time: 4.71s
2025-08-15 11:42:43,187:INFO:Epoch: 3800/10000 | Train Loss: 4.370e-01 | Dynamic Loss: 4.370e-01 | Regularization Loss: 1.749e-07 | Val Loss: 4.364e-01 | Time: 4.70s
2025-08-15 11:42:43,187:INFO:New best model found at epoch 3800 with validation loss 4.364e-01. Saving...
2025-08-15 11:42:52,792:INFO:Epoch: 3850/10000 | Train Loss: 4.367e-01 | Dynamic Loss: 4.367e-01 | Regularization Loss: 1.735e-07 | Val Loss: 4.363e-01 | Time: 9.59s
2025-08-15 11:42:52,792:INFO:New best model found at epoch 3850 with validation loss 4.363e-01. Saving...
2025-08-15 11:42:57,586:INFO:Epoch: 3900/10000 | Train Loss: 4.360e-01 | Dynamic Loss: 4.360e-01 | Regularization Loss: 1.722e-07 | Val Loss: 4.372e-01 | Time: 4.78s
2025-08-15 11:43:02,316:INFO:Epoch: 3950/10000 | Train Loss: 4.352e-01 | Dynamic Loss: 4.352e-01 | Regularization Loss: 1.703e-07 | Val Loss: 4.355e-01 | Time: 4.73s
2025-08-15 11:43:02,316:INFO:New best model found at epoch 3950 with validation loss 4.355e-01. Saving...
2025-08-15 11:43:07,024:INFO:Epoch: 4000/10000 | Train Loss: 4.350e-01 | Dynamic Loss: 4.350e-01 | Regularization Loss: 1.687e-07 | Val Loss: 4.347e-01 | Time: 4.70s
2025-08-15 11:43:07,024:INFO:New best model found at epoch 4000 with validation loss 4.347e-01. Saving...
2025-08-15 11:43:15,480:INFO:Epoch: 4050/10000 | Train Loss: 4.334e-01 | Dynamic Loss: 4.334e-01 | Regularization Loss: 1.678e-07 | Val Loss: 4.341e-01 | Time: 8.45s
2025-08-15 11:43:15,480:INFO:New best model found at epoch 4050 with validation loss 4.341e-01. Saving...
2025-08-15 11:43:20,221:INFO:Epoch: 4100/10000 | Train Loss: 4.313e-01 | Dynamic Loss: 4.313e-01 | Regularization Loss: 1.652e-07 | Val Loss: 4.323e-01 | Time: 4.73s
2025-08-15 11:43:20,221:INFO:New best model found at epoch 4100 with validation loss 4.323e-01. Saving...
2025-08-15 11:43:25,090:INFO:Epoch: 4150/10000 | Train Loss: 4.291e-01 | Dynamic Loss: 4.291e-01 | Regularization Loss: 1.637e-07 | Val Loss: 4.319e-01 | Time: 4.86s
2025-08-15 11:43:25,090:INFO:New best model found at epoch 4150 with validation loss 4.319e-01. Saving...
2025-08-15 11:43:29,843:INFO:Epoch: 4200/10000 | Train Loss: 4.302e-01 | Dynamic Loss: 4.302e-01 | Regularization Loss: 1.606e-07 | Val Loss: 4.317e-01 | Time: 4.74s
2025-08-15 11:43:29,843:INFO:New best model found at epoch 4200 with validation loss 4.317e-01. Saving...
2025-08-15 11:43:34,541:INFO:Epoch: 4250/10000 | Train Loss: 4.267e-01 | Dynamic Loss: 4.267e-01 | Regularization Loss: 1.590e-07 | Val Loss: 4.305e-01 | Time: 4.69s
2025-08-15 11:43:34,541:INFO:New best model found at epoch 4250 with validation loss 4.305e-01. Saving...
2025-08-15 11:43:45,424:INFO:Epoch: 4300/10000 | Train Loss: 4.251e-01 | Dynamic Loss: 4.251e-01 | Regularization Loss: 1.568e-07 | Val Loss: 4.281e-01 | Time: 10.87s
2025-08-15 11:43:45,424:INFO:New best model found at epoch 4300 with validation loss 4.281e-01. Saving...
2025-08-15 11:43:50,214:INFO:Epoch: 4350/10000 | Train Loss: 4.246e-01 | Dynamic Loss: 4.246e-01 | Regularization Loss: 1.555e-07 | Val Loss: 4.283e-01 | Time: 4.78s
2025-08-15 11:43:55,036:INFO:Epoch: 4400/10000 | Train Loss: 4.235e-01 | Dynamic Loss: 4.235e-01 | Regularization Loss: 1.545e-07 | Val Loss: 4.272e-01 | Time: 4.82s
2025-08-15 11:43:55,036:INFO:New best model found at epoch 4400 with validation loss 4.272e-01. Saving...
2025-08-15 11:43:59,757:INFO:Epoch: 4450/10000 | Train Loss: 4.234e-01 | Dynamic Loss: 4.234e-01 | Regularization Loss: 1.535e-07 | Val Loss: 4.276e-01 | Time: 4.71s
2025-08-15 11:44:04,402:INFO:Epoch: 4500/10000 | Train Loss: 4.230e-01 | Dynamic Loss: 4.230e-01 | Regularization Loss: 1.523e-07 | Val Loss: 4.259e-01 | Time: 4.64s
2025-08-15 11:44:04,402:INFO:New best model found at epoch 4500 with validation loss 4.259e-01. Saving...
2025-08-15 11:44:15,254:INFO:Epoch: 4550/10000 | Train Loss: 4.214e-01 | Dynamic Loss: 4.214e-01 | Regularization Loss: 1.501e-07 | Val Loss: 4.257e-01 | Time: 10.84s
2025-08-15 11:44:15,254:INFO:New best model found at epoch 4550 with validation loss 4.257e-01. Saving...
2025-08-15 11:44:19,977:INFO:Epoch: 4600/10000 | Train Loss: 4.197e-01 | Dynamic Loss: 4.197e-01 | Regularization Loss: 1.493e-07 | Val Loss: 4.250e-01 | Time: 4.71s
2025-08-15 11:44:19,977:INFO:New best model found at epoch 4600 with validation loss 4.250e-01. Saving...
2025-08-15 11:44:24,731:INFO:Epoch: 4650/10000 | Train Loss: 4.191e-01 | Dynamic Loss: 4.191e-01 | Regularization Loss: 1.483e-07 | Val Loss: 4.243e-01 | Time: 4.75s
2025-08-15 11:44:24,732:INFO:New best model found at epoch 4650 with validation loss 4.243e-01. Saving...
2025-08-15 11:44:29,362:INFO:Epoch: 4700/10000 | Train Loss: 4.179e-01 | Dynamic Loss: 4.179e-01 | Regularization Loss: 1.476e-07 | Val Loss: 4.243e-01 | Time: 4.62s
2025-08-15 11:44:29,362:INFO:New best model found at epoch 4700 with validation loss 4.243e-01. Saving...
2025-08-15 11:44:34,882:INFO:Epoch: 4750/10000 | Train Loss: 4.184e-01 | Dynamic Loss: 4.184e-01 | Regularization Loss: 1.455e-07 | Val Loss: 4.246e-01 | Time: 5.51s
2025-08-15 11:44:39,671:INFO:Epoch: 4800/10000 | Train Loss: 4.183e-01 | Dynamic Loss: 4.183e-01 | Regularization Loss: 1.453e-07 | Val Loss: 4.239e-01 | Time: 4.79s
2025-08-15 11:44:39,671:INFO:New best model found at epoch 4800 with validation loss 4.239e-01. Saving...
2025-08-15 11:44:44,442:INFO:Epoch: 4850/10000 | Train Loss: 4.138e-01 | Dynamic Loss: 4.138e-01 | Regularization Loss: 1.427e-07 | Val Loss: 4.211e-01 | Time: 4.76s
2025-08-15 11:44:44,442:INFO:New best model found at epoch 4850 with validation loss 4.211e-01. Saving...
2025-08-15 11:44:49,139:INFO:Epoch: 4900/10000 | Train Loss: 4.122e-01 | Dynamic Loss: 4.122e-01 | Regularization Loss: 1.417e-07 | Val Loss: 4.203e-01 | Time: 4.69s
2025-08-15 11:44:49,139:INFO:New best model found at epoch 4900 with validation loss 4.203e-01. Saving...
2025-08-15 11:44:53,825:INFO:Epoch: 4950/10000 | Train Loss: 4.124e-01 | Dynamic Loss: 4.124e-01 | Regularization Loss: 1.393e-07 | Val Loss: 4.199e-01 | Time: 4.68s
2025-08-15 11:44:53,825:INFO:New best model found at epoch 4950 with validation loss 4.199e-01. Saving...
2025-08-15 11:45:01,530:INFO:Epoch: 5000/10000 | Train Loss: 4.110e-01 | Dynamic Loss: 4.110e-01 | Regularization Loss: 1.393e-07 | Val Loss: 4.188e-01 | Time: 7.70s
2025-08-15 11:45:01,530:INFO:New best model found at epoch 5000 with validation loss 4.188e-01. Saving...
2025-08-15 11:45:06,374:INFO:Epoch: 5050/10000 | Train Loss: 4.099e-01 | Dynamic Loss: 4.099e-01 | Regularization Loss: 1.385e-07 | Val Loss: 4.183e-01 | Time: 4.83s
2025-08-15 11:45:06,374:INFO:New best model found at epoch 5050 with validation loss 4.183e-01. Saving...
2025-08-15 11:45:11,186:INFO:Epoch: 5100/10000 | Train Loss: 4.087e-01 | Dynamic Loss: 4.087e-01 | Regularization Loss: 1.371e-07 | Val Loss: 4.176e-01 | Time: 4.80s
2025-08-15 11:45:11,186:INFO:New best model found at epoch 5100 with validation loss 4.176e-01. Saving...
2025-08-15 11:45:15,877:INFO:Epoch: 5150/10000 | Train Loss: 4.094e-01 | Dynamic Loss: 4.094e-01 | Regularization Loss: 1.352e-07 | Val Loss: 4.170e-01 | Time: 4.68s
2025-08-15 11:45:15,878:INFO:New best model found at epoch 5150 with validation loss 4.170e-01. Saving...
2025-08-15 11:45:20,705:INFO:Epoch: 5200/10000 | Train Loss: 4.065e-01 | Dynamic Loss: 4.065e-01 | Regularization Loss: 1.337e-07 | Val Loss: 4.164e-01 | Time: 4.82s
2025-08-15 11:45:20,705:INFO:New best model found at epoch 5200 with validation loss 4.164e-01. Saving...
2025-08-15 11:45:28,291:INFO:Epoch: 5250/10000 | Train Loss: 4.077e-01 | Dynamic Loss: 4.077e-01 | Regularization Loss: 1.324e-07 | Val Loss: 4.153e-01 | Time: 7.58s
2025-08-15 11:45:28,292:INFO:New best model found at epoch 5250 with validation loss 4.153e-01. Saving...
2025-08-15 11:45:33,154:INFO:Epoch: 5300/10000 | Train Loss: 4.064e-01 | Dynamic Loss: 4.064e-01 | Regularization Loss: 1.323e-07 | Val Loss: 4.147e-01 | Time: 4.85s
2025-08-15 11:45:33,154:INFO:New best model found at epoch 5300 with validation loss 4.147e-01. Saving...
2025-08-15 11:45:37,931:INFO:Epoch: 5350/10000 | Train Loss: 4.046e-01 | Dynamic Loss: 4.046e-01 | Regularization Loss: 1.302e-07 | Val Loss: 4.140e-01 | Time: 4.77s
2025-08-15 11:45:37,931:INFO:New best model found at epoch 5350 with validation loss 4.140e-01. Saving...
2025-08-15 11:45:42,751:INFO:Epoch: 5400/10000 | Train Loss: 4.034e-01 | Dynamic Loss: 4.034e-01 | Regularization Loss: 1.306e-07 | Val Loss: 4.134e-01 | Time: 4.81s
2025-08-15 11:45:42,751:INFO:New best model found at epoch 5400 with validation loss 4.134e-01. Saving...
2025-08-15 11:45:47,518:INFO:Epoch: 5450/10000 | Train Loss: 4.033e-01 | Dynamic Loss: 4.033e-01 | Regularization Loss: 1.298e-07 | Val Loss: 4.128e-01 | Time: 4.76s
2025-08-15 11:45:47,518:INFO:New best model found at epoch 5450 with validation loss 4.128e-01. Saving...
2025-08-15 11:45:55,760:INFO:Epoch: 5500/10000 | Train Loss: 4.027e-01 | Dynamic Loss: 4.027e-01 | Regularization Loss: 1.287e-07 | Val Loss: 4.118e-01 | Time: 8.23s
2025-08-15 11:45:55,761:INFO:New best model found at epoch 5500 with validation loss 4.118e-01. Saving...
2025-08-15 11:46:00,516:INFO:Epoch: 5550/10000 | Train Loss: 4.015e-01 | Dynamic Loss: 4.015e-01 | Regularization Loss: 1.261e-07 | Val Loss: 4.114e-01 | Time: 4.74s
2025-08-15 11:46:00,516:INFO:New best model found at epoch 5550 with validation loss 4.114e-01. Saving...
2025-08-15 11:46:05,330:INFO:Epoch: 5600/10000 | Train Loss: 4.020e-01 | Dynamic Loss: 4.020e-01 | Regularization Loss: 1.254e-07 | Val Loss: 4.110e-01 | Time: 4.80s
2025-08-15 11:46:05,330:INFO:New best model found at epoch 5600 with validation loss 4.110e-01. Saving...
2025-08-15 11:46:10,248:INFO:Epoch: 5650/10000 | Train Loss: 3.988e-01 | Dynamic Loss: 3.988e-01 | Regularization Loss: 1.266e-07 | Val Loss: 4.101e-01 | Time: 4.91s
2025-08-15 11:46:10,248:INFO:New best model found at epoch 5650 with validation loss 4.101e-01. Saving...
2025-08-15 11:46:15,015:INFO:Epoch: 5700/10000 | Train Loss: 4.000e-01 | Dynamic Loss: 4.000e-01 | Regularization Loss: 1.247e-07 | Val Loss: 4.136e-01 | Time: 4.76s
2025-08-15 11:46:25,553:INFO:Epoch: 5750/10000 | Train Loss: 3.969e-01 | Dynamic Loss: 3.969e-01 | Regularization Loss: 1.210e-07 | Val Loss: 4.083e-01 | Time: 10.54s
2025-08-15 11:46:25,553:INFO:New best model found at epoch 5750 with validation loss 4.083e-01. Saving...
2025-08-15 11:46:30,315:INFO:Epoch: 5800/10000 | Train Loss: 3.949e-01 | Dynamic Loss: 3.949e-01 | Regularization Loss: 1.209e-07 | Val Loss: 4.073e-01 | Time: 4.75s
2025-08-15 11:46:30,316:INFO:New best model found at epoch 5800 with validation loss 4.073e-01. Saving...
2025-08-15 11:46:35,036:INFO:Epoch: 5850/10000 | Train Loss: 3.932e-01 | Dynamic Loss: 3.932e-01 | Regularization Loss: 1.197e-07 | Val Loss: 4.067e-01 | Time: 4.71s
2025-08-15 11:46:35,036:INFO:New best model found at epoch 5850 with validation loss 4.067e-01. Saving...
2025-08-15 11:46:39,850:INFO:Epoch: 5900/10000 | Train Loss: 3.910e-01 | Dynamic Loss: 3.910e-01 | Regularization Loss: 1.162e-07 | Val Loss: 4.051e-01 | Time: 4.80s
2025-08-15 11:46:39,850:INFO:New best model found at epoch 5900 with validation loss 4.051e-01. Saving...
2025-08-15 11:46:44,639:INFO:Epoch: 5950/10000 | Train Loss: 3.907e-01 | Dynamic Loss: 3.907e-01 | Regularization Loss: 1.147e-07 | Val Loss: 4.046e-01 | Time: 4.78s
2025-08-15 11:46:44,639:INFO:New best model found at epoch 5950 with validation loss 4.046e-01. Saving...
2025-08-15 11:46:55,991:INFO:Epoch: 6000/10000 | Train Loss: 3.890e-01 | Dynamic Loss: 3.890e-01 | Regularization Loss: 1.127e-07 | Val Loss: 4.039e-01 | Time: 11.34s
2025-08-15 11:46:55,991:INFO:New best model found at epoch 6000 with validation loss 4.039e-01. Saving...
2025-08-15 11:47:00,738:INFO:Epoch: 6050/10000 | Train Loss: 3.876e-01 | Dynamic Loss: 3.876e-01 | Regularization Loss: 1.124e-07 | Val Loss: 4.020e-01 | Time: 4.74s
2025-08-15 11:47:00,738:INFO:New best model found at epoch 6050 with validation loss 4.020e-01. Saving...
2025-08-15 11:47:05,418:INFO:Epoch: 6100/10000 | Train Loss: 3.847e-01 | Dynamic Loss: 3.847e-01 | Regularization Loss: 1.111e-07 | Val Loss: 4.008e-01 | Time: 4.67s
2025-08-15 11:47:05,418:INFO:New best model found at epoch 6100 with validation loss 4.008e-01. Saving...
2025-08-15 11:47:10,201:INFO:Epoch: 6150/10000 | Train Loss: 3.849e-01 | Dynamic Loss: 3.849e-01 | Regularization Loss: 1.097e-07 | Val Loss: 4.001e-01 | Time: 4.77s
2025-08-15 11:47:10,201:INFO:New best model found at epoch 6150 with validation loss 4.001e-01. Saving...
2025-08-15 11:47:15,068:INFO:Epoch: 6200/10000 | Train Loss: 3.841e-01 | Dynamic Loss: 3.841e-01 | Regularization Loss: 1.075e-07 | Val Loss: 4.002e-01 | Time: 4.86s
2025-08-15 11:47:19,893:INFO:Epoch: 6250/10000 | Train Loss: 3.843e-01 | Dynamic Loss: 3.843e-01 | Regularization Loss: 1.063e-07 | Val Loss: 4.002e-01 | Time: 4.82s
2025-08-15 11:47:24,687:INFO:Epoch: 6300/10000 | Train Loss: 3.833e-01 | Dynamic Loss: 3.833e-01 | Regularization Loss: 1.059e-07 | Val Loss: 4.021e-01 | Time: 4.79s
2025-08-15 11:47:29,379:INFO:Epoch: 6350/10000 | Train Loss: 3.814e-01 | Dynamic Loss: 3.814e-01 | Regularization Loss: 1.063e-07 | Val Loss: 3.980e-01 | Time: 4.69s
2025-08-15 11:47:29,379:INFO:New best model found at epoch 6350 with validation loss 3.980e-01. Saving...
2025-08-15 11:47:34,096:INFO:Epoch: 6400/10000 | Train Loss: 3.825e-01 | Dynamic Loss: 3.825e-01 | Regularization Loss: 1.036e-07 | Val Loss: 3.977e-01 | Time: 4.70s
2025-08-15 11:47:34,096:INFO:New best model found at epoch 6400 with validation loss 3.977e-01. Saving...
2025-08-15 11:47:43,869:INFO:Epoch: 6450/10000 | Train Loss: 3.802e-01 | Dynamic Loss: 3.802e-01 | Regularization Loss: 1.047e-07 | Val Loss: 3.970e-01 | Time: 9.76s
2025-08-15 11:47:43,869:INFO:New best model found at epoch 6450 with validation loss 3.970e-01. Saving...
2025-08-15 11:47:48,558:INFO:Epoch: 6500/10000 | Train Loss: 3.791e-01 | Dynamic Loss: 3.791e-01 | Regularization Loss: 1.053e-07 | Val Loss: 3.958e-01 | Time: 4.68s
2025-08-15 11:47:48,558:INFO:New best model found at epoch 6500 with validation loss 3.958e-01. Saving...
2025-08-15 11:47:53,261:INFO:Epoch: 6550/10000 | Train Loss: 3.767e-01 | Dynamic Loss: 3.767e-01 | Regularization Loss: 9.910e-08 | Val Loss: 3.959e-01 | Time: 4.69s
2025-08-15 11:47:58,081:INFO:Epoch: 6600/10000 | Train Loss: 3.765e-01 | Dynamic Loss: 3.765e-01 | Regularization Loss: 9.647e-08 | Val Loss: 3.946e-01 | Time: 4.82s
2025-08-15 11:47:58,081:INFO:New best model found at epoch 6600 with validation loss 3.946e-01. Saving...
2025-08-15 11:48:02,848:INFO:Epoch: 6650/10000 | Train Loss: 3.756e-01 | Dynamic Loss: 3.756e-01 | Regularization Loss: 1.099e-07 | Val Loss: 3.949e-01 | Time: 4.76s
2025-08-15 11:48:13,875:INFO:Epoch: 6700/10000 | Train Loss: 3.759e-01 | Dynamic Loss: 3.759e-01 | Regularization Loss: 1.241e-07 | Val Loss: 3.937e-01 | Time: 11.03s
2025-08-15 11:48:13,875:INFO:New best model found at epoch 6700 with validation loss 3.937e-01. Saving...
2025-08-15 11:48:18,688:INFO:Epoch: 6750/10000 | Train Loss: 3.756e-01 | Dynamic Loss: 3.756e-01 | Regularization Loss: 0.000e+00 | Val Loss: 3.928e-01 | Time: 4.80s
2025-08-15 11:48:18,688:INFO:New best model found at epoch 6750 with validation loss 3.928e-01. Saving...
2025-08-15 11:48:23,509:INFO:Epoch: 6800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.81s
2025-08-15 11:48:28,300:INFO:Epoch: 6850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.79s
2025-08-15 11:48:33,069:INFO:Epoch: 6900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.77s
2025-08-15 11:48:37,817:INFO:Epoch: 6950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.75s
2025-08-15 11:48:42,594:INFO:Epoch: 7000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.78s
2025-08-15 11:48:47,343:INFO:Epoch: 7050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.75s
2025-08-15 11:48:52,083:INFO:Epoch: 7100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.74s
2025-08-15 11:49:02,813:INFO:Epoch: 7150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 10.73s
2025-08-15 11:49:07,640:INFO:Epoch: 7200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.83s
2025-08-15 11:49:12,453:INFO:Epoch: 7250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.81s
2025-08-15 11:49:17,219:INFO:Epoch: 7300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.77s
2025-08-15 11:49:22,216:INFO:Epoch: 7350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.00s
2025-08-15 11:49:27,070:INFO:Epoch: 7400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.85s
2025-08-15 11:49:31,945:INFO:Epoch: 7450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.87s
2025-08-15 11:49:36,728:INFO:Epoch: 7500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.78s
2025-08-15 11:49:41,439:INFO:Epoch: 7550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.71s
2025-08-15 11:49:50,159:INFO:Epoch: 7600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 8.72s
2025-08-15 11:49:54,912:INFO:Epoch: 7650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.75s
2025-08-15 11:49:59,822:INFO:Epoch: 7700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.91s
2025-08-15 11:50:04,517:INFO:Epoch: 7750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.69s
2025-08-15 11:50:09,200:INFO:Epoch: 7800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.68s
2025-08-15 11:50:16,893:INFO:Epoch: 7850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 7.69s
2025-08-15 11:50:21,744:INFO:Epoch: 7900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.85s
2025-08-15 11:50:26,632:INFO:Epoch: 7950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.89s
2025-08-15 11:50:31,319:INFO:Epoch: 8000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.69s
2025-08-15 11:50:36,004:INFO:Epoch: 8050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.68s
2025-08-15 11:50:46,392:INFO:Epoch: 8100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 10.39s
2025-08-15 11:50:51,271:INFO:Epoch: 8150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.88s
2025-08-15 11:50:56,155:INFO:Epoch: 8200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.88s
2025-08-15 11:51:00,903:INFO:Epoch: 8250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.75s
2025-08-15 11:51:05,616:INFO:Epoch: 8300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.71s
2025-08-15 11:51:13,947:INFO:Epoch: 8350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 8.33s
2025-08-15 11:51:18,718:INFO:Epoch: 8400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.77s
2025-08-15 11:51:23,479:INFO:Epoch: 8450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.76s
2025-08-15 11:51:28,222:INFO:Epoch: 8500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.74s
2025-08-15 11:51:32,968:INFO:Epoch: 8550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.75s
2025-08-15 11:51:40,708:INFO:Epoch: 8600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 7.74s
2025-08-15 11:51:45,457:INFO:Epoch: 8650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.75s
2025-08-15 11:51:50,180:INFO:Epoch: 8700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.72s
2025-08-15 11:51:55,116:INFO:Epoch: 8750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.93s
2025-08-15 11:51:59,968:INFO:Epoch: 8800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.85s
2025-08-15 11:52:08,358:INFO:Epoch: 8850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 8.39s
2025-08-15 11:52:13,185:INFO:Epoch: 8900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.83s
2025-08-15 11:52:17,982:INFO:Epoch: 8950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.80s
2025-08-15 11:52:22,756:INFO:Epoch: 9000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.77s
2025-08-15 11:52:27,560:INFO:Epoch: 9050/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.80s
2025-08-15 11:52:38,794:INFO:Epoch: 9100/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 11.23s
2025-08-15 11:52:43,627:INFO:Epoch: 9150/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.83s
2025-08-15 11:52:48,475:INFO:Epoch: 9200/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.85s
2025-08-15 11:52:53,305:INFO:Epoch: 9250/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.83s
2025-08-15 11:52:58,244:INFO:Epoch: 9300/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.94s
2025-08-15 11:53:03,126:INFO:Epoch: 9350/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.88s
2025-08-15 11:53:07,947:INFO:Epoch: 9400/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.82s
2025-08-15 11:53:12,708:INFO:Epoch: 9450/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.76s
2025-08-15 11:53:17,442:INFO:Epoch: 9500/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.73s
2025-08-15 11:53:22,334:INFO:Epoch: 9550/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.89s
2025-08-15 11:53:27,077:INFO:Epoch: 9600/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.74s
2025-08-15 11:53:32,080:INFO:Epoch: 9650/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.00s
2025-08-15 11:53:36,942:INFO:Epoch: 9700/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.86s
2025-08-15 11:53:41,754:INFO:Epoch: 9750/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.81s
2025-08-15 11:53:47,059:INFO:Epoch: 9800/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 5.30s
2025-08-15 11:53:51,910:INFO:Epoch: 9850/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.85s
2025-08-15 11:53:56,780:INFO:Epoch: 9900/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.87s
2025-08-15 11:54:01,551:INFO:Epoch: 9950/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.77s
2025-08-15 11:54:06,405:INFO:Epoch: 10000/10000 | Train Loss: nan | Dynamic Loss: nan | Regularization Loss: nan | Val Loss: nan | Time: 4.85s
2025-08-15 11:57:07,024:INFO:Using device: cuda
2025-08-15 11:58:08,238:INFO:Using device: cuda
2025-08-15 11:59:09,203:INFO:Using device: cuda
